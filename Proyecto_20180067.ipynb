{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Final\n",
    "## Elements of Machine Learning\n",
    "## Carlos Morales Sanchez 20180067"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7200, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTR</th>\n",
       "      <th>HS</th>\n",
       "      <th>AS</th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>...</th>\n",
       "      <th>AF</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fulham</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>6.00</td>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>West Ham</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.15</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>West Brom</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         HomeTeam     AwayTeam FTR  HTHG  HTAG  HTR    HS   AS  HST  AST  ...  \\\n",
       "0          Fulham      Arsenal   A     0     1   -1   2.5  6.5  1.0  3.0  ...   \n",
       "1  Crystal Palace  Southampton   H     1     0    1   2.5  4.5  1.5  2.5  ...   \n",
       "2       Liverpool        Leeds   H     3     2    1  11.0  3.0  3.0  1.5  ...   \n",
       "3        West Ham    Newcastle   A     0     0    0   7.5  7.5  1.5  1.0  ...   \n",
       "4       West Brom    Leicester   A     0     0    0   3.5  6.5  0.5  3.5  ...   \n",
       "\n",
       "    AF   HC   AC   HY   AY   HR   AR  B365H  B365D  B365A  \n",
       "0  6.0  1.0  1.5  1.0  1.0  0.0  0.0   6.00   4.33   1.53  \n",
       "1  5.5  3.5  1.5  1.0  0.5  0.0  0.0   3.10   3.25   2.37  \n",
       "2  3.0  4.5  0.0  0.5  0.0  0.0  0.0   1.28   6.00   9.50  \n",
       "3  3.5  4.0  3.5  1.0  1.0  0.0  0.0   2.15   3.40   3.40  \n",
       "4  4.5  1.0  2.5  0.5  0.5  0.0  0.0   3.80   3.60   1.95  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"datos_premier_eml.csv\")\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset cuenta con registro de cada partido que se ha disputado en la Liga Premier de Inglaterra desde la temporada 2003/2004 hasta la fecha. El dataset se consolidó utilizando los documentos que publica Football-data cada año. Fuente: http://www.football-data.co.uk/englandm.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo general del proyecto consiste en predecir la variable FTR (Full time result), la cual puede tomar 3 valores: A (victoria del visitant) D (empate) H (victoria del local), utilizando como input el resto de variables del dataset, con información corresponidente a las estadisticas de juego generadas por cada equipo (tiros, faltas, tarjetas, tiros de esquina), y el monto que paga Bet365 antes del comienzo del partido en apuestas por victoria local, visitante, o empate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como primer punto se generó un segundo dataset, el cual excluye las variables categóricas HomeTeam y AwayTeam, las cuales indican el nombre del equipo que jugaba. Esto con el fin de determinar si es mejor entrenar el modelo utilizando dichas variables o no. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTR</th>\n",
       "      <th>HS</th>\n",
       "      <th>AS</th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fulham</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>6.00</td>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>West Ham</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.15</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>West Brom</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         HomeTeam     AwayTeam  HTHG  HTAG  HTR    HS   AS  HST  AST   HF  \\\n",
       "0          Fulham      Arsenal     0     1   -1   2.5  6.5  1.0  3.0  6.0   \n",
       "1  Crystal Palace  Southampton     1     0    1   2.5  4.5  1.5  2.5  7.0   \n",
       "2       Liverpool        Leeds     3     2    1  11.0  3.0  3.0  1.5  4.5   \n",
       "3        West Ham    Newcastle     0     0    0   7.5  7.5  1.5  1.0  6.5   \n",
       "4       West Brom    Leicester     0     0    0   3.5  6.5  0.5  3.5  6.0   \n",
       "\n",
       "    AF   HC   AC   HY   AY   HR   AR  B365H  B365D  B365A  \n",
       "0  6.0  1.0  1.5  1.0  1.0  0.0  0.0   6.00   4.33   1.53  \n",
       "1  5.5  3.5  1.5  1.0  0.5  0.0  0.0   3.10   3.25   2.37  \n",
       "2  3.0  4.5  0.0  0.5  0.0  0.0  0.0   1.28   6.00   9.50  \n",
       "3  3.5  4.0  3.5  1.0  1.0  0.0  0.0   2.15   3.40   3.40  \n",
       "4  4.5  1.0  2.5  0.5  0.5  0.0  0.0   3.80   3.60   1.95  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX = data.drop('FTR', axis = 'columns')\n",
    "dataX2 = data.drop(['FTR','HomeTeam','AwayTeam'], axis = 'columns')\n",
    "dataX.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizó un onehot encoder para generar variables dummies de cada una de las categorias de HomeTeam y AwayTeam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncode(df,colNames):\n",
    "    for col in colNames:\n",
    "        if( df[col].dtype == np.dtype('object')):\n",
    "            dummies = pd.get_dummies(df[col],prefix=col)\n",
    "            df = pd.concat([df,dummies],axis=1)\n",
    "\n",
    "            df.drop([col],axis = 1 , inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTR</th>\n",
       "      <th>HS</th>\n",
       "      <th>AS</th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HC</th>\n",
       "      <th>...</th>\n",
       "      <th>AwayTeam_Southampton</th>\n",
       "      <th>AwayTeam_Stoke</th>\n",
       "      <th>AwayTeam_Sunderland</th>\n",
       "      <th>AwayTeam_Swansea</th>\n",
       "      <th>AwayTeam_Tottenham</th>\n",
       "      <th>AwayTeam_Watford</th>\n",
       "      <th>AwayTeam_West Brom</th>\n",
       "      <th>AwayTeam_West Ham</th>\n",
       "      <th>AwayTeam_Wigan</th>\n",
       "      <th>AwayTeam_Wolves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HTHG  HTAG  HTR    HS   AS  HST  AST   HF   AF   HC  ...  \\\n",
       "0     0     1   -1   2.5  6.5  1.0  3.0  6.0  6.0  1.0  ...   \n",
       "1     1     0    1   2.5  4.5  1.5  2.5  7.0  5.5  3.5  ...   \n",
       "2     3     2    1  11.0  3.0  3.0  1.5  4.5  3.0  4.5  ...   \n",
       "3     0     0    0   7.5  7.5  1.5  1.0  6.5  3.5  4.0  ...   \n",
       "4     0     0    0   3.5  6.5  0.5  3.5  6.0  4.5  1.0  ...   \n",
       "\n",
       "   AwayTeam_Southampton  AwayTeam_Stoke  AwayTeam_Sunderland  \\\n",
       "0                     0               0                    0   \n",
       "1                     1               0                    0   \n",
       "2                     0               0                    0   \n",
       "3                     0               0                    0   \n",
       "4                     0               0                    0   \n",
       "\n",
       "   AwayTeam_Swansea  AwayTeam_Tottenham  AwayTeam_Watford  AwayTeam_West Brom  \\\n",
       "0                 0                   0                 0                   0   \n",
       "1                 0                   0                 0                   0   \n",
       "2                 0                   0                 0                   0   \n",
       "3                 0                   0                 0                   0   \n",
       "4                 0                   0                 0                   0   \n",
       "\n",
       "   AwayTeam_West Ham  AwayTeam_Wigan  AwayTeam_Wolves  \n",
       "0                  0               0                0  \n",
       "1                  0               0                0  \n",
       "2                  0               0                0  \n",
       "3                  0               0                0  \n",
       "4                  0               0                0  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX = oneHotEncode(dataX,dataX.columns)\n",
    "dataX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataX.values\n",
    "dataset2 = dataX2.values\n",
    "data_v = data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo a la documentación citada al final del notebook, se realizó un standard scaler a las variables numéricas, buscando un mejor resultado en el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(dataset)\n",
    "scaler2 = StandardScaler().fit(dataset2)\n",
    "\n",
    "dataset = scaler.transform(dataset)\n",
    "dataset2 = scaler2.transform(dataset2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambíen fue necesario generar variables dummies para la variable objetio (FTR) ya que dicha variable es categórica, y tiene 3 categorías. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7200, 98)\n",
      "[[-0.81941278  0.68664143 -1.04728995 ... -0.20959996 -0.14685504\n",
      "  -0.13665914]\n",
      " [ 0.38290473 -0.70051297  0.73301642 ... -0.20959996 -0.14685504\n",
      "  -0.13665914]\n",
      " [ 2.78753976  2.07379582  0.73301642 ... -0.20959996 -0.14685504\n",
      "  -0.13665914]\n",
      " ...\n",
      " [ 2.78753976 -0.70051297  2.51332279 ... -0.20959996 -0.14685504\n",
      "  -0.13665914]\n",
      " [ 2.78753976  0.68664143  1.6231696  ... -0.20959996 -0.14685504\n",
      "  -0.13665914]\n",
      " [-0.81941278  0.68664143 -1.04728995 ... -0.20959996 -0.14685504\n",
      "  -0.13665914]]\n",
      "(7200, 18)\n",
      "[[-0.81941278  0.68664143 -1.04728995 ...  1.71252156  0.35016326\n",
      "  -0.82197336]\n",
      " [ 0.38290473 -0.70051297  0.73301642 ...  0.18893405 -0.60138829\n",
      "  -0.61060593]\n",
      " [ 2.78753976  2.07379582  0.73301642 ... -0.76724846  1.82154389\n",
      "   1.18350091]\n",
      " ...\n",
      " [ 2.78753976 -0.70051297  2.51332279 ... -0.33644096 -0.60138829\n",
      "  -0.35142921]\n",
      " [ 2.78753976  0.68664143  1.6231696  ... -0.25763471 -0.55733497\n",
      "  -0.45208036]\n",
      " [-0.81941278  0.68664143 -1.04728995 ... -0.19458971 -0.55733497\n",
      "  -0.50240594]]\n",
      "(7200, 3)\n",
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "y = data_v[:,2]\n",
    "y_0 = y[0:2000]\n",
    "X = dataset\n",
    "X_0 = dataset[0:2000]\n",
    "X2 = dataset2\n",
    "X2_0 = dataset2[0:2000]\n",
    "print(X.shape)\n",
    "print(X)\n",
    "print(X2.shape)\n",
    "print(X2)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "y = np_utils.to_categorical(encoded_Y)\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como primer punto se generan dos funciones, encargadas de generar la misma red neuronal, y de esta forma poder evaluar el dataset con variables dummies, y sin variables dummies. De esta forma se determinará que dataset se utilizará para seguir adelante con el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=98, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_2():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=18, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=create_model, epochs=50, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator2 = KerasClassifier(build_fn=create_model_2, epochs=50, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.05% (5.35%)\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(estimator, X_0, y_0, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.25% (2.21%)\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(estimator2, X2_0, y_0, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se determinó que las variables categóricas HomeTeam y Away team no aportan un verdadero valor al modelo predictivo realizado en esta prueba. Debido a esto se decidió trabajar con el dataset que no contiene dichas variables, puesto que estas perjudican la predicción, e incrementan el nivel de computo requerido. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente se utilizará la función de Grid Search, con el fin de probar multiples hiper parametros, como el optimizador utilizado, el estado inicial de los pesos de la red, el número de epochs y el bach size. De esta forma se determinará la mejor combinación, para pasar a la parte final en la cual se evaluará la arquitectura que debera tener la red. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_3(optimizer='rmsprop', init='glorot_uniform'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim = 18, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dense(3, kernel_initializer=init, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model_3, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = ['rmsprop', 'adam']\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = [50, 100]\n",
    "batches = [5, 10, 20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideal: 0.673500 using {'batch_size': 20, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.655500 (0.030307) with: {'batch_size': 5, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.649000 (0.021599) with: {'batch_size': 5, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.661000 (0.023484) with: {'batch_size': 5, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.657500 (0.025000) with: {'batch_size': 5, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.653500 (0.034807) with: {'batch_size': 5, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.660000 (0.035637) with: {'batch_size': 5, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.640000 (0.031544) with: {'batch_size': 5, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.643500 (0.022616) with: {'batch_size': 5, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.640500 (0.033556) with: {'batch_size': 5, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.648000 (0.021119) with: {'batch_size': 5, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.640500 (0.027677) with: {'batch_size': 5, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.657500 (0.022023) with: {'batch_size': 5, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.652000 (0.024617) with: {'batch_size': 10, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.662000 (0.028653) with: {'batch_size': 10, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.663000 (0.026898) with: {'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.663500 (0.026058) with: {'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.660000 (0.031425) with: {'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.660500 (0.025120) with: {'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.640500 (0.025515) with: {'batch_size': 10, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.656500 (0.025179) with: {'batch_size': 10, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.647000 (0.037928) with: {'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.650000 (0.032210) with: {'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.658500 (0.026344) with: {'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.658500 (0.015621) with: {'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.658000 (0.024413) with: {'batch_size': 20, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.650500 (0.024259) with: {'batch_size': 20, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.673500 (0.022338) with: {'batch_size': 20, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.671000 (0.024729) with: {'batch_size': 20, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.666000 (0.026861) with: {'batch_size': 20, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.662000 (0.028213) with: {'batch_size': 20, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.646000 (0.022946) with: {'batch_size': 20, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.648000 (0.022159) with: {'batch_size': 20, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.659500 (0.019710) with: {'batch_size': 20, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.663000 (0.027722) with: {'batch_size': 20, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.663000 (0.027359) with: {'batch_size': 20, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.650000 (0.024900) with: {'batch_size': 20, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(optimizer=optimizers, epochs=epochs, batch_size=batches, init=init)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X2_0, y_0)\n",
    "\n",
    "print(\"Ideal: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa anteriormente, el modelo que obtuvo el mejor resultado de accuracy fue el que utilizó un batch size de 20, un total de 50 epochs, inicializador 'normal', y optimizador 'rmsprop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la parte final de selección, se dividó el dataset en 3 fragmentos. El 70% para entrenamiento del modelo, 20% para testeo continuo, y 10 para cross validation en la parte final. Esto se realiza para asegurarnos de que el modelo no este generando overfitting, y perdiendo su capacidad de geeralizar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5040, 18)\n",
      "(5040, 3)\n",
      "(1447, 18)\n",
      "(1447, 3)\n",
      "(713, 18)\n",
      "(713, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size=0.3, random_state=15)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.33, random_state=15)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para seleecioanr la mejor arquitectura de red neural para el modelo, se comenzó utilizando una base con estructura 12/8/3. El objetivo es ir movinedonos desde aqui, hasta llegar a la estructura que mejor resultado genere. La red neuronal utiliza los parámetos previamente identificados como los mejores, además de la función de activación relu para las capas oculats, y softmax para la capa de output. También se utilizó categorical crossentropy como la loss functio que el modelo optimizará."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se observara una gran serie de modelos de redes neuronales, cada uno con una arquitectura distinta, con el fin de determianr que estructura se utilizará para el modelo definitivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_221\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_663 (Dense)            (None, 12)                228       \n",
      "_________________________________________________________________\n",
      "dense_664 (Dense)            (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_665 (Dense)            (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 359\n",
      "Trainable params: 359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(12, kernel_initializer='normal', activation='relu', input_shape=(18,)))\n",
    "model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "252/252 [==============================] - 1s 1ms/step - loss: 1.0127 - accuracy: 0.5418\n",
      "Epoch 2/200\n",
      "252/252 [==============================] - 0s 982us/step - loss: 0.7628 - accuracy: 0.6479\n",
      "Epoch 3/200\n",
      "252/252 [==============================] - 0s 946us/step - loss: 0.7466 - accuracy: 0.6522\n",
      "Epoch 4/200\n",
      "252/252 [==============================] - 0s 943us/step - loss: 0.7458 - accuracy: 0.6578\n",
      "Epoch 5/200\n",
      "252/252 [==============================] - 0s 949us/step - loss: 0.7317 - accuracy: 0.6700\n",
      "Epoch 6/200\n",
      "252/252 [==============================] - 0s 952us/step - loss: 0.7346 - accuracy: 0.6614\n",
      "Epoch 7/200\n",
      "252/252 [==============================] - 0s 938us/step - loss: 0.7313 - accuracy: 0.6703\n",
      "Epoch 8/200\n",
      "252/252 [==============================] - 0s 948us/step - loss: 0.7197 - accuracy: 0.6666\n",
      "Epoch 9/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7279 - accuracy: 0.6626\n",
      "Epoch 10/200\n",
      "252/252 [==============================] - 0s 977us/step - loss: 0.7254 - accuracy: 0.6674\n",
      "Epoch 11/200\n",
      "252/252 [==============================] - 0s 943us/step - loss: 0.7166 - accuracy: 0.6743\n",
      "Epoch 12/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7252 - accuracy: 0.6752\n",
      "Epoch 13/200\n",
      "252/252 [==============================] - 0s 952us/step - loss: 0.7139 - accuracy: 0.6795\n",
      "Epoch 14/200\n",
      "252/252 [==============================] - 0s 945us/step - loss: 0.7264 - accuracy: 0.6635\n",
      "Epoch 15/200\n",
      "252/252 [==============================] - 0s 931us/step - loss: 0.7127 - accuracy: 0.6720\n",
      "Epoch 16/200\n",
      "252/252 [==============================] - 0s 932us/step - loss: 0.6970 - accuracy: 0.6890\n",
      "Epoch 17/200\n",
      "252/252 [==============================] - 0s 950us/step - loss: 0.7110 - accuracy: 0.6876\n",
      "Epoch 18/200\n",
      "252/252 [==============================] - 0s 991us/step - loss: 0.7065 - accuracy: 0.6861\n",
      "Epoch 19/200\n",
      "252/252 [==============================] - 0s 940us/step - loss: 0.7245 - accuracy: 0.6708\n",
      "Epoch 20/200\n",
      "252/252 [==============================] - 0s 932us/step - loss: 0.6992 - accuracy: 0.6852\n",
      "Epoch 21/200\n",
      "252/252 [==============================] - 0s 945us/step - loss: 0.7151 - accuracy: 0.6786\n",
      "Epoch 22/200\n",
      "252/252 [==============================] - 0s 938us/step - loss: 0.7039 - accuracy: 0.6830\n",
      "Epoch 23/200\n",
      "252/252 [==============================] - 0s 951us/step - loss: 0.7044 - accuracy: 0.6898\n",
      "Epoch 24/200\n",
      "252/252 [==============================] - 0s 978us/step - loss: 0.6907 - accuracy: 0.6979\n",
      "Epoch 25/200\n",
      "252/252 [==============================] - 0s 996us/step - loss: 0.7021 - accuracy: 0.6918\n",
      "Epoch 26/200\n",
      "252/252 [==============================] - 0s 982us/step - loss: 0.7029 - accuracy: 0.6930\n",
      "Epoch 27/200\n",
      "252/252 [==============================] - 0s 942us/step - loss: 0.7212 - accuracy: 0.6882\n",
      "Epoch 28/200\n",
      "252/252 [==============================] - 0s 937us/step - loss: 0.7102 - accuracy: 0.6773\n",
      "Epoch 29/200\n",
      "252/252 [==============================] - 0s 941us/step - loss: 0.7070 - accuracy: 0.6907\n",
      "Epoch 30/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6987 - accuracy: 0.6945\n",
      "Epoch 31/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7073 - accuracy: 0.6899\n",
      "Epoch 32/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7055 - accuracy: 0.6792\n",
      "Epoch 33/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7058 - accuracy: 0.6800\n",
      "Epoch 34/200\n",
      "252/252 [==============================] - 0s 934us/step - loss: 0.7061 - accuracy: 0.6888\n",
      "Epoch 35/200\n",
      "252/252 [==============================] - 0s 957us/step - loss: 0.7053 - accuracy: 0.6862\n",
      "Epoch 36/200\n",
      "252/252 [==============================] - 0s 947us/step - loss: 0.7193 - accuracy: 0.6826\n",
      "Epoch 37/200\n",
      "252/252 [==============================] - 0s 939us/step - loss: 0.7011 - accuracy: 0.6872\n",
      "Epoch 38/200\n",
      "252/252 [==============================] - 0s 939us/step - loss: 0.7114 - accuracy: 0.6851\n",
      "Epoch 39/200\n",
      "252/252 [==============================] - 0s 967us/step - loss: 0.6971 - accuracy: 0.6956\n",
      "Epoch 40/200\n",
      "252/252 [==============================] - 0s 933us/step - loss: 0.7119 - accuracy: 0.6798\n",
      "Epoch 41/200\n",
      "252/252 [==============================] - 0s 942us/step - loss: 0.6985 - accuracy: 0.6953\n",
      "Epoch 42/200\n",
      "252/252 [==============================] - 0s 943us/step - loss: 0.7103 - accuracy: 0.6829\n",
      "Epoch 43/200\n",
      "252/252 [==============================] - 0s 941us/step - loss: 0.6889 - accuracy: 0.6920\n",
      "Epoch 44/200\n",
      "252/252 [==============================] - 0s 940us/step - loss: 0.7019 - accuracy: 0.6904\n",
      "Epoch 45/200\n",
      "252/252 [==============================] - 0s 950us/step - loss: 0.6964 - accuracy: 0.6926\n",
      "Epoch 46/200\n",
      "252/252 [==============================] - 0s 929us/step - loss: 0.6957 - accuracy: 0.6942\n",
      "Epoch 47/200\n",
      "252/252 [==============================] - 0s 936us/step - loss: 0.7105 - accuracy: 0.6708\n",
      "Epoch 48/200\n",
      "252/252 [==============================] - 0s 943us/step - loss: 0.7066 - accuracy: 0.6867\n",
      "Epoch 49/200\n",
      "252/252 [==============================] - 0s 940us/step - loss: 0.6875 - accuracy: 0.6943\n",
      "Epoch 50/200\n",
      "252/252 [==============================] - 0s 945us/step - loss: 0.6728 - accuracy: 0.6963\n",
      "Epoch 51/200\n",
      "252/252 [==============================] - 0s 932us/step - loss: 0.6985 - accuracy: 0.6913\n",
      "Epoch 52/200\n",
      "252/252 [==============================] - 0s 973us/step - loss: 0.6947 - accuracy: 0.6915\n",
      "Epoch 53/200\n",
      "252/252 [==============================] - 0s 929us/step - loss: 0.6977 - accuracy: 0.6827\n",
      "Epoch 54/200\n",
      "252/252 [==============================] - 0s 935us/step - loss: 0.7040 - accuracy: 0.6855\n",
      "Epoch 55/200\n",
      "252/252 [==============================] - 0s 936us/step - loss: 0.7030 - accuracy: 0.6865\n",
      "Epoch 56/200\n",
      "252/252 [==============================] - 0s 935us/step - loss: 0.6930 - accuracy: 0.6883\n",
      "Epoch 57/200\n",
      "252/252 [==============================] - 0s 935us/step - loss: 0.6727 - accuracy: 0.7069\n",
      "Epoch 58/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7082 - accuracy: 0.6897\n",
      "Epoch 59/200\n",
      "252/252 [==============================] - 0s 955us/step - loss: 0.6816 - accuracy: 0.6989\n",
      "Epoch 60/200\n",
      "252/252 [==============================] - 0s 960us/step - loss: 0.7026 - accuracy: 0.6770\n",
      "Epoch 61/200\n",
      "252/252 [==============================] - 0s 939us/step - loss: 0.6997 - accuracy: 0.6906\n",
      "Epoch 62/200\n",
      "252/252 [==============================] - 0s 944us/step - loss: 0.6960 - accuracy: 0.7010\n",
      "Epoch 63/200\n",
      "252/252 [==============================] - 0s 949us/step - loss: 0.6978 - accuracy: 0.6887\n",
      "Epoch 64/200\n",
      "252/252 [==============================] - 0s 951us/step - loss: 0.6928 - accuracy: 0.6929\n",
      "Epoch 65/200\n",
      "252/252 [==============================] - 0s 947us/step - loss: 0.7022 - accuracy: 0.6839\n",
      "Epoch 66/200\n",
      "252/252 [==============================] - 0s 985us/step - loss: 0.6816 - accuracy: 0.7028\n",
      "Epoch 67/200\n",
      "252/252 [==============================] - 0s 984us/step - loss: 0.6953 - accuracy: 0.6884\n",
      "Epoch 68/200\n",
      "252/252 [==============================] - 0s 948us/step - loss: 0.6882 - accuracy: 0.6942\n",
      "Epoch 69/200\n",
      "252/252 [==============================] - 0s 992us/step - loss: 0.6930 - accuracy: 0.6910\n",
      "Epoch 70/200\n",
      "252/252 [==============================] - 0s 965us/step - loss: 0.6948 - accuracy: 0.6930\n",
      "Epoch 71/200\n",
      "252/252 [==============================] - 0s 932us/step - loss: 0.6898 - accuracy: 0.6944\n",
      "Epoch 72/200\n",
      "252/252 [==============================] - 0s 953us/step - loss: 0.7091 - accuracy: 0.6843\n",
      "Epoch 73/200\n",
      "252/252 [==============================] - 0s 955us/step - loss: 0.6911 - accuracy: 0.6982\n",
      "Epoch 74/200\n",
      "252/252 [==============================] - 0s 956us/step - loss: 0.6861 - accuracy: 0.6967\n",
      "Epoch 75/200\n",
      "252/252 [==============================] - 0s 938us/step - loss: 0.6858 - accuracy: 0.6923\n",
      "Epoch 76/200\n",
      "252/252 [==============================] - 0s 928us/step - loss: 0.6801 - accuracy: 0.6998\n",
      "Epoch 77/200\n",
      "252/252 [==============================] - 0s 931us/step - loss: 0.6848 - accuracy: 0.6892\n",
      "Epoch 78/200\n",
      "252/252 [==============================] - 0s 926us/step - loss: 0.6832 - accuracy: 0.7008\n",
      "Epoch 79/200\n",
      "252/252 [==============================] - 0s 943us/step - loss: 0.6792 - accuracy: 0.7002\n",
      "Epoch 80/200\n",
      "252/252 [==============================] - 0s 936us/step - loss: 0.6849 - accuracy: 0.6954\n",
      "Epoch 81/200\n",
      "252/252 [==============================] - 0s 932us/step - loss: 0.6708 - accuracy: 0.7135\n",
      "Epoch 82/200\n",
      "252/252 [==============================] - 0s 948us/step - loss: 0.6717 - accuracy: 0.7012\n",
      "Epoch 83/200\n",
      "252/252 [==============================] - 0s 978us/step - loss: 0.6966 - accuracy: 0.6892\n",
      "Epoch 84/200\n",
      "252/252 [==============================] - 0s 964us/step - loss: 0.6799 - accuracy: 0.6988\n",
      "Epoch 85/200\n",
      "252/252 [==============================] - 0s 947us/step - loss: 0.6845 - accuracy: 0.6944\n",
      "Epoch 86/200\n",
      "252/252 [==============================] - 0s 966us/step - loss: 0.7033 - accuracy: 0.6797\n",
      "Epoch 87/200\n",
      "252/252 [==============================] - 0s 954us/step - loss: 0.6856 - accuracy: 0.6939\n",
      "Epoch 88/200\n",
      "252/252 [==============================] - 0s 933us/step - loss: 0.7119 - accuracy: 0.6798\n",
      "Epoch 89/200\n",
      "252/252 [==============================] - 0s 938us/step - loss: 0.6967 - accuracy: 0.6949\n",
      "Epoch 90/200\n",
      "252/252 [==============================] - 0s 937us/step - loss: 0.6892 - accuracy: 0.6960\n",
      "Epoch 91/200\n",
      "252/252 [==============================] - 0s 964us/step - loss: 0.6886 - accuracy: 0.6931\n",
      "Epoch 92/200\n",
      "252/252 [==============================] - 0s 960us/step - loss: 0.6866 - accuracy: 0.6913\n",
      "Epoch 93/200\n",
      "252/252 [==============================] - 0s 968us/step - loss: 0.7159 - accuracy: 0.6833\n",
      "Epoch 94/200\n",
      "252/252 [==============================] - 0s 952us/step - loss: 0.6744 - accuracy: 0.7015\n",
      "Epoch 95/200\n",
      "252/252 [==============================] - 0s 946us/step - loss: 0.6953 - accuracy: 0.6902\n",
      "Epoch 96/200\n",
      "252/252 [==============================] - 0s 949us/step - loss: 0.6889 - accuracy: 0.6967\n",
      "Epoch 97/200\n",
      "252/252 [==============================] - 0s 952us/step - loss: 0.6692 - accuracy: 0.7080\n",
      "Epoch 98/200\n",
      "252/252 [==============================] - 0s 940us/step - loss: 0.6862 - accuracy: 0.6949\n",
      "Epoch 99/200\n",
      "252/252 [==============================] - 0s 959us/step - loss: 0.6854 - accuracy: 0.7070\n",
      "Epoch 100/200\n",
      "252/252 [==============================] - 0s 956us/step - loss: 0.6892 - accuracy: 0.7038\n",
      "Epoch 101/200\n",
      "252/252 [==============================] - 0s 968us/step - loss: 0.6904 - accuracy: 0.6909\n",
      "Epoch 102/200\n",
      "252/252 [==============================] - 0s 945us/step - loss: 0.6868 - accuracy: 0.6953\n",
      "Epoch 103/200\n",
      "252/252 [==============================] - 0s 948us/step - loss: 0.6832 - accuracy: 0.6919\n",
      "Epoch 104/200\n",
      "252/252 [==============================] - 0s 933us/step - loss: 0.6859 - accuracy: 0.6925\n",
      "Epoch 105/200\n",
      "252/252 [==============================] - 0s 954us/step - loss: 0.6936 - accuracy: 0.6898\n",
      "Epoch 106/200\n",
      "252/252 [==============================] - 0s 951us/step - loss: 0.6810 - accuracy: 0.7076\n",
      "Epoch 107/200\n",
      "252/252 [==============================] - 0s 964us/step - loss: 0.6808 - accuracy: 0.6975\n",
      "Epoch 108/200\n",
      "252/252 [==============================] - 0s 966us/step - loss: 0.6845 - accuracy: 0.6961\n",
      "Epoch 109/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.6947\n",
      "Epoch 110/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.7025\n",
      "Epoch 111/200\n",
      "252/252 [==============================] - 0s 983us/step - loss: 0.6781 - accuracy: 0.6965\n",
      "Epoch 112/200\n",
      "252/252 [==============================] - 0s 946us/step - loss: 0.6905 - accuracy: 0.6946\n",
      "Epoch 113/200\n",
      "252/252 [==============================] - 0s 947us/step - loss: 0.6855 - accuracy: 0.7027\n",
      "Epoch 114/200\n",
      "252/252 [==============================] - 0s 960us/step - loss: 0.6844 - accuracy: 0.6962\n",
      "Epoch 115/200\n",
      "252/252 [==============================] - 0s 957us/step - loss: 0.6877 - accuracy: 0.6934\n",
      "Epoch 116/200\n",
      "252/252 [==============================] - 0s 938us/step - loss: 0.6871 - accuracy: 0.7003\n",
      "Epoch 117/200\n",
      "252/252 [==============================] - 0s 943us/step - loss: 0.6806 - accuracy: 0.7014\n",
      "Epoch 118/200\n",
      "252/252 [==============================] - 0s 939us/step - loss: 0.6646 - accuracy: 0.7167\n",
      "Epoch 119/200\n",
      "252/252 [==============================] - 0s 947us/step - loss: 0.6744 - accuracy: 0.6979\n",
      "Epoch 120/200\n",
      "252/252 [==============================] - 0s 938us/step - loss: 0.6883 - accuracy: 0.6969\n",
      "Epoch 121/200\n",
      "252/252 [==============================] - 0s 958us/step - loss: 0.6752 - accuracy: 0.6993\n",
      "Epoch 122/200\n",
      "252/252 [==============================] - 0s 937us/step - loss: 0.6911 - accuracy: 0.6875\n",
      "Epoch 123/200\n",
      "252/252 [==============================] - 0s 946us/step - loss: 0.6855 - accuracy: 0.6960\n",
      "Epoch 124/200\n",
      "252/252 [==============================] - 0s 949us/step - loss: 0.6669 - accuracy: 0.7056\n",
      "Epoch 125/200\n",
      "252/252 [==============================] - 0s 925us/step - loss: 0.6727 - accuracy: 0.7034\n",
      "Epoch 126/200\n",
      "252/252 [==============================] - 0s 942us/step - loss: 0.6739 - accuracy: 0.6977\n",
      "Epoch 127/200\n",
      "252/252 [==============================] - 0s 944us/step - loss: 0.6787 - accuracy: 0.7029\n",
      "Epoch 128/200\n",
      "252/252 [==============================] - 0s 950us/step - loss: 0.6843 - accuracy: 0.6990\n",
      "Epoch 129/200\n",
      "252/252 [==============================] - 0s 944us/step - loss: 0.6741 - accuracy: 0.7018\n",
      "Epoch 130/200\n",
      "252/252 [==============================] - 0s 958us/step - loss: 0.6819 - accuracy: 0.7000\n",
      "Epoch 131/200\n",
      "252/252 [==============================] - 0s 940us/step - loss: 0.6906 - accuracy: 0.6892\n",
      "Epoch 132/200\n",
      "252/252 [==============================] - 0s 952us/step - loss: 0.6822 - accuracy: 0.7017\n",
      "Epoch 133/200\n",
      "252/252 [==============================] - 0s 940us/step - loss: 0.6772 - accuracy: 0.7035\n",
      "Epoch 134/200\n",
      "252/252 [==============================] - 0s 953us/step - loss: 0.6905 - accuracy: 0.7033\n",
      "Epoch 135/200\n",
      "252/252 [==============================] - 0s 931us/step - loss: 0.6942 - accuracy: 0.6884\n",
      "Epoch 136/200\n",
      "252/252 [==============================] - 0s 951us/step - loss: 0.6632 - accuracy: 0.7012\n",
      "Epoch 137/200\n",
      "252/252 [==============================] - 0s 947us/step - loss: 0.6801 - accuracy: 0.7027\n",
      "Epoch 138/200\n",
      "252/252 [==============================] - 0s 940us/step - loss: 0.6856 - accuracy: 0.7017\n",
      "Epoch 139/200\n",
      "252/252 [==============================] - 0s 945us/step - loss: 0.6715 - accuracy: 0.7078\n",
      "Epoch 140/200\n",
      "252/252 [==============================] - 0s 940us/step - loss: 0.6784 - accuracy: 0.7010\n",
      "Epoch 141/200\n",
      "252/252 [==============================] - 0s 947us/step - loss: 0.6941 - accuracy: 0.6899\n",
      "Epoch 142/200\n",
      "252/252 [==============================] - 0s 987us/step - loss: 0.6700 - accuracy: 0.7066\n",
      "Epoch 143/200\n",
      "252/252 [==============================] - 0s 971us/step - loss: 0.6866 - accuracy: 0.6955\n",
      "Epoch 144/200\n",
      "252/252 [==============================] - 0s 947us/step - loss: 0.6867 - accuracy: 0.6979\n",
      "Epoch 145/200\n",
      "252/252 [==============================] - 0s 931us/step - loss: 0.6861 - accuracy: 0.7005\n",
      "Epoch 146/200\n",
      "252/252 [==============================] - 0s 945us/step - loss: 0.6707 - accuracy: 0.7074\n",
      "Epoch 147/200\n",
      "252/252 [==============================] - 0s 933us/step - loss: 0.6866 - accuracy: 0.6905\n",
      "Epoch 148/200\n",
      "252/252 [==============================] - 0s 940us/step - loss: 0.6792 - accuracy: 0.7036\n",
      "Epoch 149/200\n",
      "252/252 [==============================] - 0s 928us/step - loss: 0.7015 - accuracy: 0.6817\n",
      "Epoch 150/200\n",
      "252/252 [==============================] - 0s 921us/step - loss: 0.7092 - accuracy: 0.6782\n",
      "Epoch 151/200\n",
      "252/252 [==============================] - 0s 927us/step - loss: 0.6898 - accuracy: 0.6906\n",
      "Epoch 152/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.6958\n",
      "Epoch 153/200\n",
      "252/252 [==============================] - 0s 989us/step - loss: 0.7042 - accuracy: 0.6774\n",
      "Epoch 154/200\n",
      "252/252 [==============================] - 0s 941us/step - loss: 0.6759 - accuracy: 0.6987\n",
      "Epoch 155/200\n",
      "252/252 [==============================] - 0s 945us/step - loss: 0.6685 - accuracy: 0.7088\n",
      "Epoch 156/200\n",
      "252/252 [==============================] - 0s 942us/step - loss: 0.6760 - accuracy: 0.7076\n",
      "Epoch 157/200\n",
      "252/252 [==============================] - 0s 959us/step - loss: 0.6882 - accuracy: 0.6973\n",
      "Epoch 158/200\n",
      "252/252 [==============================] - 0s 935us/step - loss: 0.6753 - accuracy: 0.7059\n",
      "Epoch 159/200\n",
      "252/252 [==============================] - 0s 954us/step - loss: 0.6887 - accuracy: 0.6967\n",
      "Epoch 160/200\n",
      "252/252 [==============================] - 0s 948us/step - loss: 0.6879 - accuracy: 0.6941\n",
      "Epoch 161/200\n",
      "252/252 [==============================] - 0s 975us/step - loss: 0.6705 - accuracy: 0.7050\n",
      "Epoch 162/200\n",
      "252/252 [==============================] - 0s 950us/step - loss: 0.6769 - accuracy: 0.7055\n",
      "Epoch 163/200\n",
      "252/252 [==============================] - 0s 948us/step - loss: 0.6810 - accuracy: 0.6963\n",
      "Epoch 164/200\n",
      "252/252 [==============================] - 0s 951us/step - loss: 0.6819 - accuracy: 0.6947\n",
      "Epoch 165/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.6883\n",
      "Epoch 166/200\n",
      "252/252 [==============================] - 0s 945us/step - loss: 0.6799 - accuracy: 0.6949\n",
      "Epoch 167/200\n",
      "252/252 [==============================] - 0s 932us/step - loss: 0.6776 - accuracy: 0.6954\n",
      "Epoch 168/200\n",
      "252/252 [==============================] - 0s 921us/step - loss: 0.6816 - accuracy: 0.7030\n",
      "Epoch 169/200\n",
      "252/252 [==============================] - 0s 945us/step - loss: 0.6639 - accuracy: 0.7101\n",
      "Epoch 170/200\n",
      "252/252 [==============================] - 0s 939us/step - loss: 0.7022 - accuracy: 0.6911\n",
      "Epoch 171/200\n",
      "252/252 [==============================] - 0s 966us/step - loss: 0.6741 - accuracy: 0.6977\n",
      "Epoch 172/200\n",
      "252/252 [==============================] - 0s 934us/step - loss: 0.6730 - accuracy: 0.7041\n",
      "Epoch 173/200\n",
      "252/252 [==============================] - 0s 957us/step - loss: 0.6699 - accuracy: 0.6995\n",
      "Epoch 174/200\n",
      "252/252 [==============================] - 0s 939us/step - loss: 0.6968 - accuracy: 0.6903\n",
      "Epoch 175/200\n",
      "252/252 [==============================] - 0s 941us/step - loss: 0.6822 - accuracy: 0.6967\n",
      "Epoch 176/200\n",
      "252/252 [==============================] - 0s 945us/step - loss: 0.6842 - accuracy: 0.6967\n",
      "Epoch 177/200\n",
      "252/252 [==============================] - 0s 931us/step - loss: 0.6696 - accuracy: 0.7110\n",
      "Epoch 178/200\n",
      "252/252 [==============================] - 0s 953us/step - loss: 0.6693 - accuracy: 0.7015\n",
      "Epoch 179/200\n",
      "252/252 [==============================] - 0s 936us/step - loss: 0.6592 - accuracy: 0.7093\n",
      "Epoch 180/200\n",
      "252/252 [==============================] - 0s 955us/step - loss: 0.6867 - accuracy: 0.6938\n",
      "Epoch 181/200\n",
      "252/252 [==============================] - 0s 935us/step - loss: 0.6936 - accuracy: 0.6896\n",
      "Epoch 182/200\n",
      "252/252 [==============================] - 0s 941us/step - loss: 0.6801 - accuracy: 0.6938\n",
      "Epoch 183/200\n",
      "252/252 [==============================] - 0s 966us/step - loss: 0.6817 - accuracy: 0.6910\n",
      "Epoch 184/200\n",
      "252/252 [==============================] - 0s 981us/step - loss: 0.6800 - accuracy: 0.7042\n",
      "Epoch 185/200\n",
      "252/252 [==============================] - 0s 969us/step - loss: 0.6755 - accuracy: 0.7079\n",
      "Epoch 186/200\n",
      "252/252 [==============================] - 0s 953us/step - loss: 0.6815 - accuracy: 0.7011\n",
      "Epoch 187/200\n",
      "252/252 [==============================] - 0s 926us/step - loss: 0.6907 - accuracy: 0.6979\n",
      "Epoch 188/200\n",
      "252/252 [==============================] - 0s 937us/step - loss: 0.6781 - accuracy: 0.6989\n",
      "Epoch 189/200\n",
      "252/252 [==============================] - 0s 936us/step - loss: 0.6899 - accuracy: 0.6972\n",
      "Epoch 190/200\n",
      "252/252 [==============================] - 0s 930us/step - loss: 0.6806 - accuracy: 0.7018\n",
      "Epoch 191/200\n",
      "252/252 [==============================] - 0s 944us/step - loss: 0.6619 - accuracy: 0.7143\n",
      "Epoch 192/200\n",
      "252/252 [==============================] - 0s 924us/step - loss: 0.6930 - accuracy: 0.6928\n",
      "Epoch 193/200\n",
      "252/252 [==============================] - 0s 959us/step - loss: 0.6668 - accuracy: 0.7062\n",
      "Epoch 194/200\n",
      "252/252 [==============================] - 0s 979us/step - loss: 0.6751 - accuracy: 0.7006\n",
      "Epoch 195/200\n",
      "252/252 [==============================] - 0s 990us/step - loss: 0.6772 - accuracy: 0.7023\n",
      "Epoch 196/200\n",
      "252/252 [==============================] - 0s 971us/step - loss: 0.6855 - accuracy: 0.6945\n",
      "Epoch 197/200\n",
      "252/252 [==============================] - 0s 947us/step - loss: 0.6896 - accuracy: 0.6954\n",
      "Epoch 198/200\n",
      "252/252 [==============================] - 0s 978us/step - loss: 0.6599 - accuracy: 0.7124\n",
      "Epoch 199/200\n",
      "252/252 [==============================] - 0s 955us/step - loss: 0.6623 - accuracy: 0.7061\n",
      "Epoch 200/200\n",
      "252/252 [==============================] - 0s 948us/step - loss: 0.6836 - accuracy: 0.7014\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 950us/step - loss: 0.8036 - accuracy: 0.6289\n",
      "Acc:\n",
      "0.6288873553276062\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Acc:')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_222\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_666 (Dense)            (None, 14)                266       \n",
      "_________________________________________________________________\n",
      "dense_667 (Dense)            (None, 8)                 120       \n",
      "_________________________________________________________________\n",
      "dense_668 (Dense)            (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 413\n",
      "Trainable params: 413\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu', input_shape=(18,)))\n",
    "model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "252/252 [==============================] - 1s 979us/step - loss: 1.0216 - accuracy: 0.5143\n",
      "Epoch 2/200\n",
      "252/252 [==============================] - 0s 996us/step - loss: 0.7600 - accuracy: 0.6464\n",
      "Epoch 3/200\n",
      "252/252 [==============================] - 0s 988us/step - loss: 0.7382 - accuracy: 0.6500\n",
      "Epoch 4/200\n",
      "252/252 [==============================] - 0s 999us/step - loss: 0.7286 - accuracy: 0.6657\n",
      "Epoch 5/200\n",
      "252/252 [==============================] - 0s 947us/step - loss: 0.7420 - accuracy: 0.6562\n",
      "Epoch 6/200\n",
      "252/252 [==============================] - 0s 964us/step - loss: 0.7406 - accuracy: 0.6527\n",
      "Epoch 7/200\n",
      "252/252 [==============================] - 0s 949us/step - loss: 0.7283 - accuracy: 0.6546\n",
      "Epoch 8/200\n",
      "252/252 [==============================] - 0s 948us/step - loss: 0.7088 - accuracy: 0.6763\n",
      "Epoch 9/200\n",
      "252/252 [==============================] - 0s 964us/step - loss: 0.7253 - accuracy: 0.6592\n",
      "Epoch 10/200\n",
      "252/252 [==============================] - 0s 961us/step - loss: 0.7231 - accuracy: 0.6706\n",
      "Epoch 11/200\n",
      "252/252 [==============================] - 0s 977us/step - loss: 0.7190 - accuracy: 0.6680\n",
      "Epoch 12/200\n",
      "252/252 [==============================] - 0s 967us/step - loss: 0.7179 - accuracy: 0.6665\n",
      "Epoch 13/200\n",
      "252/252 [==============================] - 0s 974us/step - loss: 0.7147 - accuracy: 0.6733\n",
      "Epoch 14/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7168 - accuracy: 0.6724\n",
      "Epoch 15/200\n",
      "252/252 [==============================] - 0s 951us/step - loss: 0.7150 - accuracy: 0.6738\n",
      "Epoch 16/200\n",
      "252/252 [==============================] - 0s 965us/step - loss: 0.7081 - accuracy: 0.6681\n",
      "Epoch 17/200\n",
      "252/252 [==============================] - 0s 950us/step - loss: 0.7161 - accuracy: 0.6820\n",
      "Epoch 18/200\n",
      "252/252 [==============================] - 0s 957us/step - loss: 0.7228 - accuracy: 0.6729\n",
      "Epoch 19/200\n",
      "252/252 [==============================] - 0s 962us/step - loss: 0.7098 - accuracy: 0.6775\n",
      "Epoch 20/200\n",
      "252/252 [==============================] - 0s 944us/step - loss: 0.7185 - accuracy: 0.6685\n",
      "Epoch 21/200\n",
      "252/252 [==============================] - 0s 957us/step - loss: 0.7190 - accuracy: 0.6707\n",
      "Epoch 22/200\n",
      "252/252 [==============================] - 0s 974us/step - loss: 0.7079 - accuracy: 0.6852\n",
      "Epoch 23/200\n",
      "252/252 [==============================] - 0s 957us/step - loss: 0.6980 - accuracy: 0.6891\n",
      "Epoch 24/200\n",
      "252/252 [==============================] - 0s 944us/step - loss: 0.7131 - accuracy: 0.6887\n",
      "Epoch 25/200\n",
      "252/252 [==============================] - 0s 946us/step - loss: 0.7043 - accuracy: 0.6857\n",
      "Epoch 26/200\n",
      "252/252 [==============================] - 0s 967us/step - loss: 0.7005 - accuracy: 0.6896\n",
      "Epoch 27/200\n",
      "252/252 [==============================] - 0s 942us/step - loss: 0.6978 - accuracy: 0.6917\n",
      "Epoch 28/200\n",
      "252/252 [==============================] - 0s 948us/step - loss: 0.6948 - accuracy: 0.6885\n",
      "Epoch 29/200\n",
      "252/252 [==============================] - 0s 953us/step - loss: 0.7084 - accuracy: 0.6847\n",
      "Epoch 30/200\n",
      "252/252 [==============================] - 0s 954us/step - loss: 0.7129 - accuracy: 0.6857\n",
      "Epoch 31/200\n",
      "252/252 [==============================] - 0s 990us/step - loss: 0.6984 - accuracy: 0.6970\n",
      "Epoch 32/200\n",
      "252/252 [==============================] - 0s 962us/step - loss: 0.7002 - accuracy: 0.6940\n",
      "Epoch 33/200\n",
      "252/252 [==============================] - 0s 967us/step - loss: 0.7008 - accuracy: 0.6893\n",
      "Epoch 34/200\n",
      "252/252 [==============================] - 0s 958us/step - loss: 0.7053 - accuracy: 0.6827\n",
      "Epoch 35/200\n",
      "252/252 [==============================] - 0s 946us/step - loss: 0.6982 - accuracy: 0.6940\n",
      "Epoch 36/200\n",
      "252/252 [==============================] - 0s 942us/step - loss: 0.7059 - accuracy: 0.6853\n",
      "Epoch 37/200\n",
      "252/252 [==============================] - 0s 942us/step - loss: 0.6902 - accuracy: 0.6959\n",
      "Epoch 38/200\n",
      "252/252 [==============================] - 0s 970us/step - loss: 0.7139 - accuracy: 0.6945\n",
      "Epoch 39/200\n",
      "252/252 [==============================] - 0s 937us/step - loss: 0.6920 - accuracy: 0.7099\n",
      "Epoch 40/200\n",
      "252/252 [==============================] - 0s 954us/step - loss: 0.7014 - accuracy: 0.6934\n",
      "Epoch 41/200\n",
      "252/252 [==============================] - 0s 949us/step - loss: 0.6836 - accuracy: 0.7045\n",
      "Epoch 42/200\n",
      "252/252 [==============================] - 0s 954us/step - loss: 0.7061 - accuracy: 0.6895\n",
      "Epoch 43/200\n",
      "252/252 [==============================] - 0s 951us/step - loss: 0.6829 - accuracy: 0.7026\n",
      "Epoch 44/200\n",
      "252/252 [==============================] - 0s 956us/step - loss: 0.6933 - accuracy: 0.6919\n",
      "Epoch 45/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6962 - accuracy: 0.6951\n",
      "Epoch 46/200\n",
      "252/252 [==============================] - 0s 942us/step - loss: 0.7051 - accuracy: 0.7017\n",
      "Epoch 47/200\n",
      "252/252 [==============================] - 0s 953us/step - loss: 0.7027 - accuracy: 0.6935\n",
      "Epoch 48/200\n",
      "252/252 [==============================] - 0s 945us/step - loss: 0.6968 - accuracy: 0.6976\n",
      "Epoch 49/200\n",
      "252/252 [==============================] - 0s 946us/step - loss: 0.6734 - accuracy: 0.7131\n",
      "Epoch 50/200\n",
      "252/252 [==============================] - 0s 937us/step - loss: 0.6982 - accuracy: 0.6919\n",
      "Epoch 51/200\n",
      "252/252 [==============================] - 0s 968us/step - loss: 0.6906 - accuracy: 0.7049\n",
      "Epoch 52/200\n",
      "252/252 [==============================] - 0s 939us/step - loss: 0.6939 - accuracy: 0.7001\n",
      "Epoch 53/200\n",
      "252/252 [==============================] - 0s 950us/step - loss: 0.6912 - accuracy: 0.6965\n",
      "Epoch 54/200\n",
      "252/252 [==============================] - 0s 945us/step - loss: 0.7148 - accuracy: 0.6905\n",
      "Epoch 55/200\n",
      "252/252 [==============================] - 0s 949us/step - loss: 0.6806 - accuracy: 0.7042\n",
      "Epoch 56/200\n",
      "252/252 [==============================] - 0s 968us/step - loss: 0.6903 - accuracy: 0.7038\n",
      "Epoch 57/200\n",
      "252/252 [==============================] - 0s 938us/step - loss: 0.7112 - accuracy: 0.6912\n",
      "Epoch 58/200\n",
      "252/252 [==============================] - 0s 946us/step - loss: 0.6896 - accuracy: 0.6949\n",
      "Epoch 59/200\n",
      "252/252 [==============================] - 0s 973us/step - loss: 0.7135 - accuracy: 0.6829\n",
      "Epoch 60/200\n",
      "252/252 [==============================] - 0s 971us/step - loss: 0.6954 - accuracy: 0.6939\n",
      "Epoch 61/200\n",
      "252/252 [==============================] - 0s 939us/step - loss: 0.6794 - accuracy: 0.7085\n",
      "Epoch 62/200\n",
      "252/252 [==============================] - 0s 943us/step - loss: 0.6881 - accuracy: 0.6950\n",
      "Epoch 63/200\n",
      "252/252 [==============================] - 0s 972us/step - loss: 0.6805 - accuracy: 0.7111\n",
      "Epoch 64/200\n",
      "252/252 [==============================] - 0s 946us/step - loss: 0.6901 - accuracy: 0.7008\n",
      "Epoch 65/200\n",
      "252/252 [==============================] - 0s 936us/step - loss: 0.6950 - accuracy: 0.6964\n",
      "Epoch 66/200\n",
      "252/252 [==============================] - 0s 944us/step - loss: 0.7016 - accuracy: 0.6960\n",
      "Epoch 67/200\n",
      "252/252 [==============================] - 0s 953us/step - loss: 0.6924 - accuracy: 0.7026\n",
      "Epoch 68/200\n",
      "252/252 [==============================] - 0s 933us/step - loss: 0.6883 - accuracy: 0.7069\n",
      "Epoch 69/200\n",
      "252/252 [==============================] - 0s 961us/step - loss: 0.7054 - accuracy: 0.6906\n",
      "Epoch 70/200\n",
      "252/252 [==============================] - 0s 963us/step - loss: 0.6885 - accuracy: 0.6951\n",
      "Epoch 71/200\n",
      "252/252 [==============================] - 0s 953us/step - loss: 0.6869 - accuracy: 0.6966\n",
      "Epoch 72/200\n",
      "252/252 [==============================] - 0s 956us/step - loss: 0.6985 - accuracy: 0.6909\n",
      "Epoch 73/200\n",
      "252/252 [==============================] - 0s 993us/step - loss: 0.7032 - accuracy: 0.6930\n",
      "Epoch 74/200\n",
      "252/252 [==============================] - 0s 972us/step - loss: 0.6881 - accuracy: 0.6914\n",
      "Epoch 75/200\n",
      "252/252 [==============================] - 0s 975us/step - loss: 0.7093 - accuracy: 0.6850\n",
      "Epoch 76/200\n",
      "252/252 [==============================] - 0s 948us/step - loss: 0.6835 - accuracy: 0.7009\n",
      "Epoch 77/200\n",
      "252/252 [==============================] - 0s 953us/step - loss: 0.6868 - accuracy: 0.6980\n",
      "Epoch 78/200\n",
      "252/252 [==============================] - 0s 944us/step - loss: 0.6801 - accuracy: 0.7046\n",
      "Epoch 79/200\n",
      "252/252 [==============================] - 0s 956us/step - loss: 0.6958 - accuracy: 0.6952\n",
      "Epoch 80/200\n",
      "252/252 [==============================] - 0s 961us/step - loss: 0.6907 - accuracy: 0.6988\n",
      "Epoch 81/200\n",
      "252/252 [==============================] - 0s 947us/step - loss: 0.6914 - accuracy: 0.6936\n",
      "Epoch 82/200\n",
      "252/252 [==============================] - 0s 947us/step - loss: 0.6776 - accuracy: 0.6980\n",
      "Epoch 83/200\n",
      "252/252 [==============================] - 0s 957us/step - loss: 0.6952 - accuracy: 0.6971\n",
      "Epoch 84/200\n",
      "252/252 [==============================] - 0s 966us/step - loss: 0.6980 - accuracy: 0.6899\n",
      "Epoch 85/200\n",
      "252/252 [==============================] - 0s 944us/step - loss: 0.6785 - accuracy: 0.7139\n",
      "Epoch 86/200\n",
      "252/252 [==============================] - 0s 963us/step - loss: 0.6945 - accuracy: 0.7026\n",
      "Epoch 87/200\n",
      "252/252 [==============================] - 0s 980us/step - loss: 0.6859 - accuracy: 0.7063\n",
      "Epoch 88/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6787 - accuracy: 0.7063\n",
      "Epoch 89/200\n",
      "252/252 [==============================] - 0s 970us/step - loss: 0.6979 - accuracy: 0.7023\n",
      "Epoch 90/200\n",
      "252/252 [==============================] - 0s 987us/step - loss: 0.6863 - accuracy: 0.6982\n",
      "Epoch 91/200\n",
      "252/252 [==============================] - 0s 953us/step - loss: 0.6874 - accuracy: 0.6973\n",
      "Epoch 92/200\n",
      "252/252 [==============================] - 0s 966us/step - loss: 0.6761 - accuracy: 0.7108\n",
      "Epoch 93/200\n",
      "252/252 [==============================] - 0s 958us/step - loss: 0.6715 - accuracy: 0.7097\n",
      "Epoch 94/200\n",
      "252/252 [==============================] - 0s 955us/step - loss: 0.6930 - accuracy: 0.7006\n",
      "Epoch 95/200\n",
      "252/252 [==============================] - 0s 969us/step - loss: 0.6827 - accuracy: 0.6967\n",
      "Epoch 96/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.7039\n",
      "Epoch 97/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.6969\n",
      "Epoch 98/200\n",
      "252/252 [==============================] - 0s 940us/step - loss: 0.6611 - accuracy: 0.7123\n",
      "Epoch 99/200\n",
      "252/252 [==============================] - 0s 973us/step - loss: 0.7060 - accuracy: 0.6900\n",
      "Epoch 100/200\n",
      "252/252 [==============================] - 0s 991us/step - loss: 0.6711 - accuracy: 0.7104\n",
      "Epoch 101/200\n",
      "252/252 [==============================] - 0s 995us/step - loss: 0.6783 - accuracy: 0.7061\n",
      "Epoch 102/200\n",
      "252/252 [==============================] - 0s 988us/step - loss: 0.6814 - accuracy: 0.7114\n",
      "Epoch 103/200\n",
      "252/252 [==============================] - 0s 953us/step - loss: 0.6747 - accuracy: 0.7088\n",
      "Epoch 104/200\n",
      "252/252 [==============================] - 0s 940us/step - loss: 0.6819 - accuracy: 0.7020\n",
      "Epoch 105/200\n",
      "252/252 [==============================] - 0s 968us/step - loss: 0.6818 - accuracy: 0.7081\n",
      "Epoch 106/200\n",
      "252/252 [==============================] - 0s 954us/step - loss: 0.6708 - accuracy: 0.7092\n",
      "Epoch 107/200\n",
      "252/252 [==============================] - 0s 949us/step - loss: 0.6684 - accuracy: 0.7081\n",
      "Epoch 108/200\n",
      "252/252 [==============================] - 0s 954us/step - loss: 0.6693 - accuracy: 0.7119\n",
      "Epoch 109/200\n",
      "252/252 [==============================] - 0s 942us/step - loss: 0.6964 - accuracy: 0.7054\n",
      "Epoch 110/200\n",
      "252/252 [==============================] - 0s 944us/step - loss: 0.6877 - accuracy: 0.6934\n",
      "Epoch 111/200\n",
      "252/252 [==============================] - 0s 961us/step - loss: 0.6987 - accuracy: 0.6919\n",
      "Epoch 112/200\n",
      "252/252 [==============================] - 0s 956us/step - loss: 0.6844 - accuracy: 0.7045\n",
      "Epoch 113/200\n",
      "252/252 [==============================] - 0s 955us/step - loss: 0.6715 - accuracy: 0.7082\n",
      "Epoch 114/200\n",
      "252/252 [==============================] - 0s 991us/step - loss: 0.6673 - accuracy: 0.7098\n",
      "Epoch 115/200\n",
      "252/252 [==============================] - 0s 935us/step - loss: 0.6829 - accuracy: 0.7038\n",
      "Epoch 116/200\n",
      "252/252 [==============================] - 0s 943us/step - loss: 0.6880 - accuracy: 0.6982\n",
      "Epoch 117/200\n",
      "252/252 [==============================] - 0s 967us/step - loss: 0.6785 - accuracy: 0.7054\n",
      "Epoch 118/200\n",
      "252/252 [==============================] - 0s 939us/step - loss: 0.6955 - accuracy: 0.6888\n",
      "Epoch 119/200\n",
      "252/252 [==============================] - 0s 946us/step - loss: 0.6938 - accuracy: 0.7014\n",
      "Epoch 120/200\n",
      "252/252 [==============================] - 0s 959us/step - loss: 0.6907 - accuracy: 0.7054\n",
      "Epoch 121/200\n",
      "252/252 [==============================] - 0s 940us/step - loss: 0.6789 - accuracy: 0.7042\n",
      "Epoch 122/200\n",
      "252/252 [==============================] - 0s 941us/step - loss: 0.6923 - accuracy: 0.7012\n",
      "Epoch 123/200\n",
      "252/252 [==============================] - 0s 945us/step - loss: 0.6815 - accuracy: 0.7055\n",
      "Epoch 124/200\n",
      "252/252 [==============================] - 0s 965us/step - loss: 0.6911 - accuracy: 0.6951\n",
      "Epoch 125/200\n",
      "252/252 [==============================] - 0s 952us/step - loss: 0.6943 - accuracy: 0.6981\n",
      "Epoch 126/200\n",
      "252/252 [==============================] - 0s 962us/step - loss: 0.6873 - accuracy: 0.7029\n",
      "Epoch 127/200\n",
      "252/252 [==============================] - 0s 959us/step - loss: 0.6951 - accuracy: 0.6926\n",
      "Epoch 128/200\n",
      "252/252 [==============================] - 0s 976us/step - loss: 0.6927 - accuracy: 0.7007\n",
      "Epoch 129/200\n",
      "252/252 [==============================] - 0s 1000us/step - loss: 0.6748 - accuracy: 0.7081\n",
      "Epoch 130/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6733 - accuracy: 0.7055\n",
      "Epoch 131/200\n",
      "252/252 [==============================] - 0s 949us/step - loss: 0.6641 - accuracy: 0.7159\n",
      "Epoch 132/200\n",
      "252/252 [==============================] - 0s 952us/step - loss: 0.6765 - accuracy: 0.7074\n",
      "Epoch 133/200\n",
      "252/252 [==============================] - 0s 948us/step - loss: 0.6797 - accuracy: 0.7058\n",
      "Epoch 134/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6688 - accuracy: 0.7097\n",
      "Epoch 135/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.6923\n",
      "Epoch 136/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.7006\n",
      "Epoch 137/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.6989\n",
      "Epoch 138/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6780 - accuracy: 0.7047\n",
      "Epoch 139/200\n",
      "252/252 [==============================] - 0s 943us/step - loss: 0.6815 - accuracy: 0.7030\n",
      "Epoch 140/200\n",
      "252/252 [==============================] - 0s 936us/step - loss: 0.6902 - accuracy: 0.7043\n",
      "Epoch 141/200\n",
      "252/252 [==============================] - 0s 964us/step - loss: 0.6831 - accuracy: 0.7015\n",
      "Epoch 142/200\n",
      "252/252 [==============================] - 0s 949us/step - loss: 0.6717 - accuracy: 0.7029\n",
      "Epoch 143/200\n",
      "252/252 [==============================] - 0s 947us/step - loss: 0.6825 - accuracy: 0.7033\n",
      "Epoch 144/200\n",
      "252/252 [==============================] - 0s 938us/step - loss: 0.6850 - accuracy: 0.7008\n",
      "Epoch 145/200\n",
      "252/252 [==============================] - 0s 955us/step - loss: 0.6625 - accuracy: 0.7081\n",
      "Epoch 146/200\n",
      "252/252 [==============================] - 0s 955us/step - loss: 0.6663 - accuracy: 0.7103\n",
      "Epoch 147/200\n",
      "252/252 [==============================] - 0s 968us/step - loss: 0.6896 - accuracy: 0.6993\n",
      "Epoch 148/200\n",
      "252/252 [==============================] - 0s 932us/step - loss: 0.6649 - accuracy: 0.7097\n",
      "Epoch 149/200\n",
      "252/252 [==============================] - 0s 962us/step - loss: 0.6876 - accuracy: 0.7084\n",
      "Epoch 150/200\n",
      "252/252 [==============================] - 0s 953us/step - loss: 0.6857 - accuracy: 0.7030\n",
      "Epoch 151/200\n",
      "252/252 [==============================] - 0s 955us/step - loss: 0.6827 - accuracy: 0.7038\n",
      "Epoch 152/200\n",
      "252/252 [==============================] - 0s 958us/step - loss: 0.6901 - accuracy: 0.6967\n",
      "Epoch 153/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6711 - accuracy: 0.7109\n",
      "Epoch 154/200\n",
      "252/252 [==============================] - 0s 962us/step - loss: 0.6621 - accuracy: 0.7138\n",
      "Epoch 155/200\n",
      "252/252 [==============================] - 0s 987us/step - loss: 0.6646 - accuracy: 0.7100\n",
      "Epoch 156/200\n",
      "252/252 [==============================] - 0s 947us/step - loss: 0.6832 - accuracy: 0.7114\n",
      "Epoch 157/200\n",
      "252/252 [==============================] - 0s 954us/step - loss: 0.6553 - accuracy: 0.7147\n",
      "Epoch 158/200\n",
      "252/252 [==============================] - 0s 949us/step - loss: 0.6824 - accuracy: 0.7025\n",
      "Epoch 159/200\n",
      "252/252 [==============================] - 0s 966us/step - loss: 0.6730 - accuracy: 0.7019\n",
      "Epoch 160/200\n",
      "252/252 [==============================] - 0s 948us/step - loss: 0.6692 - accuracy: 0.7101\n",
      "Epoch 161/200\n",
      "252/252 [==============================] - 0s 975us/step - loss: 0.6801 - accuracy: 0.7045\n",
      "Epoch 162/200\n",
      "252/252 [==============================] - 0s 949us/step - loss: 0.6852 - accuracy: 0.6992\n",
      "Epoch 163/200\n",
      "252/252 [==============================] - 0s 952us/step - loss: 0.6769 - accuracy: 0.7055\n",
      "Epoch 164/200\n",
      "252/252 [==============================] - 0s 940us/step - loss: 0.6903 - accuracy: 0.6992\n",
      "Epoch 165/200\n",
      "252/252 [==============================] - 0s 947us/step - loss: 0.6739 - accuracy: 0.6981\n",
      "Epoch 166/200\n",
      "252/252 [==============================] - 0s 950us/step - loss: 0.6684 - accuracy: 0.7146\n",
      "Epoch 167/200\n",
      "252/252 [==============================] - 0s 963us/step - loss: 0.6904 - accuracy: 0.6969\n",
      "Epoch 168/200\n",
      "252/252 [==============================] - 0s 956us/step - loss: 0.6799 - accuracy: 0.7008\n",
      "Epoch 169/200\n",
      "252/252 [==============================] - 0s 958us/step - loss: 0.6839 - accuracy: 0.7020\n",
      "Epoch 170/200\n",
      "252/252 [==============================] - 0s 994us/step - loss: 0.6773 - accuracy: 0.6987\n",
      "Epoch 171/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6661 - accuracy: 0.7123\n",
      "Epoch 172/200\n",
      "252/252 [==============================] - 0s 974us/step - loss: 0.6606 - accuracy: 0.7122\n",
      "Epoch 173/200\n",
      "252/252 [==============================] - 0s 959us/step - loss: 0.6792 - accuracy: 0.6979\n",
      "Epoch 174/200\n",
      "252/252 [==============================] - 0s 961us/step - loss: 0.6784 - accuracy: 0.6996\n",
      "Epoch 175/200\n",
      "252/252 [==============================] - 0s 961us/step - loss: 0.6642 - accuracy: 0.7110\n",
      "Epoch 176/200\n",
      "252/252 [==============================] - 0s 950us/step - loss: 0.6793 - accuracy: 0.7130\n",
      "Epoch 177/200\n",
      "252/252 [==============================] - 0s 956us/step - loss: 0.6774 - accuracy: 0.7029\n",
      "Epoch 178/200\n",
      "252/252 [==============================] - 0s 959us/step - loss: 0.6696 - accuracy: 0.7067\n",
      "Epoch 179/200\n",
      "252/252 [==============================] - 0s 951us/step - loss: 0.6728 - accuracy: 0.7082\n",
      "Epoch 180/200\n",
      "252/252 [==============================] - 0s 957us/step - loss: 0.6947 - accuracy: 0.6983\n",
      "Epoch 181/200\n",
      "252/252 [==============================] - 0s 947us/step - loss: 0.6723 - accuracy: 0.7068\n",
      "Epoch 182/200\n",
      "252/252 [==============================] - 0s 954us/step - loss: 0.6807 - accuracy: 0.6995\n",
      "Epoch 183/200\n",
      "252/252 [==============================] - 0s 951us/step - loss: 0.7010 - accuracy: 0.6950\n",
      "Epoch 184/200\n",
      "252/252 [==============================] - 0s 975us/step - loss: 0.6658 - accuracy: 0.7159\n",
      "Epoch 185/200\n",
      "252/252 [==============================] - 0s 947us/step - loss: 0.6760 - accuracy: 0.6997\n",
      "Epoch 186/200\n",
      "252/252 [==============================] - 0s 946us/step - loss: 0.6946 - accuracy: 0.7006\n",
      "Epoch 187/200\n",
      "252/252 [==============================] - 0s 959us/step - loss: 0.6851 - accuracy: 0.7053\n",
      "Epoch 188/200\n",
      "252/252 [==============================] - 0s 955us/step - loss: 0.6916 - accuracy: 0.6917\n",
      "Epoch 189/200\n",
      "252/252 [==============================] - 0s 955us/step - loss: 0.6776 - accuracy: 0.7090\n",
      "Epoch 190/200\n",
      "252/252 [==============================] - 0s 951us/step - loss: 0.6946 - accuracy: 0.6992\n",
      "Epoch 191/200\n",
      "252/252 [==============================] - 0s 954us/step - loss: 0.6721 - accuracy: 0.7096\n",
      "Epoch 192/200\n",
      "252/252 [==============================] - 0s 938us/step - loss: 0.6736 - accuracy: 0.7117\n",
      "Epoch 193/200\n",
      "252/252 [==============================] - 0s 948us/step - loss: 0.6739 - accuracy: 0.7136\n",
      "Epoch 194/200\n",
      "252/252 [==============================] - 0s 949us/step - loss: 0.6768 - accuracy: 0.6967\n",
      "Epoch 195/200\n",
      "252/252 [==============================] - 0s 954us/step - loss: 0.6853 - accuracy: 0.7010\n",
      "Epoch 196/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6741 - accuracy: 0.7019\n",
      "Epoch 197/200\n",
      "252/252 [==============================] - 0s 976us/step - loss: 0.6748 - accuracy: 0.7059\n",
      "Epoch 198/200\n",
      "252/252 [==============================] - 0s 994us/step - loss: 0.7019 - accuracy: 0.6950\n",
      "Epoch 199/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.6993\n",
      "Epoch 200/200\n",
      "252/252 [==============================] - 0s 993us/step - loss: 0.6701 - accuracy: 0.7143\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 857us/step - loss: 0.8117 - accuracy: 0.6296\n",
      "Acc:\n",
      "0.6295784115791321\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Acc:')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_223\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_669 (Dense)            (None, 10)                190       \n",
      "_________________________________________________________________\n",
      "dense_670 (Dense)            (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_671 (Dense)            (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 305\n",
      "Trainable params: 305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(10, kernel_initializer='normal', activation='relu', input_shape=(18,)))\n",
    "model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "252/252 [==============================] - 1s 1ms/step - loss: 1.0382 - accuracy: 0.4988\n",
      "Epoch 2/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7851 - accuracy: 0.6583\n",
      "Epoch 3/200\n",
      "252/252 [==============================] - 0s 983us/step - loss: 0.7550 - accuracy: 0.6451\n",
      "Epoch 4/200\n",
      "252/252 [==============================] - 0s 947us/step - loss: 0.7384 - accuracy: 0.6594\n",
      "Epoch 5/200\n",
      "252/252 [==============================] - 0s 940us/step - loss: 0.7302 - accuracy: 0.6568\n",
      "Epoch 6/200\n",
      "252/252 [==============================] - 0s 965us/step - loss: 0.7326 - accuracy: 0.6609\n",
      "Epoch 7/200\n",
      "252/252 [==============================] - 0s 950us/step - loss: 0.7193 - accuracy: 0.6638\n",
      "Epoch 8/200\n",
      "252/252 [==============================] - 0s 946us/step - loss: 0.7252 - accuracy: 0.6616\n",
      "Epoch 9/200\n",
      "252/252 [==============================] - 0s 947us/step - loss: 0.7246 - accuracy: 0.6647\n",
      "Epoch 10/200\n",
      "252/252 [==============================] - 0s 970us/step - loss: 0.7301 - accuracy: 0.6614\n",
      "Epoch 11/200\n",
      "252/252 [==============================] - 0s 954us/step - loss: 0.7253 - accuracy: 0.6628\n",
      "Epoch 12/200\n",
      "252/252 [==============================] - 0s 955us/step - loss: 0.7222 - accuracy: 0.6710\n",
      "Epoch 13/200\n",
      "252/252 [==============================] - 0s 998us/step - loss: 0.7060 - accuracy: 0.6717\n",
      "Epoch 14/200\n",
      "252/252 [==============================] - 0s 972us/step - loss: 0.7238 - accuracy: 0.6678\n",
      "Epoch 15/200\n",
      "252/252 [==============================] - 0s 944us/step - loss: 0.7229 - accuracy: 0.6700\n",
      "Epoch 16/200\n",
      "252/252 [==============================] - 0s 948us/step - loss: 0.7203 - accuracy: 0.6723\n",
      "Epoch 17/200\n",
      "252/252 [==============================] - 0s 977us/step - loss: 0.7171 - accuracy: 0.6708\n",
      "Epoch 18/200\n",
      "252/252 [==============================] - 0s 956us/step - loss: 0.7199 - accuracy: 0.6709\n",
      "Epoch 19/200\n",
      "252/252 [==============================] - 0s 954us/step - loss: 0.7143 - accuracy: 0.6789\n",
      "Epoch 20/200\n",
      "252/252 [==============================] - 0s 952us/step - loss: 0.7143 - accuracy: 0.6730\n",
      "Epoch 21/200\n",
      "252/252 [==============================] - 0s 951us/step - loss: 0.7374 - accuracy: 0.6563\n",
      "Epoch 22/200\n",
      "252/252 [==============================] - 0s 943us/step - loss: 0.7253 - accuracy: 0.6708\n",
      "Epoch 23/200\n",
      "252/252 [==============================] - 0s 951us/step - loss: 0.7069 - accuracy: 0.6903\n",
      "Epoch 24/200\n",
      "252/252 [==============================] - 0s 950us/step - loss: 0.7266 - accuracy: 0.6770\n",
      "Epoch 25/200\n",
      "252/252 [==============================] - 0s 940us/step - loss: 0.7059 - accuracy: 0.6821\n",
      "Epoch 26/200\n",
      "252/252 [==============================] - 0s 973us/step - loss: 0.7172 - accuracy: 0.6789\n",
      "Epoch 27/200\n",
      "252/252 [==============================] - 0s 940us/step - loss: 0.7114 - accuracy: 0.6832\n",
      "Epoch 28/200\n",
      "252/252 [==============================] - 0s 961us/step - loss: 0.7332 - accuracy: 0.6706\n",
      "Epoch 29/200\n",
      "252/252 [==============================] - 0s 950us/step - loss: 0.7237 - accuracy: 0.6735\n",
      "Epoch 30/200\n",
      "252/252 [==============================] - 0s 953us/step - loss: 0.7121 - accuracy: 0.6819\n",
      "Epoch 31/200\n",
      "252/252 [==============================] - 0s 959us/step - loss: 0.7053 - accuracy: 0.6972\n",
      "Epoch 32/200\n",
      "252/252 [==============================] - 0s 941us/step - loss: 0.7216 - accuracy: 0.6852\n",
      "Epoch 33/200\n",
      "252/252 [==============================] - 0s 942us/step - loss: 0.7287 - accuracy: 0.6729\n",
      "Epoch 34/200\n",
      "252/252 [==============================] - 0s 955us/step - loss: 0.7113 - accuracy: 0.6842\n",
      "Epoch 35/200\n",
      "252/252 [==============================] - 0s 955us/step - loss: 0.7041 - accuracy: 0.6812\n",
      "Epoch 36/200\n",
      "252/252 [==============================] - 0s 954us/step - loss: 0.7026 - accuracy: 0.6818\n",
      "Epoch 37/200\n",
      "252/252 [==============================] - 0s 934us/step - loss: 0.7017 - accuracy: 0.6959\n",
      "Epoch 38/200\n",
      "252/252 [==============================] - 0s 981us/step - loss: 0.7154 - accuracy: 0.6864\n",
      "Epoch 39/200\n",
      "252/252 [==============================] - 0s 930us/step - loss: 0.6971 - accuracy: 0.6912\n",
      "Epoch 40/200\n",
      "252/252 [==============================] - 0s 975us/step - loss: 0.7218 - accuracy: 0.6770\n",
      "Epoch 41/200\n",
      "252/252 [==============================] - 0s 951us/step - loss: 0.7014 - accuracy: 0.6920\n",
      "Epoch 42/200\n",
      "252/252 [==============================] - 0s 946us/step - loss: 0.7062 - accuracy: 0.6911\n",
      "Epoch 43/200\n",
      "252/252 [==============================] - 0s 941us/step - loss: 0.6954 - accuracy: 0.6937\n",
      "Epoch 44/200\n",
      "252/252 [==============================] - 0s 940us/step - loss: 0.6931 - accuracy: 0.6942\n",
      "Epoch 45/200\n",
      "252/252 [==============================] - 0s 941us/step - loss: 0.7251 - accuracy: 0.6739\n",
      "Epoch 46/200\n",
      "252/252 [==============================] - 0s 948us/step - loss: 0.7009 - accuracy: 0.6939\n",
      "Epoch 47/200\n",
      "252/252 [==============================] - 0s 946us/step - loss: 0.7049 - accuracy: 0.6888\n",
      "Epoch 48/200\n",
      "252/252 [==============================] - 0s 951us/step - loss: 0.6988 - accuracy: 0.6930\n",
      "Epoch 49/200\n",
      "252/252 [==============================] - 0s 964us/step - loss: 0.7006 - accuracy: 0.6898\n",
      "Epoch 50/200\n",
      "252/252 [==============================] - 0s 943us/step - loss: 0.7029 - accuracy: 0.6872\n",
      "Epoch 51/200\n",
      "252/252 [==============================] - 0s 941us/step - loss: 0.6880 - accuracy: 0.6992\n",
      "Epoch 52/200\n",
      "252/252 [==============================] - 0s 951us/step - loss: 0.6984 - accuracy: 0.6962\n",
      "Epoch 53/200\n",
      "252/252 [==============================] - 0s 977us/step - loss: 0.7232 - accuracy: 0.6790\n",
      "Epoch 54/200\n",
      "252/252 [==============================] - 0s 979us/step - loss: 0.6900 - accuracy: 0.6981\n",
      "Epoch 55/200\n",
      "252/252 [==============================] - 0s 948us/step - loss: 0.7036 - accuracy: 0.6834\n",
      "Epoch 56/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6993 - accuracy: 0.6920\n",
      "Epoch 57/200\n",
      "252/252 [==============================] - 0s 935us/step - loss: 0.6785 - accuracy: 0.7020\n",
      "Epoch 58/200\n",
      "252/252 [==============================] - 0s 946us/step - loss: 0.6966 - accuracy: 0.6970\n",
      "Epoch 59/200\n",
      "252/252 [==============================] - 0s 953us/step - loss: 0.7127 - accuracy: 0.6906\n",
      "Epoch 60/200\n",
      "252/252 [==============================] - 0s 932us/step - loss: 0.6975 - accuracy: 0.6928\n",
      "Epoch 61/200\n",
      "252/252 [==============================] - 0s 929us/step - loss: 0.7051 - accuracy: 0.6896\n",
      "Epoch 62/200\n",
      "252/252 [==============================] - 0s 934us/step - loss: 0.6884 - accuracy: 0.7041\n",
      "Epoch 63/200\n",
      "252/252 [==============================] - 0s 980us/step - loss: 0.7040 - accuracy: 0.6859\n",
      "Epoch 64/200\n",
      "252/252 [==============================] - 0s 934us/step - loss: 0.6944 - accuracy: 0.7051\n",
      "Epoch 65/200\n",
      "252/252 [==============================] - 0s 937us/step - loss: 0.6874 - accuracy: 0.6965\n",
      "Epoch 66/200\n",
      "252/252 [==============================] - 0s 943us/step - loss: 0.6818 - accuracy: 0.7003\n",
      "Epoch 67/200\n",
      "252/252 [==============================] - 0s 983us/step - loss: 0.6957 - accuracy: 0.6866\n",
      "Epoch 68/200\n",
      "252/252 [==============================] - 0s 935us/step - loss: 0.7072 - accuracy: 0.6903\n",
      "Epoch 69/200\n",
      "252/252 [==============================] - 0s 940us/step - loss: 0.7125 - accuracy: 0.6925\n",
      "Epoch 70/200\n",
      "252/252 [==============================] - 0s 943us/step - loss: 0.6949 - accuracy: 0.6893\n",
      "Epoch 71/200\n",
      "252/252 [==============================] - 0s 936us/step - loss: 0.6846 - accuracy: 0.7018\n",
      "Epoch 72/200\n",
      "252/252 [==============================] - 0s 945us/step - loss: 0.6993 - accuracy: 0.6918\n",
      "Epoch 73/200\n",
      "252/252 [==============================] - 0s 939us/step - loss: 0.6955 - accuracy: 0.6933\n",
      "Epoch 74/200\n",
      "252/252 [==============================] - 0s 934us/step - loss: 0.6900 - accuracy: 0.7002\n",
      "Epoch 75/200\n",
      "252/252 [==============================] - 0s 946us/step - loss: 0.6963 - accuracy: 0.6920\n",
      "Epoch 76/200\n",
      "252/252 [==============================] - 0s 935us/step - loss: 0.6915 - accuracy: 0.7006\n",
      "Epoch 77/200\n",
      "252/252 [==============================] - 0s 953us/step - loss: 0.7016 - accuracy: 0.6882\n",
      "Epoch 78/200\n",
      "252/252 [==============================] - 0s 941us/step - loss: 0.7014 - accuracy: 0.6922\n",
      "Epoch 79/200\n",
      "252/252 [==============================] - 0s 971us/step - loss: 0.6930 - accuracy: 0.7024\n",
      "Epoch 80/200\n",
      "252/252 [==============================] - 0s 940us/step - loss: 0.6870 - accuracy: 0.6986\n",
      "Epoch 81/200\n",
      "252/252 [==============================] - 0s 941us/step - loss: 0.7015 - accuracy: 0.6924\n",
      "Epoch 82/200\n",
      "252/252 [==============================] - 0s 942us/step - loss: 0.6917 - accuracy: 0.6942\n",
      "Epoch 83/200\n",
      "252/252 [==============================] - 0s 941us/step - loss: 0.7032 - accuracy: 0.6882\n",
      "Epoch 84/200\n",
      "252/252 [==============================] - 0s 939us/step - loss: 0.7011 - accuracy: 0.6927\n",
      "Epoch 85/200\n",
      "252/252 [==============================] - 0s 956us/step - loss: 0.6941 - accuracy: 0.6990\n",
      "Epoch 86/200\n",
      "252/252 [==============================] - 0s 934us/step - loss: 0.7039 - accuracy: 0.6846\n",
      "Epoch 87/200\n",
      "252/252 [==============================] - 0s 944us/step - loss: 0.6867 - accuracy: 0.6967\n",
      "Epoch 88/200\n",
      "252/252 [==============================] - 0s 993us/step - loss: 0.6994 - accuracy: 0.6908\n",
      "Epoch 89/200\n",
      "252/252 [==============================] - 0s 962us/step - loss: 0.6862 - accuracy: 0.7016\n",
      "Epoch 90/200\n",
      "252/252 [==============================] - 0s 948us/step - loss: 0.7027 - accuracy: 0.6988\n",
      "Epoch 91/200\n",
      "252/252 [==============================] - 0s 935us/step - loss: 0.6822 - accuracy: 0.7021\n",
      "Epoch 92/200\n",
      "252/252 [==============================] - 0s 970us/step - loss: 0.6928 - accuracy: 0.6915\n",
      "Epoch 93/200\n",
      "252/252 [==============================] - 0s 942us/step - loss: 0.7010 - accuracy: 0.6879\n",
      "Epoch 94/200\n",
      "252/252 [==============================] - 0s 928us/step - loss: 0.6923 - accuracy: 0.6978\n",
      "Epoch 95/200\n",
      "252/252 [==============================] - 0s 945us/step - loss: 0.6872 - accuracy: 0.6997\n",
      "Epoch 96/200\n",
      "252/252 [==============================] - 0s 956us/step - loss: 0.6895 - accuracy: 0.7028\n",
      "Epoch 97/200\n",
      "252/252 [==============================] - 0s 926us/step - loss: 0.6883 - accuracy: 0.7004\n",
      "Epoch 98/200\n",
      "252/252 [==============================] - 0s 947us/step - loss: 0.6931 - accuracy: 0.6996\n",
      "Epoch 99/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6773 - accuracy: 0.7048\n",
      "Epoch 100/200\n",
      "252/252 [==============================] - 0s 948us/step - loss: 0.6820 - accuracy: 0.7081\n",
      "Epoch 101/200\n",
      "252/252 [==============================] - 0s 949us/step - loss: 0.6837 - accuracy: 0.7062\n",
      "Epoch 102/200\n",
      "252/252 [==============================] - 0s 936us/step - loss: 0.6867 - accuracy: 0.6985\n",
      "Epoch 103/200\n",
      "252/252 [==============================] - 0s 956us/step - loss: 0.6969 - accuracy: 0.7019\n",
      "Epoch 104/200\n",
      "252/252 [==============================] - 0s 963us/step - loss: 0.6902 - accuracy: 0.7006\n",
      "Epoch 105/200\n",
      "252/252 [==============================] - 0s 946us/step - loss: 0.6909 - accuracy: 0.7026\n",
      "Epoch 106/200\n",
      "252/252 [==============================] - 0s 938us/step - loss: 0.6857 - accuracy: 0.7016\n",
      "Epoch 107/200\n",
      "252/252 [==============================] - 0s 960us/step - loss: 0.6908 - accuracy: 0.7039\n",
      "Epoch 108/200\n",
      "252/252 [==============================] - 0s 950us/step - loss: 0.6992 - accuracy: 0.6960\n",
      "Epoch 109/200\n",
      "252/252 [==============================] - 0s 951us/step - loss: 0.6988 - accuracy: 0.6974\n",
      "Epoch 110/200\n",
      "252/252 [==============================] - 0s 963us/step - loss: 0.6865 - accuracy: 0.7066\n",
      "Epoch 111/200\n",
      "252/252 [==============================] - 0s 940us/step - loss: 0.6967 - accuracy: 0.6927\n",
      "Epoch 112/200\n",
      "252/252 [==============================] - 0s 945us/step - loss: 0.6876 - accuracy: 0.6957\n",
      "Epoch 113/200\n",
      "252/252 [==============================] - 0s 956us/step - loss: 0.6758 - accuracy: 0.7019\n",
      "Epoch 114/200\n",
      "252/252 [==============================] - 0s 952us/step - loss: 0.7003 - accuracy: 0.6952\n",
      "Epoch 115/200\n",
      "252/252 [==============================] - 0s 931us/step - loss: 0.6969 - accuracy: 0.6940\n",
      "Epoch 116/200\n",
      "252/252 [==============================] - 0s 990us/step - loss: 0.6860 - accuracy: 0.7029\n",
      "Epoch 117/200\n",
      "252/252 [==============================] - 0s 944us/step - loss: 0.6730 - accuracy: 0.7133\n",
      "Epoch 118/200\n",
      "252/252 [==============================] - 0s 949us/step - loss: 0.6996 - accuracy: 0.6951\n",
      "Epoch 119/200\n",
      "252/252 [==============================] - 0s 946us/step - loss: 0.6970 - accuracy: 0.7017\n",
      "Epoch 120/200\n",
      "252/252 [==============================] - 0s 975us/step - loss: 0.6967 - accuracy: 0.7047\n",
      "Epoch 121/200\n",
      "252/252 [==============================] - 0s 957us/step - loss: 0.6877 - accuracy: 0.6995\n",
      "Epoch 122/200\n",
      "252/252 [==============================] - 0s 936us/step - loss: 0.6959 - accuracy: 0.6938\n",
      "Epoch 123/200\n",
      "252/252 [==============================] - 0s 952us/step - loss: 0.6879 - accuracy: 0.7075\n",
      "Epoch 124/200\n",
      "252/252 [==============================] - 0s 955us/step - loss: 0.6821 - accuracy: 0.6997\n",
      "Epoch 125/200\n",
      "252/252 [==============================] - 0s 938us/step - loss: 0.6889 - accuracy: 0.6979\n",
      "Epoch 126/200\n",
      "252/252 [==============================] - 0s 935us/step - loss: 0.6958 - accuracy: 0.6910\n",
      "Epoch 127/200\n",
      "252/252 [==============================] - 0s 935us/step - loss: 0.6934 - accuracy: 0.6996\n",
      "Epoch 128/200\n",
      "252/252 [==============================] - 0s 963us/step - loss: 0.6879 - accuracy: 0.7032\n",
      "Epoch 129/200\n",
      "252/252 [==============================] - 0s 967us/step - loss: 0.6964 - accuracy: 0.7054\n",
      "Epoch 130/200\n",
      "252/252 [==============================] - 0s 943us/step - loss: 0.7040 - accuracy: 0.7004\n",
      "Epoch 131/200\n",
      "252/252 [==============================] - 0s 936us/step - loss: 0.6944 - accuracy: 0.7091\n",
      "Epoch 132/200\n",
      "252/252 [==============================] - 0s 990us/step - loss: 0.6774 - accuracy: 0.6999\n",
      "Epoch 133/200\n",
      "252/252 [==============================] - 0s 942us/step - loss: 0.6857 - accuracy: 0.7064\n",
      "Epoch 134/200\n",
      "252/252 [==============================] - 0s 956us/step - loss: 0.6850 - accuracy: 0.7061\n",
      "Epoch 135/200\n",
      "252/252 [==============================] - 0s 934us/step - loss: 0.6861 - accuracy: 0.7072\n",
      "Epoch 136/200\n",
      "252/252 [==============================] - 0s 943us/step - loss: 0.6888 - accuracy: 0.7017\n",
      "Epoch 137/200\n",
      "252/252 [==============================] - 0s 954us/step - loss: 0.6836 - accuracy: 0.7057\n",
      "Epoch 138/200\n",
      "252/252 [==============================] - 0s 945us/step - loss: 0.6996 - accuracy: 0.6969\n",
      "Epoch 139/200\n",
      "252/252 [==============================] - 0s 944us/step - loss: 0.6814 - accuracy: 0.7029\n",
      "Epoch 140/200\n",
      "252/252 [==============================] - 0s 945us/step - loss: 0.6949 - accuracy: 0.6929\n",
      "Epoch 141/200\n",
      "252/252 [==============================] - 0s 967us/step - loss: 0.6863 - accuracy: 0.7072\n",
      "Epoch 142/200\n",
      "252/252 [==============================] - 0s 960us/step - loss: 0.7015 - accuracy: 0.6944\n",
      "Epoch 143/200\n",
      "252/252 [==============================] - 0s 935us/step - loss: 0.6827 - accuracy: 0.6969\n",
      "Epoch 144/200\n",
      "252/252 [==============================] - 0s 946us/step - loss: 0.6899 - accuracy: 0.6979\n",
      "Epoch 145/200\n",
      "252/252 [==============================] - 0s 942us/step - loss: 0.6808 - accuracy: 0.7068\n",
      "Epoch 146/200\n",
      "252/252 [==============================] - 0s 958us/step - loss: 0.6806 - accuracy: 0.7099\n",
      "Epoch 147/200\n",
      "252/252 [==============================] - 0s 962us/step - loss: 0.6876 - accuracy: 0.7040\n",
      "Epoch 148/200\n",
      "252/252 [==============================] - 0s 958us/step - loss: 0.6989 - accuracy: 0.7052\n",
      "Epoch 149/200\n",
      "252/252 [==============================] - 0s 961us/step - loss: 0.7105 - accuracy: 0.6876\n",
      "Epoch 150/200\n",
      "252/252 [==============================] - 0s 962us/step - loss: 0.6785 - accuracy: 0.7107\n",
      "Epoch 151/200\n",
      "252/252 [==============================] - 0s 937us/step - loss: 0.7168 - accuracy: 0.6866\n",
      "Epoch 152/200\n",
      "252/252 [==============================] - 0s 950us/step - loss: 0.6853 - accuracy: 0.7029\n",
      "Epoch 153/200\n",
      "252/252 [==============================] - 0s 962us/step - loss: 0.7053 - accuracy: 0.6959\n",
      "Epoch 154/200\n",
      "252/252 [==============================] - 0s 938us/step - loss: 0.7019 - accuracy: 0.6905\n",
      "Epoch 155/200\n",
      "252/252 [==============================] - 0s 974us/step - loss: 0.6922 - accuracy: 0.7040\n",
      "Epoch 156/200\n",
      "252/252 [==============================] - 0s 945us/step - loss: 0.6806 - accuracy: 0.7098\n",
      "Epoch 157/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.6962\n",
      "Epoch 158/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.7007\n",
      "Epoch 159/200\n",
      "252/252 [==============================] - 0s 960us/step - loss: 0.6916 - accuracy: 0.7003\n",
      "Epoch 160/200\n",
      "252/252 [==============================] - 0s 950us/step - loss: 0.6963 - accuracy: 0.6979\n",
      "Epoch 161/200\n",
      "252/252 [==============================] - 0s 941us/step - loss: 0.6781 - accuracy: 0.7043\n",
      "Epoch 162/200\n",
      "252/252 [==============================] - 0s 997us/step - loss: 0.7047 - accuracy: 0.6918\n",
      "Epoch 163/200\n",
      "252/252 [==============================] - 0s 955us/step - loss: 0.6767 - accuracy: 0.7029\n",
      "Epoch 164/200\n",
      "252/252 [==============================] - 0s 931us/step - loss: 0.6898 - accuracy: 0.6996\n",
      "Epoch 165/200\n",
      "252/252 [==============================] - 0s 967us/step - loss: 0.6899 - accuracy: 0.7051\n",
      "Epoch 166/200\n",
      "252/252 [==============================] - 0s 951us/step - loss: 0.7000 - accuracy: 0.6922\n",
      "Epoch 167/200\n",
      "252/252 [==============================] - 0s 947us/step - loss: 0.6919 - accuracy: 0.7020\n",
      "Epoch 168/200\n",
      "252/252 [==============================] - 0s 939us/step - loss: 0.6796 - accuracy: 0.7062\n",
      "Epoch 169/200\n",
      "252/252 [==============================] - 0s 937us/step - loss: 0.6623 - accuracy: 0.7158\n",
      "Epoch 170/200\n",
      "252/252 [==============================] - 0s 941us/step - loss: 0.6841 - accuracy: 0.6992\n",
      "Epoch 171/200\n",
      "252/252 [==============================] - 0s 936us/step - loss: 0.6884 - accuracy: 0.7032\n",
      "Epoch 172/200\n",
      "252/252 [==============================] - 0s 947us/step - loss: 0.6832 - accuracy: 0.7042\n",
      "Epoch 173/200\n",
      "252/252 [==============================] - 0s 938us/step - loss: 0.6968 - accuracy: 0.6993\n",
      "Epoch 174/200\n",
      "252/252 [==============================] - 0s 950us/step - loss: 0.6922 - accuracy: 0.6954\n",
      "Epoch 175/200\n",
      "252/252 [==============================] - 0s 940us/step - loss: 0.6981 - accuracy: 0.6973\n",
      "Epoch 176/200\n",
      "252/252 [==============================] - 0s 942us/step - loss: 0.6985 - accuracy: 0.6941\n",
      "Epoch 177/200\n",
      "252/252 [==============================] - 0s 941us/step - loss: 0.6812 - accuracy: 0.7010\n",
      "Epoch 178/200\n",
      "252/252 [==============================] - 0s 976us/step - loss: 0.6927 - accuracy: 0.6998\n",
      "Epoch 179/200\n",
      "252/252 [==============================] - 0s 935us/step - loss: 0.6828 - accuracy: 0.7025\n",
      "Epoch 180/200\n",
      "252/252 [==============================] - 0s 937us/step - loss: 0.7047 - accuracy: 0.6902\n",
      "Epoch 181/200\n",
      "252/252 [==============================] - 0s 937us/step - loss: 0.6858 - accuracy: 0.7035\n",
      "Epoch 182/200\n",
      "252/252 [==============================] - 0s 963us/step - loss: 0.6893 - accuracy: 0.7045\n",
      "Epoch 183/200\n",
      "252/252 [==============================] - 0s 973us/step - loss: 0.7012 - accuracy: 0.6966\n",
      "Epoch 184/200\n",
      "252/252 [==============================] - 0s 951us/step - loss: 0.6722 - accuracy: 0.7114\n",
      "Epoch 185/200\n",
      "252/252 [==============================] - 0s 986us/step - loss: 0.6727 - accuracy: 0.7077\n",
      "Epoch 186/200\n",
      "252/252 [==============================] - 0s 969us/step - loss: 0.6878 - accuracy: 0.7013\n",
      "Epoch 187/200\n",
      "252/252 [==============================] - 0s 942us/step - loss: 0.6811 - accuracy: 0.7048\n",
      "Epoch 188/200\n",
      "252/252 [==============================] - 0s 938us/step - loss: 0.6669 - accuracy: 0.7098\n",
      "Epoch 189/200\n",
      "252/252 [==============================] - 0s 954us/step - loss: 0.6775 - accuracy: 0.7100\n",
      "Epoch 190/200\n",
      "252/252 [==============================] - 0s 975us/step - loss: 0.6922 - accuracy: 0.6943\n",
      "Epoch 191/200\n",
      "252/252 [==============================] - 0s 941us/step - loss: 0.6903 - accuracy: 0.7019\n",
      "Epoch 192/200\n",
      "252/252 [==============================] - 0s 953us/step - loss: 0.6771 - accuracy: 0.7011\n",
      "Epoch 193/200\n",
      "252/252 [==============================] - 0s 958us/step - loss: 0.6800 - accuracy: 0.7050\n",
      "Epoch 194/200\n",
      "252/252 [==============================] - 0s 957us/step - loss: 0.6894 - accuracy: 0.6957\n",
      "Epoch 195/200\n",
      "252/252 [==============================] - 0s 938us/step - loss: 0.6907 - accuracy: 0.6966\n",
      "Epoch 196/200\n",
      "252/252 [==============================] - 0s 946us/step - loss: 0.6893 - accuracy: 0.7047\n",
      "Epoch 197/200\n",
      "252/252 [==============================] - 0s 948us/step - loss: 0.6850 - accuracy: 0.7036\n",
      "Epoch 198/200\n",
      "252/252 [==============================] - 0s 951us/step - loss: 0.6983 - accuracy: 0.7019\n",
      "Epoch 199/200\n",
      "252/252 [==============================] - 0s 952us/step - loss: 0.6804 - accuracy: 0.7003\n",
      "Epoch 200/200\n",
      "252/252 [==============================] - 0s 955us/step - loss: 0.6904 - accuracy: 0.7028\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 823us/step - loss: 0.7871 - accuracy: 0.6406\n",
      "Acc:\n",
      "0.6406357884407043\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Acc:')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_224\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_672 (Dense)            (None, 12)                228       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_673 (Dense)            (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_674 (Dense)            (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 359\n",
      "Trainable params: 359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(12, kernel_initializer='normal', activation='relu', input_shape=(18,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "252/252 [==============================] - 1s 993us/step - loss: 1.0385 - accuracy: 0.5105\n",
      "Epoch 2/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7882 - accuracy: 0.6454\n",
      "Epoch 3/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7744 - accuracy: 0.6462\n",
      "Epoch 4/200\n",
      "252/252 [==============================] - 0s 976us/step - loss: 0.7610 - accuracy: 0.6525\n",
      "Epoch 5/200\n",
      "252/252 [==============================] - 0s 970us/step - loss: 0.7516 - accuracy: 0.6490\n",
      "Epoch 6/200\n",
      "252/252 [==============================] - 0s 963us/step - loss: 0.7313 - accuracy: 0.6671\n",
      "Epoch 7/200\n",
      "252/252 [==============================] - 0s 974us/step - loss: 0.7399 - accuracy: 0.6548\n",
      "Epoch 8/200\n",
      "252/252 [==============================] - 0s 973us/step - loss: 0.7532 - accuracy: 0.6608\n",
      "Epoch 9/200\n",
      "252/252 [==============================] - 0s 976us/step - loss: 0.7516 - accuracy: 0.6535\n",
      "Epoch 10/200\n",
      "252/252 [==============================] - 0s 973us/step - loss: 0.7467 - accuracy: 0.6523\n",
      "Epoch 11/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7525 - accuracy: 0.6601\n",
      "Epoch 12/200\n",
      "252/252 [==============================] - 0s 972us/step - loss: 0.7532 - accuracy: 0.6584\n",
      "Epoch 13/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7481 - accuracy: 0.6585\n",
      "Epoch 14/200\n",
      "252/252 [==============================] - 0s 970us/step - loss: 0.7447 - accuracy: 0.6597\n",
      "Epoch 15/200\n",
      "252/252 [==============================] - 0s 997us/step - loss: 0.7319 - accuracy: 0.6644\n",
      "Epoch 16/200\n",
      "252/252 [==============================] - 0s 983us/step - loss: 0.7331 - accuracy: 0.6721\n",
      "Epoch 17/200\n",
      "252/252 [==============================] - 0s 981us/step - loss: 0.7602 - accuracy: 0.6528\n",
      "Epoch 18/200\n",
      "252/252 [==============================] - 0s 970us/step - loss: 0.7429 - accuracy: 0.6571\n",
      "Epoch 19/200\n",
      "252/252 [==============================] - 0s 967us/step - loss: 0.7301 - accuracy: 0.6620\n",
      "Epoch 20/200\n",
      "252/252 [==============================] - 0s 966us/step - loss: 0.7422 - accuracy: 0.6549\n",
      "Epoch 21/200\n",
      "252/252 [==============================] - 0s 972us/step - loss: 0.7207 - accuracy: 0.6735\n",
      "Epoch 22/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7310 - accuracy: 0.6753\n",
      "Epoch 23/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7263 - accuracy: 0.6746\n",
      "Epoch 24/200\n",
      "252/252 [==============================] - 0s 969us/step - loss: 0.7384 - accuracy: 0.6536\n",
      "Epoch 25/200\n",
      "252/252 [==============================] - 0s 971us/step - loss: 0.7153 - accuracy: 0.6664\n",
      "Epoch 26/200\n",
      "252/252 [==============================] - 0s 961us/step - loss: 0.7370 - accuracy: 0.6701\n",
      "Epoch 27/200\n",
      "252/252 [==============================] - 0s 983us/step - loss: 0.7254 - accuracy: 0.6794\n",
      "Epoch 28/200\n",
      "252/252 [==============================] - 0s 976us/step - loss: 0.7208 - accuracy: 0.6798\n",
      "Epoch 29/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7284 - accuracy: 0.6788\n",
      "Epoch 30/200\n",
      "252/252 [==============================] - 0s 982us/step - loss: 0.7371 - accuracy: 0.6743\n",
      "Epoch 31/200\n",
      "252/252 [==============================] - 0s 979us/step - loss: 0.7313 - accuracy: 0.6689\n",
      "Epoch 32/200\n",
      "252/252 [==============================] - 0s 973us/step - loss: 0.7198 - accuracy: 0.6857\n",
      "Epoch 33/200\n",
      "252/252 [==============================] - 0s 975us/step - loss: 0.7296 - accuracy: 0.6710\n",
      "Epoch 34/200\n",
      "252/252 [==============================] - 0s 957us/step - loss: 0.7332 - accuracy: 0.6733\n",
      "Epoch 35/200\n",
      "252/252 [==============================] - 0s 971us/step - loss: 0.7329 - accuracy: 0.6626\n",
      "Epoch 36/200\n",
      "252/252 [==============================] - 0s 961us/step - loss: 0.7205 - accuracy: 0.6805\n",
      "Epoch 37/200\n",
      "252/252 [==============================] - 0s 967us/step - loss: 0.7345 - accuracy: 0.6733\n",
      "Epoch 38/200\n",
      "252/252 [==============================] - 0s 967us/step - loss: 0.7211 - accuracy: 0.6703\n",
      "Epoch 39/200\n",
      "252/252 [==============================] - 0s 997us/step - loss: 0.7212 - accuracy: 0.6840\n",
      "Epoch 40/200\n",
      "252/252 [==============================] - 0s 967us/step - loss: 0.7165 - accuracy: 0.6732\n",
      "Epoch 41/200\n",
      "252/252 [==============================] - 0s 985us/step - loss: 0.7391 - accuracy: 0.6742\n",
      "Epoch 42/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7372 - accuracy: 0.6744\n",
      "Epoch 43/200\n",
      "252/252 [==============================] - 0s 971us/step - loss: 0.7293 - accuracy: 0.6777\n",
      "Epoch 44/200\n",
      "252/252 [==============================] - 0s 962us/step - loss: 0.7338 - accuracy: 0.6624\n",
      "Epoch 45/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7326 - accuracy: 0.6647\n",
      "Epoch 46/200\n",
      "252/252 [==============================] - 0s 966us/step - loss: 0.7220 - accuracy: 0.6816\n",
      "Epoch 47/200\n",
      "252/252 [==============================] - 0s 976us/step - loss: 0.7254 - accuracy: 0.6679\n",
      "Epoch 48/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7519 - accuracy: 0.6587\n",
      "Epoch 49/200\n",
      "252/252 [==============================] - 0s 965us/step - loss: 0.7215 - accuracy: 0.6790\n",
      "Epoch 50/200\n",
      "252/252 [==============================] - 0s 968us/step - loss: 0.7439 - accuracy: 0.6670\n",
      "Epoch 51/200\n",
      "252/252 [==============================] - 0s 994us/step - loss: 0.7360 - accuracy: 0.6733\n",
      "Epoch 52/200\n",
      "252/252 [==============================] - 0s 972us/step - loss: 0.7504 - accuracy: 0.6595\n",
      "Epoch 53/200\n",
      "252/252 [==============================] - 0s 966us/step - loss: 0.7399 - accuracy: 0.6675\n",
      "Epoch 54/200\n",
      "252/252 [==============================] - 0s 961us/step - loss: 0.7332 - accuracy: 0.6775\n",
      "Epoch 55/200\n",
      "252/252 [==============================] - 0s 966us/step - loss: 0.7347 - accuracy: 0.6682\n",
      "Epoch 56/200\n",
      "252/252 [==============================] - 0s 977us/step - loss: 0.7595 - accuracy: 0.6695\n",
      "Epoch 57/200\n",
      "252/252 [==============================] - 0s 984us/step - loss: 0.7204 - accuracy: 0.6834\n",
      "Epoch 58/200\n",
      "252/252 [==============================] - 0s 980us/step - loss: 0.7190 - accuracy: 0.6823\n",
      "Epoch 59/200\n",
      "252/252 [==============================] - 0s 976us/step - loss: 0.7254 - accuracy: 0.6748\n",
      "Epoch 60/200\n",
      "252/252 [==============================] - 0s 971us/step - loss: 0.7215 - accuracy: 0.6853\n",
      "Epoch 61/200\n",
      "252/252 [==============================] - 0s 992us/step - loss: 0.7342 - accuracy: 0.6721\n",
      "Epoch 62/200\n",
      "252/252 [==============================] - 0s 990us/step - loss: 0.7207 - accuracy: 0.6777\n",
      "Epoch 63/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7380 - accuracy: 0.6660\n",
      "Epoch 64/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7270 - accuracy: 0.6758\n",
      "Epoch 65/200\n",
      "252/252 [==============================] - 0s 965us/step - loss: 0.7320 - accuracy: 0.6732\n",
      "Epoch 66/200\n",
      "252/252 [==============================] - 0s 985us/step - loss: 0.7054 - accuracy: 0.6830\n",
      "Epoch 67/200\n",
      "252/252 [==============================] - 0s 974us/step - loss: 0.7369 - accuracy: 0.6753\n",
      "Epoch 68/200\n",
      "252/252 [==============================] - 0s 961us/step - loss: 0.7182 - accuracy: 0.6843\n",
      "Epoch 69/200\n",
      "252/252 [==============================] - 0s 973us/step - loss: 0.7404 - accuracy: 0.6691\n",
      "Epoch 70/200\n",
      "252/252 [==============================] - 0s 966us/step - loss: 0.7255 - accuracy: 0.6748\n",
      "Epoch 71/200\n",
      "252/252 [==============================] - 0s 960us/step - loss: 0.7428 - accuracy: 0.6788\n",
      "Epoch 72/200\n",
      "252/252 [==============================] - 0s 977us/step - loss: 0.7323 - accuracy: 0.6750\n",
      "Epoch 73/200\n",
      "252/252 [==============================] - 0s 963us/step - loss: 0.7411 - accuracy: 0.6634\n",
      "Epoch 74/200\n",
      "252/252 [==============================] - 0s 966us/step - loss: 0.7428 - accuracy: 0.6680\n",
      "Epoch 75/200\n",
      "252/252 [==============================] - 0s 975us/step - loss: 0.7220 - accuracy: 0.6841\n",
      "Epoch 76/200\n",
      "252/252 [==============================] - 0s 946us/step - loss: 0.7330 - accuracy: 0.6707\n",
      "Epoch 77/200\n",
      "252/252 [==============================] - 0s 968us/step - loss: 0.7336 - accuracy: 0.6748\n",
      "Epoch 78/200\n",
      "252/252 [==============================] - 0s 960us/step - loss: 0.7241 - accuracy: 0.6835\n",
      "Epoch 79/200\n",
      "252/252 [==============================] - 0s 985us/step - loss: 0.7160 - accuracy: 0.6796\n",
      "Epoch 80/200\n",
      "252/252 [==============================] - 0s 986us/step - loss: 0.7148 - accuracy: 0.6824\n",
      "Epoch 81/200\n",
      "252/252 [==============================] - 0s 984us/step - loss: 0.7193 - accuracy: 0.6873\n",
      "Epoch 82/200\n",
      "252/252 [==============================] - 0s 953us/step - loss: 0.7261 - accuracy: 0.6837\n",
      "Epoch 83/200\n",
      "252/252 [==============================] - 0s 948us/step - loss: 0.7345 - accuracy: 0.6741\n",
      "Epoch 84/200\n",
      "252/252 [==============================] - 0s 970us/step - loss: 0.7288 - accuracy: 0.6773\n",
      "Epoch 85/200\n",
      "252/252 [==============================] - 0s 973us/step - loss: 0.7313 - accuracy: 0.6781\n",
      "Epoch 86/200\n",
      "252/252 [==============================] - 0s 958us/step - loss: 0.6944 - accuracy: 0.6890\n",
      "Epoch 87/200\n",
      "252/252 [==============================] - 0s 965us/step - loss: 0.7265 - accuracy: 0.6917\n",
      "Epoch 88/200\n",
      "252/252 [==============================] - 0s 961us/step - loss: 0.7321 - accuracy: 0.6666\n",
      "Epoch 89/200\n",
      "252/252 [==============================] - 0s 992us/step - loss: 0.7077 - accuracy: 0.6905\n",
      "Epoch 90/200\n",
      "252/252 [==============================] - 0s 958us/step - loss: 0.7147 - accuracy: 0.6834\n",
      "Epoch 91/200\n",
      "252/252 [==============================] - 0s 992us/step - loss: 0.7141 - accuracy: 0.6827\n",
      "Epoch 92/200\n",
      "252/252 [==============================] - 0s 951us/step - loss: 0.7410 - accuracy: 0.6700\n",
      "Epoch 93/200\n",
      "252/252 [==============================] - 0s 965us/step - loss: 0.7247 - accuracy: 0.6806\n",
      "Epoch 94/200\n",
      "252/252 [==============================] - 0s 959us/step - loss: 0.7344 - accuracy: 0.6756\n",
      "Epoch 95/200\n",
      "252/252 [==============================] - 0s 964us/step - loss: 0.7078 - accuracy: 0.6919\n",
      "Epoch 96/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7181 - accuracy: 0.6867\n",
      "Epoch 97/200\n",
      "252/252 [==============================] - 0s 980us/step - loss: 0.6968 - accuracy: 0.6970\n",
      "Epoch 98/200\n",
      "252/252 [==============================] - 0s 989us/step - loss: 0.7441 - accuracy: 0.6718\n",
      "Epoch 99/200\n",
      "252/252 [==============================] - 0s 974us/step - loss: 0.7248 - accuracy: 0.6734\n",
      "Epoch 100/200\n",
      "252/252 [==============================] - 0s 961us/step - loss: 0.7126 - accuracy: 0.6911\n",
      "Epoch 101/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7327 - accuracy: 0.6805\n",
      "Epoch 102/200\n",
      "252/252 [==============================] - 0s 990us/step - loss: 0.7142 - accuracy: 0.6825\n",
      "Epoch 103/200\n",
      "252/252 [==============================] - 0s 975us/step - loss: 0.7395 - accuracy: 0.6724\n",
      "Epoch 104/200\n",
      "252/252 [==============================] - 0s 970us/step - loss: 0.7111 - accuracy: 0.6863\n",
      "Epoch 105/200\n",
      "252/252 [==============================] - 0s 985us/step - loss: 0.7293 - accuracy: 0.6886\n",
      "Epoch 106/200\n",
      "252/252 [==============================] - 0s 980us/step - loss: 0.7236 - accuracy: 0.6832\n",
      "Epoch 107/200\n",
      "252/252 [==============================] - 0s 968us/step - loss: 0.7156 - accuracy: 0.6967\n",
      "Epoch 108/200\n",
      "252/252 [==============================] - 0s 965us/step - loss: 0.7475 - accuracy: 0.6726\n",
      "Epoch 109/200\n",
      "252/252 [==============================] - 0s 953us/step - loss: 0.7209 - accuracy: 0.6828\n",
      "Epoch 110/200\n",
      "252/252 [==============================] - 0s 948us/step - loss: 0.7137 - accuracy: 0.6824\n",
      "Epoch 111/200\n",
      "252/252 [==============================] - 0s 982us/step - loss: 0.7150 - accuracy: 0.6836\n",
      "Epoch 112/200\n",
      "252/252 [==============================] - 0s 952us/step - loss: 0.7442 - accuracy: 0.6716\n",
      "Epoch 113/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7102 - accuracy: 0.6906\n",
      "Epoch 114/200\n",
      "252/252 [==============================] - 0s 989us/step - loss: 0.7044 - accuracy: 0.6964\n",
      "Epoch 115/200\n",
      "252/252 [==============================] - 0s 967us/step - loss: 0.7156 - accuracy: 0.6895\n",
      "Epoch 116/200\n",
      "252/252 [==============================] - 0s 969us/step - loss: 0.7173 - accuracy: 0.6795\n",
      "Epoch 117/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7079 - accuracy: 0.6906\n",
      "Epoch 118/200\n",
      "252/252 [==============================] - 0s 962us/step - loss: 0.7303 - accuracy: 0.6724\n",
      "Epoch 119/200\n",
      "252/252 [==============================] - 0s 974us/step - loss: 0.7176 - accuracy: 0.6769\n",
      "Epoch 120/200\n",
      "252/252 [==============================] - 0s 967us/step - loss: 0.7116 - accuracy: 0.6826\n",
      "Epoch 121/200\n",
      "252/252 [==============================] - 0s 971us/step - loss: 0.7109 - accuracy: 0.6930\n",
      "Epoch 122/200\n",
      "252/252 [==============================] - 0s 964us/step - loss: 0.7325 - accuracy: 0.6750\n",
      "Epoch 123/200\n",
      "252/252 [==============================] - 0s 960us/step - loss: 0.7229 - accuracy: 0.6829\n",
      "Epoch 124/200\n",
      "252/252 [==============================] - 0s 961us/step - loss: 0.7237 - accuracy: 0.6870\n",
      "Epoch 125/200\n",
      "252/252 [==============================] - 0s 982us/step - loss: 0.7293 - accuracy: 0.6844\n",
      "Epoch 126/200\n",
      "252/252 [==============================] - 0s 950us/step - loss: 0.7284 - accuracy: 0.6721\n",
      "Epoch 127/200\n",
      "252/252 [==============================] - 0s 979us/step - loss: 0.7195 - accuracy: 0.6823\n",
      "Epoch 128/200\n",
      "252/252 [==============================] - 0s 958us/step - loss: 0.7281 - accuracy: 0.6839\n",
      "Epoch 129/200\n",
      "252/252 [==============================] - 0s 969us/step - loss: 0.7225 - accuracy: 0.6867\n",
      "Epoch 130/200\n",
      "252/252 [==============================] - 0s 966us/step - loss: 0.7286 - accuracy: 0.6770\n",
      "Epoch 131/200\n",
      "252/252 [==============================] - 0s 960us/step - loss: 0.7308 - accuracy: 0.6835\n",
      "Epoch 132/200\n",
      "252/252 [==============================] - 0s 982us/step - loss: 0.7166 - accuracy: 0.6830\n",
      "Epoch 133/200\n",
      "252/252 [==============================] - 0s 969us/step - loss: 0.7066 - accuracy: 0.6914\n",
      "Epoch 134/200\n",
      "252/252 [==============================] - 0s 959us/step - loss: 0.7152 - accuracy: 0.6805\n",
      "Epoch 135/200\n",
      "252/252 [==============================] - 0s 968us/step - loss: 0.7050 - accuracy: 0.6878\n",
      "Epoch 136/200\n",
      "252/252 [==============================] - 0s 968us/step - loss: 0.7212 - accuracy: 0.6811\n",
      "Epoch 137/200\n",
      "252/252 [==============================] - 0s 978us/step - loss: 0.7110 - accuracy: 0.6844\n",
      "Epoch 138/200\n",
      "252/252 [==============================] - 0s 958us/step - loss: 0.7024 - accuracy: 0.6865\n",
      "Epoch 139/200\n",
      "252/252 [==============================] - 0s 979us/step - loss: 0.7142 - accuracy: 0.6920\n",
      "Epoch 140/200\n",
      "252/252 [==============================] - 0s 979us/step - loss: 0.7344 - accuracy: 0.6827\n",
      "Epoch 141/200\n",
      "252/252 [==============================] - 0s 969us/step - loss: 0.7112 - accuracy: 0.6882\n",
      "Epoch 142/200\n",
      "252/252 [==============================] - 0s 959us/step - loss: 0.7273 - accuracy: 0.6884\n",
      "Epoch 143/200\n",
      "252/252 [==============================] - 0s 955us/step - loss: 0.7245 - accuracy: 0.6899\n",
      "Epoch 144/200\n",
      "252/252 [==============================] - 0s 968us/step - loss: 0.7159 - accuracy: 0.6800\n",
      "Epoch 145/200\n",
      "252/252 [==============================] - 0s 972us/step - loss: 0.7172 - accuracy: 0.6860\n",
      "Epoch 146/200\n",
      "252/252 [==============================] - 0s 968us/step - loss: 0.7084 - accuracy: 0.6949\n",
      "Epoch 147/200\n",
      "252/252 [==============================] - 0s 963us/step - loss: 0.7250 - accuracy: 0.6841\n",
      "Epoch 148/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7258 - accuracy: 0.6805\n",
      "Epoch 149/200\n",
      "252/252 [==============================] - 0s 988us/step - loss: 0.7169 - accuracy: 0.6830\n",
      "Epoch 150/200\n",
      "252/252 [==============================] - 0s 961us/step - loss: 0.7246 - accuracy: 0.6834\n",
      "Epoch 151/200\n",
      "252/252 [==============================] - 0s 963us/step - loss: 0.7258 - accuracy: 0.6905\n",
      "Epoch 152/200\n",
      "252/252 [==============================] - 0s 965us/step - loss: 0.7160 - accuracy: 0.6868\n",
      "Epoch 153/200\n",
      "252/252 [==============================] - 0s 979us/step - loss: 0.7128 - accuracy: 0.6876\n",
      "Epoch 154/200\n",
      "252/252 [==============================] - 0s 949us/step - loss: 0.7123 - accuracy: 0.6837\n",
      "Epoch 155/200\n",
      "252/252 [==============================] - 0s 944us/step - loss: 0.7329 - accuracy: 0.6859\n",
      "Epoch 156/200\n",
      "252/252 [==============================] - 0s 962us/step - loss: 0.7176 - accuracy: 0.6800\n",
      "Epoch 157/200\n",
      "252/252 [==============================] - 0s 980us/step - loss: 0.7211 - accuracy: 0.6946\n",
      "Epoch 158/200\n",
      "252/252 [==============================] - 0s 974us/step - loss: 0.7257 - accuracy: 0.6868\n",
      "Epoch 159/200\n",
      "252/252 [==============================] - 0s 966us/step - loss: 0.7050 - accuracy: 0.6909\n",
      "Epoch 160/200\n",
      "252/252 [==============================] - 0s 966us/step - loss: 0.7218 - accuracy: 0.6889\n",
      "Epoch 161/200\n",
      "252/252 [==============================] - 0s 974us/step - loss: 0.7207 - accuracy: 0.6895\n",
      "Epoch 162/200\n",
      "252/252 [==============================] - 0s 980us/step - loss: 0.7146 - accuracy: 0.6865\n",
      "Epoch 163/200\n",
      "252/252 [==============================] - 0s 975us/step - loss: 0.7059 - accuracy: 0.6926\n",
      "Epoch 164/200\n",
      "252/252 [==============================] - 0s 977us/step - loss: 0.7102 - accuracy: 0.6887\n",
      "Epoch 165/200\n",
      "252/252 [==============================] - 0s 963us/step - loss: 0.7245 - accuracy: 0.6874\n",
      "Epoch 166/200\n",
      "252/252 [==============================] - 0s 966us/step - loss: 0.7308 - accuracy: 0.6740\n",
      "Epoch 167/200\n",
      "252/252 [==============================] - 0s 965us/step - loss: 0.7086 - accuracy: 0.6893\n",
      "Epoch 168/200\n",
      "252/252 [==============================] - 0s 969us/step - loss: 0.7069 - accuracy: 0.6898\n",
      "Epoch 169/200\n",
      "252/252 [==============================] - 0s 966us/step - loss: 0.7171 - accuracy: 0.6812\n",
      "Epoch 170/200\n",
      "252/252 [==============================] - 0s 977us/step - loss: 0.7138 - accuracy: 0.6925\n",
      "Epoch 171/200\n",
      "252/252 [==============================] - 0s 967us/step - loss: 0.7038 - accuracy: 0.6902\n",
      "Epoch 172/200\n",
      "252/252 [==============================] - 0s 958us/step - loss: 0.7111 - accuracy: 0.6877\n",
      "Epoch 173/200\n",
      "252/252 [==============================] - 0s 966us/step - loss: 0.7344 - accuracy: 0.6827\n",
      "Epoch 174/200\n",
      "252/252 [==============================] - 0s 965us/step - loss: 0.7221 - accuracy: 0.6762\n",
      "Epoch 175/200\n",
      "252/252 [==============================] - 0s 964us/step - loss: 0.7118 - accuracy: 0.6871\n",
      "Epoch 176/200\n",
      "252/252 [==============================] - 0s 963us/step - loss: 0.7156 - accuracy: 0.6800\n",
      "Epoch 177/200\n",
      "252/252 [==============================] - 0s 964us/step - loss: 0.7338 - accuracy: 0.6725\n",
      "Epoch 178/200\n",
      "252/252 [==============================] - 0s 987us/step - loss: 0.7205 - accuracy: 0.6855\n",
      "Epoch 179/200\n",
      "252/252 [==============================] - 0s 967us/step - loss: 0.7170 - accuracy: 0.6808\n",
      "Epoch 180/200\n",
      "252/252 [==============================] - 0s 970us/step - loss: 0.7190 - accuracy: 0.6822\n",
      "Epoch 181/200\n",
      "252/252 [==============================] - 0s 967us/step - loss: 0.7311 - accuracy: 0.6749\n",
      "Epoch 182/200\n",
      "252/252 [==============================] - 0s 961us/step - loss: 0.7072 - accuracy: 0.6962\n",
      "Epoch 183/200\n",
      "252/252 [==============================] - 0s 970us/step - loss: 0.7071 - accuracy: 0.6848\n",
      "Epoch 184/200\n",
      "252/252 [==============================] - 0s 969us/step - loss: 0.7276 - accuracy: 0.6789\n",
      "Epoch 185/200\n",
      "252/252 [==============================] - 0s 958us/step - loss: 0.7113 - accuracy: 0.6926\n",
      "Epoch 186/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7066 - accuracy: 0.6980\n",
      "Epoch 187/200\n",
      "252/252 [==============================] - 0s 984us/step - loss: 0.7405 - accuracy: 0.6695\n",
      "Epoch 188/200\n",
      "252/252 [==============================] - 0s 963us/step - loss: 0.7177 - accuracy: 0.6883\n",
      "Epoch 189/200\n",
      "252/252 [==============================] - 0s 956us/step - loss: 0.7328 - accuracy: 0.6827\n",
      "Epoch 190/200\n",
      "252/252 [==============================] - 0s 967us/step - loss: 0.7179 - accuracy: 0.6813\n",
      "Epoch 191/200\n",
      "252/252 [==============================] - 0s 962us/step - loss: 0.7207 - accuracy: 0.6777\n",
      "Epoch 192/200\n",
      "252/252 [==============================] - 0s 969us/step - loss: 0.7162 - accuracy: 0.6898\n",
      "Epoch 193/200\n",
      "252/252 [==============================] - 0s 963us/step - loss: 0.7119 - accuracy: 0.6879\n",
      "Epoch 194/200\n",
      "252/252 [==============================] - 0s 965us/step - loss: 0.7260 - accuracy: 0.6792\n",
      "Epoch 195/200\n",
      "252/252 [==============================] - 0s 970us/step - loss: 0.7428 - accuracy: 0.6708\n",
      "Epoch 196/200\n",
      "252/252 [==============================] - 0s 983us/step - loss: 0.7070 - accuracy: 0.6892\n",
      "Epoch 197/200\n",
      "252/252 [==============================] - 0s 972us/step - loss: 0.7076 - accuracy: 0.6908\n",
      "Epoch 198/200\n",
      "252/252 [==============================] - 0s 985us/step - loss: 0.7289 - accuracy: 0.6773\n",
      "Epoch 199/200\n",
      "252/252 [==============================] - 0s 971us/step - loss: 0.7193 - accuracy: 0.6880\n",
      "Epoch 200/200\n",
      "252/252 [==============================] - 0s 970us/step - loss: 0.7159 - accuracy: 0.6920\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 890us/step - loss: 0.7714 - accuracy: 0.6365\n",
      "Acc:\n",
      "0.6364892721176147\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Acc:')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_225\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_675 (Dense)            (None, 14)                266       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_676 (Dense)            (None, 8)                 120       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_677 (Dense)            (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 413\n",
      "Trainable params: 413\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu', input_shape=(18,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "252/252 [==============================] - 1s 989us/step - loss: 1.0501 - accuracy: 0.4882\n",
      "Epoch 2/200\n",
      "252/252 [==============================] - 0s 995us/step - loss: 0.8441 - accuracy: 0.5792\n",
      "Epoch 3/200\n",
      "252/252 [==============================] - 0s 990us/step - loss: 0.7987 - accuracy: 0.6496\n",
      "Epoch 4/200\n",
      "252/252 [==============================] - 0s 981us/step - loss: 0.7884 - accuracy: 0.6588\n",
      "Epoch 5/200\n",
      "252/252 [==============================] - 0s 997us/step - loss: 0.7912 - accuracy: 0.6528\n",
      "Epoch 6/200\n",
      "252/252 [==============================] - 0s 985us/step - loss: 0.7842 - accuracy: 0.6586\n",
      "Epoch 7/200\n",
      "252/252 [==============================] - 0s 984us/step - loss: 0.7834 - accuracy: 0.6611\n",
      "Epoch 8/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7768 - accuracy: 0.6669\n",
      "Epoch 9/200\n",
      "252/252 [==============================] - 0s 974us/step - loss: 0.7826 - accuracy: 0.6510\n",
      "Epoch 10/200\n",
      "252/252 [==============================] - 0s 978us/step - loss: 0.7737 - accuracy: 0.6598\n",
      "Epoch 11/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7815 - accuracy: 0.6610\n",
      "Epoch 12/200\n",
      "252/252 [==============================] - 0s 985us/step - loss: 0.7715 - accuracy: 0.6534\n",
      "Epoch 13/200\n",
      "252/252 [==============================] - 0s 992us/step - loss: 0.7530 - accuracy: 0.6687\n",
      "Epoch 14/200\n",
      "252/252 [==============================] - 0s 987us/step - loss: 0.7844 - accuracy: 0.6540\n",
      "Epoch 15/200\n",
      "252/252 [==============================] - 0s 993us/step - loss: 0.7763 - accuracy: 0.6515\n",
      "Epoch 16/200\n",
      "252/252 [==============================] - 0s 980us/step - loss: 0.7823 - accuracy: 0.6458\n",
      "Epoch 17/200\n",
      "252/252 [==============================] - 0s 983us/step - loss: 0.7550 - accuracy: 0.6697\n",
      "Epoch 18/200\n",
      "252/252 [==============================] - 0s 979us/step - loss: 0.7701 - accuracy: 0.6573\n",
      "Epoch 19/200\n",
      "252/252 [==============================] - 0s 986us/step - loss: 0.7990 - accuracy: 0.6400\n",
      "Epoch 20/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7735 - accuracy: 0.6574\n",
      "Epoch 21/200\n",
      "252/252 [==============================] - 0s 980us/step - loss: 0.7613 - accuracy: 0.6613\n",
      "Epoch 22/200\n",
      "252/252 [==============================] - 0s 978us/step - loss: 0.7767 - accuracy: 0.6541\n",
      "Epoch 23/200\n",
      "252/252 [==============================] - 0s 992us/step - loss: 0.7697 - accuracy: 0.6595\n",
      "Epoch 24/200\n",
      "252/252 [==============================] - 0s 976us/step - loss: 0.7580 - accuracy: 0.6721\n",
      "Epoch 25/200\n",
      "252/252 [==============================] - 0s 989us/step - loss: 0.7648 - accuracy: 0.6566\n",
      "Epoch 26/200\n",
      "252/252 [==============================] - 0s 975us/step - loss: 0.7564 - accuracy: 0.6664\n",
      "Epoch 27/200\n",
      "252/252 [==============================] - 0s 986us/step - loss: 0.7594 - accuracy: 0.6597\n",
      "Epoch 28/200\n",
      "252/252 [==============================] - 0s 985us/step - loss: 0.7654 - accuracy: 0.6531\n",
      "Epoch 29/200\n",
      "252/252 [==============================] - 0s 973us/step - loss: 0.7619 - accuracy: 0.6575\n",
      "Epoch 30/200\n",
      "252/252 [==============================] - 0s 971us/step - loss: 0.7553 - accuracy: 0.6637\n",
      "Epoch 31/200\n",
      "252/252 [==============================] - 0s 982us/step - loss: 0.7555 - accuracy: 0.6634\n",
      "Epoch 32/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7481 - accuracy: 0.6791\n",
      "Epoch 33/200\n",
      "252/252 [==============================] - 0s 984us/step - loss: 0.7552 - accuracy: 0.6663\n",
      "Epoch 34/200\n",
      "252/252 [==============================] - 0s 988us/step - loss: 0.7693 - accuracy: 0.6502\n",
      "Epoch 35/200\n",
      "252/252 [==============================] - 0s 990us/step - loss: 0.7386 - accuracy: 0.6798\n",
      "Epoch 36/200\n",
      "252/252 [==============================] - 0s 981us/step - loss: 0.7505 - accuracy: 0.6658\n",
      "Epoch 37/200\n",
      "252/252 [==============================] - 0s 992us/step - loss: 0.7560 - accuracy: 0.6719\n",
      "Epoch 38/200\n",
      "252/252 [==============================] - 0s 973us/step - loss: 0.7643 - accuracy: 0.6617\n",
      "Epoch 39/200\n",
      "252/252 [==============================] - 0s 986us/step - loss: 0.7524 - accuracy: 0.6478\n",
      "Epoch 40/200\n",
      "252/252 [==============================] - 0s 974us/step - loss: 0.7550 - accuracy: 0.6618\n",
      "Epoch 41/200\n",
      "252/252 [==============================] - 0s 972us/step - loss: 0.7514 - accuracy: 0.6550\n",
      "Epoch 42/200\n",
      "252/252 [==============================] - 0s 968us/step - loss: 0.7838 - accuracy: 0.6480\n",
      "Epoch 43/200\n",
      "252/252 [==============================] - 0s 993us/step - loss: 0.7629 - accuracy: 0.6528\n",
      "Epoch 44/200\n",
      "252/252 [==============================] - 0s 1000us/step - loss: 0.7649 - accuracy: 0.6545\n",
      "Epoch 45/200\n",
      "252/252 [==============================] - 0s 981us/step - loss: 0.7562 - accuracy: 0.6642\n",
      "Epoch 46/200\n",
      "252/252 [==============================] - 0s 976us/step - loss: 0.7673 - accuracy: 0.6599\n",
      "Epoch 47/200\n",
      "252/252 [==============================] - 0s 983us/step - loss: 0.7623 - accuracy: 0.6484\n",
      "Epoch 48/200\n",
      "252/252 [==============================] - 0s 980us/step - loss: 0.7619 - accuracy: 0.6463\n",
      "Epoch 49/200\n",
      "252/252 [==============================] - 0s 973us/step - loss: 0.7557 - accuracy: 0.6696\n",
      "Epoch 50/200\n",
      "252/252 [==============================] - 0s 975us/step - loss: 0.7575 - accuracy: 0.6548\n",
      "Epoch 51/200\n",
      "252/252 [==============================] - 0s 981us/step - loss: 0.7345 - accuracy: 0.6807\n",
      "Epoch 52/200\n",
      "252/252 [==============================] - 0s 979us/step - loss: 0.7623 - accuracy: 0.6561\n",
      "Epoch 53/200\n",
      "252/252 [==============================] - 0s 984us/step - loss: 0.7417 - accuracy: 0.6791\n",
      "Epoch 54/200\n",
      "252/252 [==============================] - 0s 987us/step - loss: 0.7562 - accuracy: 0.6590\n",
      "Epoch 55/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7414 - accuracy: 0.6691\n",
      "Epoch 56/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7489 - accuracy: 0.6629\n",
      "Epoch 57/200\n",
      "252/252 [==============================] - 0s 980us/step - loss: 0.7401 - accuracy: 0.6714\n",
      "Epoch 58/200\n",
      "252/252 [==============================] - 0s 979us/step - loss: 0.7674 - accuracy: 0.6605\n",
      "Epoch 59/200\n",
      "252/252 [==============================] - 0s 982us/step - loss: 0.7641 - accuracy: 0.6576\n",
      "Epoch 60/200\n",
      "252/252 [==============================] - 0s 978us/step - loss: 0.7453 - accuracy: 0.6715\n",
      "Epoch 61/200\n",
      "252/252 [==============================] - 0s 981us/step - loss: 0.7889 - accuracy: 0.6373\n",
      "Epoch 62/200\n",
      "252/252 [==============================] - 0s 978us/step - loss: 0.7486 - accuracy: 0.6704\n",
      "Epoch 63/200\n",
      "252/252 [==============================] - 0s 984us/step - loss: 0.7541 - accuracy: 0.6558\n",
      "Epoch 64/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7546 - accuracy: 0.6658\n",
      "Epoch 65/200\n",
      "252/252 [==============================] - 0s 978us/step - loss: 0.7568 - accuracy: 0.6573\n",
      "Epoch 66/200\n",
      "252/252 [==============================] - 0s 981us/step - loss: 0.7416 - accuracy: 0.6696\n",
      "Epoch 67/200\n",
      "252/252 [==============================] - 0s 981us/step - loss: 0.7599 - accuracy: 0.6532\n",
      "Epoch 68/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7396 - accuracy: 0.6726\n",
      "Epoch 69/200\n",
      "252/252 [==============================] - 0s 976us/step - loss: 0.7778 - accuracy: 0.6487\n",
      "Epoch 70/200\n",
      "252/252 [==============================] - 0s 999us/step - loss: 0.7427 - accuracy: 0.6661\n",
      "Epoch 71/200\n",
      "252/252 [==============================] - 0s 989us/step - loss: 0.7582 - accuracy: 0.6555\n",
      "Epoch 72/200\n",
      "252/252 [==============================] - 0s 980us/step - loss: 0.7476 - accuracy: 0.6594\n",
      "Epoch 73/200\n",
      "252/252 [==============================] - 0s 983us/step - loss: 0.7691 - accuracy: 0.6510\n",
      "Epoch 74/200\n",
      "252/252 [==============================] - 0s 981us/step - loss: 0.7551 - accuracy: 0.6725\n",
      "Epoch 75/200\n",
      "252/252 [==============================] - 0s 999us/step - loss: 0.7506 - accuracy: 0.6621\n",
      "Epoch 76/200\n",
      "252/252 [==============================] - 0s 978us/step - loss: 0.7687 - accuracy: 0.6589\n",
      "Epoch 77/200\n",
      "252/252 [==============================] - 0s 973us/step - loss: 0.7624 - accuracy: 0.6590\n",
      "Epoch 78/200\n",
      "252/252 [==============================] - 0s 977us/step - loss: 0.7602 - accuracy: 0.6623\n",
      "Epoch 79/200\n",
      "252/252 [==============================] - 0s 978us/step - loss: 0.7539 - accuracy: 0.6519\n",
      "Epoch 80/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7417 - accuracy: 0.6651\n",
      "Epoch 81/200\n",
      "252/252 [==============================] - 0s 975us/step - loss: 0.7658 - accuracy: 0.6559\n",
      "Epoch 82/200\n",
      "252/252 [==============================] - 0s 984us/step - loss: 0.7447 - accuracy: 0.6640\n",
      "Epoch 83/200\n",
      "252/252 [==============================] - 0s 984us/step - loss: 0.7506 - accuracy: 0.6613\n",
      "Epoch 84/200\n",
      "252/252 [==============================] - 0s 990us/step - loss: 0.7506 - accuracy: 0.6632\n",
      "Epoch 85/200\n",
      "252/252 [==============================] - 0s 979us/step - loss: 0.7481 - accuracy: 0.6584\n",
      "Epoch 86/200\n",
      "252/252 [==============================] - 0s 983us/step - loss: 0.7677 - accuracy: 0.6481\n",
      "Epoch 87/200\n",
      "252/252 [==============================] - 0s 980us/step - loss: 0.7798 - accuracy: 0.6594\n",
      "Epoch 88/200\n",
      "252/252 [==============================] - 0s 989us/step - loss: 0.7534 - accuracy: 0.6513\n",
      "Epoch 89/200\n",
      "252/252 [==============================] - 0s 975us/step - loss: 0.7649 - accuracy: 0.6632\n",
      "Epoch 90/200\n",
      "252/252 [==============================] - 0s 978us/step - loss: 0.7466 - accuracy: 0.6673\n",
      "Epoch 91/200\n",
      "252/252 [==============================] - 0s 975us/step - loss: 0.7717 - accuracy: 0.6418\n",
      "Epoch 92/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7678 - accuracy: 0.6593\n",
      "Epoch 93/200\n",
      "252/252 [==============================] - 0s 984us/step - loss: 0.7762 - accuracy: 0.6538\n",
      "Epoch 94/200\n",
      "252/252 [==============================] - 0s 978us/step - loss: 0.7620 - accuracy: 0.6608\n",
      "Epoch 95/200\n",
      "252/252 [==============================] - 0s 983us/step - loss: 0.7620 - accuracy: 0.6608\n",
      "Epoch 96/200\n",
      "252/252 [==============================] - 0s 973us/step - loss: 0.7600 - accuracy: 0.6568\n",
      "Epoch 97/200\n",
      "252/252 [==============================] - 0s 973us/step - loss: 0.7463 - accuracy: 0.6699\n",
      "Epoch 98/200\n",
      "252/252 [==============================] - 0s 969us/step - loss: 0.7510 - accuracy: 0.6595\n",
      "Epoch 99/200\n",
      "252/252 [==============================] - 0s 977us/step - loss: 0.7584 - accuracy: 0.6488\n",
      "Epoch 100/200\n",
      "252/252 [==============================] - 0s 982us/step - loss: 0.7651 - accuracy: 0.6582\n",
      "Epoch 101/200\n",
      "252/252 [==============================] - 0s 981us/step - loss: 0.7767 - accuracy: 0.6462\n",
      "Epoch 102/200\n",
      "252/252 [==============================] - 0s 977us/step - loss: 0.7513 - accuracy: 0.6668\n",
      "Epoch 103/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7586 - accuracy: 0.6515\n",
      "Epoch 104/200\n",
      "252/252 [==============================] - 0s 969us/step - loss: 0.7620 - accuracy: 0.6526\n",
      "Epoch 105/200\n",
      "252/252 [==============================] - 0s 992us/step - loss: 0.7643 - accuracy: 0.6457\n",
      "Epoch 106/200\n",
      "252/252 [==============================] - 0s 977us/step - loss: 0.7643 - accuracy: 0.6512\n",
      "Epoch 107/200\n",
      "252/252 [==============================] - 0s 981us/step - loss: 0.7569 - accuracy: 0.6518\n",
      "Epoch 108/200\n",
      "252/252 [==============================] - 0s 981us/step - loss: 0.7509 - accuracy: 0.6638\n",
      "Epoch 109/200\n",
      "252/252 [==============================] - 0s 978us/step - loss: 0.7555 - accuracy: 0.6583\n",
      "Epoch 110/200\n",
      "252/252 [==============================] - 0s 978us/step - loss: 0.7485 - accuracy: 0.6705\n",
      "Epoch 111/200\n",
      "252/252 [==============================] - 0s 982us/step - loss: 0.7420 - accuracy: 0.6633\n",
      "Epoch 112/200\n",
      "252/252 [==============================] - 0s 978us/step - loss: 0.7640 - accuracy: 0.6463\n",
      "Epoch 113/200\n",
      "252/252 [==============================] - 0s 976us/step - loss: 0.7753 - accuracy: 0.6491\n",
      "Epoch 114/200\n",
      "252/252 [==============================] - 0s 986us/step - loss: 0.7662 - accuracy: 0.6469\n",
      "Epoch 115/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7502 - accuracy: 0.6659\n",
      "Epoch 116/200\n",
      "252/252 [==============================] - 0s 985us/step - loss: 0.7445 - accuracy: 0.6661\n",
      "Epoch 117/200\n",
      "252/252 [==============================] - 0s 981us/step - loss: 0.7585 - accuracy: 0.6582\n",
      "Epoch 118/200\n",
      "252/252 [==============================] - 0s 973us/step - loss: 0.7456 - accuracy: 0.6626\n",
      "Epoch 119/200\n",
      "252/252 [==============================] - 0s 983us/step - loss: 0.7683 - accuracy: 0.6575\n",
      "Epoch 120/200\n",
      "252/252 [==============================] - 0s 978us/step - loss: 0.7345 - accuracy: 0.6729\n",
      "Epoch 121/200\n",
      "252/252 [==============================] - 0s 974us/step - loss: 0.7654 - accuracy: 0.6516\n",
      "Epoch 122/200\n",
      "252/252 [==============================] - 0s 975us/step - loss: 0.7485 - accuracy: 0.6631\n",
      "Epoch 123/200\n",
      "252/252 [==============================] - 0s 975us/step - loss: 0.7535 - accuracy: 0.6581\n",
      "Epoch 124/200\n",
      "252/252 [==============================] - 0s 981us/step - loss: 0.7642 - accuracy: 0.6547\n",
      "Epoch 125/200\n",
      "252/252 [==============================] - 0s 977us/step - loss: 0.7559 - accuracy: 0.6618\n",
      "Epoch 126/200\n",
      "252/252 [==============================] - 0s 981us/step - loss: 0.7615 - accuracy: 0.6525\n",
      "Epoch 127/200\n",
      "252/252 [==============================] - 0s 996us/step - loss: 0.7577 - accuracy: 0.6625\n",
      "Epoch 128/200\n",
      "252/252 [==============================] - 0s 999us/step - loss: 0.7515 - accuracy: 0.6521\n",
      "Epoch 129/200\n",
      "252/252 [==============================] - 0s 972us/step - loss: 0.7612 - accuracy: 0.6562\n",
      "Epoch 130/200\n",
      "252/252 [==============================] - 0s 975us/step - loss: 0.7611 - accuracy: 0.6557\n",
      "Epoch 131/200\n",
      "252/252 [==============================] - 0s 991us/step - loss: 0.7884 - accuracy: 0.6491\n",
      "Epoch 132/200\n",
      "252/252 [==============================] - 0s 980us/step - loss: 0.7715 - accuracy: 0.6488\n",
      "Epoch 133/200\n",
      "252/252 [==============================] - 0s 975us/step - loss: 0.7746 - accuracy: 0.6485\n",
      "Epoch 134/200\n",
      "252/252 [==============================] - 0s 968us/step - loss: 0.7607 - accuracy: 0.6658\n",
      "Epoch 135/200\n",
      "252/252 [==============================] - 0s 983us/step - loss: 0.7439 - accuracy: 0.6724\n",
      "Epoch 136/200\n",
      "252/252 [==============================] - 0s 980us/step - loss: 0.7728 - accuracy: 0.6657\n",
      "Epoch 137/200\n",
      "252/252 [==============================] - 0s 976us/step - loss: 0.7615 - accuracy: 0.6608\n",
      "Epoch 138/200\n",
      "252/252 [==============================] - 0s 995us/step - loss: 0.7664 - accuracy: 0.6450\n",
      "Epoch 139/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7542 - accuracy: 0.6635\n",
      "Epoch 140/200\n",
      "252/252 [==============================] - 0s 984us/step - loss: 0.7522 - accuracy: 0.6570\n",
      "Epoch 141/200\n",
      "252/252 [==============================] - 0s 984us/step - loss: 0.7535 - accuracy: 0.6625\n",
      "Epoch 142/200\n",
      "252/252 [==============================] - 0s 981us/step - loss: 0.7615 - accuracy: 0.6656\n",
      "Epoch 143/200\n",
      "252/252 [==============================] - 0s 989us/step - loss: 0.7406 - accuracy: 0.6645\n",
      "Epoch 144/200\n",
      "252/252 [==============================] - 0s 977us/step - loss: 0.7640 - accuracy: 0.6585\n",
      "Epoch 145/200\n",
      "252/252 [==============================] - 0s 971us/step - loss: 0.7364 - accuracy: 0.6655\n",
      "Epoch 146/200\n",
      "252/252 [==============================] - 0s 983us/step - loss: 0.7659 - accuracy: 0.6497\n",
      "Epoch 147/200\n",
      "252/252 [==============================] - 0s 981us/step - loss: 0.7535 - accuracy: 0.6590\n",
      "Epoch 148/200\n",
      "252/252 [==============================] - 0s 978us/step - loss: 0.7347 - accuracy: 0.6746\n",
      "Epoch 149/200\n",
      "252/252 [==============================] - 0s 972us/step - loss: 0.7605 - accuracy: 0.6625\n",
      "Epoch 150/200\n",
      "252/252 [==============================] - 0s 983us/step - loss: 0.7343 - accuracy: 0.6664\n",
      "Epoch 151/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7558 - accuracy: 0.6586\n",
      "Epoch 152/200\n",
      "252/252 [==============================] - 0s 987us/step - loss: 0.7374 - accuracy: 0.6787\n",
      "Epoch 153/200\n",
      "252/252 [==============================] - 0s 980us/step - loss: 0.7639 - accuracy: 0.6587\n",
      "Epoch 154/200\n",
      "252/252 [==============================] - 0s 975us/step - loss: 0.7680 - accuracy: 0.6562\n",
      "Epoch 155/200\n",
      "252/252 [==============================] - 0s 984us/step - loss: 0.7678 - accuracy: 0.6564\n",
      "Epoch 156/200\n",
      "252/252 [==============================] - 0s 978us/step - loss: 0.7517 - accuracy: 0.6625\n",
      "Epoch 157/200\n",
      "252/252 [==============================] - 0s 987us/step - loss: 0.7695 - accuracy: 0.6623\n",
      "Epoch 158/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7617 - accuracy: 0.6579\n",
      "Epoch 159/200\n",
      "252/252 [==============================] - 0s 992us/step - loss: 0.7736 - accuracy: 0.6535\n",
      "Epoch 160/200\n",
      "252/252 [==============================] - 0s 996us/step - loss: 0.7811 - accuracy: 0.6505\n",
      "Epoch 161/200\n",
      "252/252 [==============================] - 0s 987us/step - loss: 0.7496 - accuracy: 0.6612\n",
      "Epoch 162/200\n",
      "252/252 [==============================] - 0s 980us/step - loss: 0.7622 - accuracy: 0.6495\n",
      "Epoch 163/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7824 - accuracy: 0.6519\n",
      "Epoch 164/200\n",
      "252/252 [==============================] - 0s 982us/step - loss: 0.7627 - accuracy: 0.6514\n",
      "Epoch 165/200\n",
      "252/252 [==============================] - 0s 974us/step - loss: 0.7586 - accuracy: 0.6574\n",
      "Epoch 166/200\n",
      "252/252 [==============================] - 0s 987us/step - loss: 0.7548 - accuracy: 0.6582\n",
      "Epoch 167/200\n",
      "252/252 [==============================] - 0s 997us/step - loss: 0.7647 - accuracy: 0.6464\n",
      "Epoch 168/200\n",
      "252/252 [==============================] - 0s 972us/step - loss: 0.7583 - accuracy: 0.6649\n",
      "Epoch 169/200\n",
      "252/252 [==============================] - 0s 971us/step - loss: 0.7675 - accuracy: 0.6510\n",
      "Epoch 170/200\n",
      "252/252 [==============================] - 0s 985us/step - loss: 0.7544 - accuracy: 0.6512\n",
      "Epoch 171/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7467 - accuracy: 0.6747\n",
      "Epoch 172/200\n",
      "252/252 [==============================] - 0s 979us/step - loss: 0.7497 - accuracy: 0.6577\n",
      "Epoch 173/200\n",
      "252/252 [==============================] - 0s 991us/step - loss: 0.7432 - accuracy: 0.6650\n",
      "Epoch 174/200\n",
      "252/252 [==============================] - 0s 976us/step - loss: 0.7369 - accuracy: 0.6574\n",
      "Epoch 175/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7610 - accuracy: 0.6541\n",
      "Epoch 176/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7647 - accuracy: 0.6656\n",
      "Epoch 177/200\n",
      "252/252 [==============================] - 0s 991us/step - loss: 0.7572 - accuracy: 0.6563\n",
      "Epoch 178/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7602 - accuracy: 0.6458\n",
      "Epoch 179/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7785 - accuracy: 0.6465\n",
      "Epoch 180/200\n",
      "252/252 [==============================] - 0s 986us/step - loss: 0.7838 - accuracy: 0.6403\n",
      "Epoch 181/200\n",
      "252/252 [==============================] - 0s 986us/step - loss: 0.7529 - accuracy: 0.6643\n",
      "Epoch 182/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7348 - accuracy: 0.6701\n",
      "Epoch 183/200\n",
      "252/252 [==============================] - 0s 998us/step - loss: 0.7495 - accuracy: 0.6558\n",
      "Epoch 184/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7725 - accuracy: 0.6575\n",
      "Epoch 185/200\n",
      "252/252 [==============================] - 0s 984us/step - loss: 0.7603 - accuracy: 0.6690\n",
      "Epoch 186/200\n",
      "252/252 [==============================] - 0s 985us/step - loss: 0.7402 - accuracy: 0.6660\n",
      "Epoch 187/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7599 - accuracy: 0.6557\n",
      "Epoch 188/200\n",
      "252/252 [==============================] - 0s 997us/step - loss: 0.7788 - accuracy: 0.6594\n",
      "Epoch 189/200\n",
      "252/252 [==============================] - 0s 996us/step - loss: 0.7661 - accuracy: 0.6421\n",
      "Epoch 190/200\n",
      "252/252 [==============================] - 0s 991us/step - loss: 0.7453 - accuracy: 0.6612\n",
      "Epoch 191/200\n",
      "252/252 [==============================] - 0s 990us/step - loss: 0.7522 - accuracy: 0.6615\n",
      "Epoch 192/200\n",
      "252/252 [==============================] - 0s 982us/step - loss: 0.7498 - accuracy: 0.6665\n",
      "Epoch 193/200\n",
      "252/252 [==============================] - 0s 991us/step - loss: 0.7399 - accuracy: 0.6639\n",
      "Epoch 194/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7644 - accuracy: 0.6591\n",
      "Epoch 195/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7524 - accuracy: 0.6548\n",
      "Epoch 196/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7761 - accuracy: 0.6481\n",
      "Epoch 197/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7666 - accuracy: 0.6601\n",
      "Epoch 198/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7572 - accuracy: 0.6605\n",
      "Epoch 199/200\n",
      "252/252 [==============================] - 0s 971us/step - loss: 0.7517 - accuracy: 0.6655\n",
      "Epoch 200/200\n",
      "252/252 [==============================] - 0s 988us/step - loss: 0.7630 - accuracy: 0.6614\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 854us/step - loss: 0.7865 - accuracy: 0.6358\n",
      "Acc:\n",
      "0.6357982158660889\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Acc:')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_226\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_678 (Dense)            (None, 14)                266       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_679 (Dense)            (None, 10)                150       \n",
      "_________________________________________________________________\n",
      "dense_680 (Dense)            (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_681 (Dense)            (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 531\n",
      "Trainable params: 531\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu', input_shape=(18,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "252/252 [==============================] - 1s 1ms/step - loss: 1.0713 - accuracy: 0.4901\n",
      "Epoch 2/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.8172 - accuracy: 0.6517\n",
      "Epoch 3/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7562 - accuracy: 0.6576\n",
      "Epoch 4/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7576 - accuracy: 0.6582\n",
      "Epoch 5/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7461 - accuracy: 0.6646\n",
      "Epoch 6/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7430 - accuracy: 0.6652\n",
      "Epoch 7/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7426 - accuracy: 0.6639\n",
      "Epoch 8/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7466 - accuracy: 0.6548\n",
      "Epoch 9/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7485 - accuracy: 0.6615\n",
      "Epoch 10/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7451 - accuracy: 0.6632\n",
      "Epoch 11/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7358 - accuracy: 0.6685\n",
      "Epoch 12/200\n",
      "252/252 [==============================] - 0s 998us/step - loss: 0.7334 - accuracy: 0.6616\n",
      "Epoch 13/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7355 - accuracy: 0.6642\n",
      "Epoch 14/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7516 - accuracy: 0.6603\n",
      "Epoch 15/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7286 - accuracy: 0.6752\n",
      "Epoch 16/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7410 - accuracy: 0.6665\n",
      "Epoch 17/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7449 - accuracy: 0.6605\n",
      "Epoch 18/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7480 - accuracy: 0.6597\n",
      "Epoch 19/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7206 - accuracy: 0.6733\n",
      "Epoch 20/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7340 - accuracy: 0.6638\n",
      "Epoch 21/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7387 - accuracy: 0.6630\n",
      "Epoch 22/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7363 - accuracy: 0.6788\n",
      "Epoch 23/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7330 - accuracy: 0.6698\n",
      "Epoch 24/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7361 - accuracy: 0.6682\n",
      "Epoch 25/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7396 - accuracy: 0.6607\n",
      "Epoch 26/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7336 - accuracy: 0.6696\n",
      "Epoch 27/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7388 - accuracy: 0.6613\n",
      "Epoch 28/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7361 - accuracy: 0.6714\n",
      "Epoch 29/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7427 - accuracy: 0.6648\n",
      "Epoch 30/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7339 - accuracy: 0.6717\n",
      "Epoch 31/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7300 - accuracy: 0.6760\n",
      "Epoch 32/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7539 - accuracy: 0.6617\n",
      "Epoch 33/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7176 - accuracy: 0.6820\n",
      "Epoch 34/200\n",
      "252/252 [==============================] - 0s 999us/step - loss: 0.7496 - accuracy: 0.6611\n",
      "Epoch 35/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7396 - accuracy: 0.6771\n",
      "Epoch 36/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7234 - accuracy: 0.6730\n",
      "Epoch 37/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7502 - accuracy: 0.6599\n",
      "Epoch 38/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7247 - accuracy: 0.6717\n",
      "Epoch 39/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7312 - accuracy: 0.6731\n",
      "Epoch 40/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7285 - accuracy: 0.6774\n",
      "Epoch 41/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7280 - accuracy: 0.6883\n",
      "Epoch 42/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7367 - accuracy: 0.6675\n",
      "Epoch 43/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7280 - accuracy: 0.6632\n",
      "Epoch 44/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7385 - accuracy: 0.6683\n",
      "Epoch 45/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7304 - accuracy: 0.6725\n",
      "Epoch 46/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7356 - accuracy: 0.6699\n",
      "Epoch 47/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7164 - accuracy: 0.6725\n",
      "Epoch 48/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7133 - accuracy: 0.6813\n",
      "Epoch 49/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7232 - accuracy: 0.6812\n",
      "Epoch 50/200\n",
      "252/252 [==============================] - 0s 991us/step - loss: 0.7129 - accuracy: 0.6818\n",
      "Epoch 51/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7322 - accuracy: 0.6736\n",
      "Epoch 52/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7247 - accuracy: 0.6675\n",
      "Epoch 53/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7377 - accuracy: 0.6672\n",
      "Epoch 54/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7163 - accuracy: 0.6769\n",
      "Epoch 55/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7118 - accuracy: 0.6828\n",
      "Epoch 56/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7301 - accuracy: 0.6674\n",
      "Epoch 57/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7267 - accuracy: 0.6845\n",
      "Epoch 58/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7457 - accuracy: 0.6683\n",
      "Epoch 59/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7371 - accuracy: 0.6671\n",
      "Epoch 60/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7286 - accuracy: 0.6717\n",
      "Epoch 61/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7217 - accuracy: 0.6769\n",
      "Epoch 62/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7343 - accuracy: 0.6713\n",
      "Epoch 63/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7236 - accuracy: 0.6816\n",
      "Epoch 64/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7171 - accuracy: 0.6775\n",
      "Epoch 65/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7333 - accuracy: 0.6727\n",
      "Epoch 66/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7313 - accuracy: 0.6779\n",
      "Epoch 67/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7237 - accuracy: 0.6839\n",
      "Epoch 68/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7117 - accuracy: 0.6842\n",
      "Epoch 69/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7065 - accuracy: 0.6833\n",
      "Epoch 70/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7103 - accuracy: 0.6931\n",
      "Epoch 71/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7235 - accuracy: 0.6696\n",
      "Epoch 72/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7321 - accuracy: 0.6693\n",
      "Epoch 73/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7142 - accuracy: 0.6874\n",
      "Epoch 74/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7308 - accuracy: 0.6738\n",
      "Epoch 75/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7353 - accuracy: 0.6792\n",
      "Epoch 76/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7281 - accuracy: 0.6759\n",
      "Epoch 77/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7194 - accuracy: 0.6761\n",
      "Epoch 78/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7194 - accuracy: 0.6837\n",
      "Epoch 79/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7247 - accuracy: 0.6760\n",
      "Epoch 80/200\n",
      "252/252 [==============================] - 0s 996us/step - loss: 0.7355 - accuracy: 0.6825\n",
      "Epoch 81/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7311 - accuracy: 0.6788\n",
      "Epoch 82/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7213 - accuracy: 0.6803\n",
      "Epoch 83/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7283 - accuracy: 0.6735\n",
      "Epoch 84/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7086 - accuracy: 0.6902\n",
      "Epoch 85/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7072 - accuracy: 0.6852\n",
      "Epoch 86/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7242 - accuracy: 0.6764\n",
      "Epoch 87/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7311 - accuracy: 0.6697\n",
      "Epoch 88/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.6820\n",
      "Epoch 89/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7476 - accuracy: 0.6720\n",
      "Epoch 90/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7173 - accuracy: 0.6814\n",
      "Epoch 91/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7131 - accuracy: 0.6803\n",
      "Epoch 92/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7107 - accuracy: 0.6871\n",
      "Epoch 93/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7227 - accuracy: 0.6848\n",
      "Epoch 94/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7111 - accuracy: 0.6811\n",
      "Epoch 95/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7253 - accuracy: 0.6743\n",
      "Epoch 96/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7227 - accuracy: 0.6737\n",
      "Epoch 97/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7128 - accuracy: 0.6830\n",
      "Epoch 98/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7141 - accuracy: 0.6747\n",
      "Epoch 99/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7047 - accuracy: 0.6910\n",
      "Epoch 100/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7182 - accuracy: 0.6732\n",
      "Epoch 101/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7215 - accuracy: 0.6768\n",
      "Epoch 102/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7131 - accuracy: 0.6820\n",
      "Epoch 103/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7175 - accuracy: 0.6760\n",
      "Epoch 104/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7135 - accuracy: 0.6788\n",
      "Epoch 105/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7141 - accuracy: 0.6848\n",
      "Epoch 106/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7020 - accuracy: 0.6890\n",
      "Epoch 107/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7044 - accuracy: 0.6850\n",
      "Epoch 108/200\n",
      "252/252 [==============================] - 0s 991us/step - loss: 0.7153 - accuracy: 0.6776\n",
      "Epoch 109/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7187 - accuracy: 0.6843\n",
      "Epoch 110/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7121 - accuracy: 0.6932\n",
      "Epoch 111/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7214 - accuracy: 0.6757\n",
      "Epoch 112/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6981 - accuracy: 0.6883\n",
      "Epoch 113/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7179 - accuracy: 0.6795\n",
      "Epoch 114/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7205 - accuracy: 0.6774\n",
      "Epoch 115/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7061 - accuracy: 0.6823\n",
      "Epoch 116/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7105 - accuracy: 0.6776\n",
      "Epoch 117/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7224 - accuracy: 0.6719\n",
      "Epoch 118/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7295 - accuracy: 0.6781\n",
      "Epoch 119/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7273 - accuracy: 0.6758\n",
      "Epoch 120/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7073 - accuracy: 0.6912\n",
      "Epoch 121/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7282 - accuracy: 0.6765\n",
      "Epoch 122/200\n",
      "252/252 [==============================] - 0s 998us/step - loss: 0.6944 - accuracy: 0.6915\n",
      "Epoch 123/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7297 - accuracy: 0.6732\n",
      "Epoch 124/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7205 - accuracy: 0.6751\n",
      "Epoch 125/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.6874\n",
      "Epoch 126/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7379 - accuracy: 0.6565\n",
      "Epoch 127/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7153 - accuracy: 0.6879\n",
      "Epoch 128/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7259 - accuracy: 0.6790\n",
      "Epoch 129/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7077 - accuracy: 0.6886\n",
      "Epoch 130/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7005 - accuracy: 0.6872\n",
      "Epoch 131/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7155 - accuracy: 0.6833\n",
      "Epoch 132/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7015 - accuracy: 0.6869\n",
      "Epoch 133/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7183 - accuracy: 0.6837\n",
      "Epoch 134/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7230 - accuracy: 0.6721\n",
      "Epoch 135/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7121 - accuracy: 0.6812\n",
      "Epoch 136/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7139 - accuracy: 0.6810\n",
      "Epoch 137/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7120 - accuracy: 0.6838\n",
      "Epoch 138/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7018 - accuracy: 0.6955\n",
      "Epoch 139/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7300 - accuracy: 0.6787\n",
      "Epoch 140/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7071 - accuracy: 0.6819\n",
      "Epoch 141/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7178 - accuracy: 0.6820\n",
      "Epoch 142/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7212 - accuracy: 0.6814\n",
      "Epoch 143/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7169 - accuracy: 0.6739\n",
      "Epoch 144/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7241 - accuracy: 0.6802\n",
      "Epoch 145/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7045 - accuracy: 0.6833\n",
      "Epoch 146/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7096 - accuracy: 0.6941\n",
      "Epoch 147/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7215 - accuracy: 0.6858\n",
      "Epoch 148/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7150 - accuracy: 0.6865\n",
      "Epoch 149/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7121 - accuracy: 0.6896\n",
      "Epoch 150/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7154 - accuracy: 0.6875\n",
      "Epoch 151/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7177 - accuracy: 0.6801\n",
      "Epoch 152/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7291 - accuracy: 0.6845\n",
      "Epoch 153/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7143 - accuracy: 0.6754\n",
      "Epoch 154/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7240 - accuracy: 0.6790\n",
      "Epoch 155/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7193 - accuracy: 0.6795\n",
      "Epoch 156/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.6895\n",
      "Epoch 157/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.6783\n",
      "Epoch 158/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7126 - accuracy: 0.6857\n",
      "Epoch 159/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7256 - accuracy: 0.6826\n",
      "Epoch 160/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7136 - accuracy: 0.6846\n",
      "Epoch 161/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7327 - accuracy: 0.6734\n",
      "Epoch 162/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7003 - accuracy: 0.6862\n",
      "Epoch 163/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7096 - accuracy: 0.6966\n",
      "Epoch 164/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7352 - accuracy: 0.6754\n",
      "Epoch 165/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7070 - accuracy: 0.6789\n",
      "Epoch 166/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7097 - accuracy: 0.6901\n",
      "Epoch 167/200\n",
      "252/252 [==============================] - 0s 996us/step - loss: 0.7125 - accuracy: 0.6941\n",
      "Epoch 168/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7200 - accuracy: 0.6814\n",
      "Epoch 169/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7082 - accuracy: 0.6920\n",
      "Epoch 170/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7178 - accuracy: 0.6809\n",
      "Epoch 171/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7124 - accuracy: 0.6733\n",
      "Epoch 172/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7113 - accuracy: 0.6737\n",
      "Epoch 173/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7373 - accuracy: 0.6757\n",
      "Epoch 174/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7210 - accuracy: 0.6784\n",
      "Epoch 175/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7161 - accuracy: 0.6835\n",
      "Epoch 176/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7032 - accuracy: 0.6884\n",
      "Epoch 177/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7330 - accuracy: 0.6819\n",
      "Epoch 178/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7114 - accuracy: 0.6873\n",
      "Epoch 179/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7079 - accuracy: 0.6924\n",
      "Epoch 180/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7025 - accuracy: 0.7006\n",
      "Epoch 181/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7067 - accuracy: 0.6781\n",
      "Epoch 182/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7283 - accuracy: 0.6751\n",
      "Epoch 183/200\n",
      "252/252 [==============================] - 0s 994us/step - loss: 0.7127 - accuracy: 0.6882\n",
      "Epoch 184/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7324 - accuracy: 0.6744\n",
      "Epoch 185/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7108 - accuracy: 0.6765\n",
      "Epoch 186/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7164 - accuracy: 0.6855\n",
      "Epoch 187/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7220 - accuracy: 0.6784\n",
      "Epoch 188/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7034 - accuracy: 0.6834\n",
      "Epoch 189/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7140 - accuracy: 0.6834\n",
      "Epoch 190/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7117 - accuracy: 0.6835\n",
      "Epoch 191/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7164 - accuracy: 0.6839\n",
      "Epoch 192/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7374 - accuracy: 0.6668\n",
      "Epoch 193/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.6886\n",
      "Epoch 194/200\n",
      "252/252 [==============================] - 0s 999us/step - loss: 0.7203 - accuracy: 0.6836\n",
      "Epoch 195/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7090 - accuracy: 0.6822\n",
      "Epoch 196/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.6896\n",
      "Epoch 197/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7189 - accuracy: 0.6919\n",
      "Epoch 198/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7229 - accuracy: 0.6783\n",
      "Epoch 199/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7234 - accuracy: 0.6860\n",
      "Epoch 200/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7081 - accuracy: 0.6921\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 832us/step - loss: 0.7667 - accuracy: 0.6413\n",
      "Acc:\n",
      "0.641326904296875\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Acc:')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_227\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_682 (Dense)            (None, 14)                266       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_683 (Dense)            (None, 12)                180       \n",
      "_________________________________________________________________\n",
      "dense_684 (Dense)            (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_685 (Dense)            (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 577\n",
      "Trainable params: 577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu', input_shape=(18,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(12, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "252/252 [==============================] - 1s 1ms/step - loss: 1.0266 - accuracy: 0.4749\n",
      "Epoch 2/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.8428 - accuracy: 0.6433\n",
      "Epoch 3/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7832 - accuracy: 0.6517\n",
      "Epoch 4/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7507 - accuracy: 0.6561\n",
      "Epoch 5/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7585 - accuracy: 0.6496\n",
      "Epoch 6/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7416 - accuracy: 0.6618\n",
      "Epoch 7/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7345 - accuracy: 0.6781\n",
      "Epoch 8/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7523 - accuracy: 0.6551\n",
      "Epoch 9/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7656 - accuracy: 0.6484\n",
      "Epoch 10/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7475 - accuracy: 0.6668\n",
      "Epoch 11/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7425 - accuracy: 0.6734\n",
      "Epoch 12/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7429 - accuracy: 0.6614\n",
      "Epoch 13/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7241 - accuracy: 0.6752\n",
      "Epoch 14/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7580 - accuracy: 0.6589\n",
      "Epoch 15/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7421 - accuracy: 0.6600\n",
      "Epoch 16/200\n",
      "252/252 [==============================] - 0s 999us/step - loss: 0.7358 - accuracy: 0.6718\n",
      "Epoch 17/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7404 - accuracy: 0.6695\n",
      "Epoch 18/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7483 - accuracy: 0.6668\n",
      "Epoch 19/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7260 - accuracy: 0.6751\n",
      "Epoch 20/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7506 - accuracy: 0.6679\n",
      "Epoch 21/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7268 - accuracy: 0.6741\n",
      "Epoch 22/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7334 - accuracy: 0.6737\n",
      "Epoch 23/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7381 - accuracy: 0.6647\n",
      "Epoch 24/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7157 - accuracy: 0.6799\n",
      "Epoch 25/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7375 - accuracy: 0.6636\n",
      "Epoch 26/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7440 - accuracy: 0.6742\n",
      "Epoch 27/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7304 - accuracy: 0.6765\n",
      "Epoch 28/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7488 - accuracy: 0.6686\n",
      "Epoch 29/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7291 - accuracy: 0.6647\n",
      "Epoch 30/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7383 - accuracy: 0.6743\n",
      "Epoch 31/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7180 - accuracy: 0.6821\n",
      "Epoch 32/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7270 - accuracy: 0.6803\n",
      "Epoch 33/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7377 - accuracy: 0.6683\n",
      "Epoch 34/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7477 - accuracy: 0.6717\n",
      "Epoch 35/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7210 - accuracy: 0.6774\n",
      "Epoch 36/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7374 - accuracy: 0.6549\n",
      "Epoch 37/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7221 - accuracy: 0.6821\n",
      "Epoch 38/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7443 - accuracy: 0.6668\n",
      "Epoch 39/200\n",
      "252/252 [==============================] - 0s 992us/step - loss: 0.7280 - accuracy: 0.6762\n",
      "Epoch 40/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7090 - accuracy: 0.6922\n",
      "Epoch 41/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7237 - accuracy: 0.6830\n",
      "Epoch 42/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7431 - accuracy: 0.6657\n",
      "Epoch 43/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7222 - accuracy: 0.6875\n",
      "Epoch 44/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7295 - accuracy: 0.6720\n",
      "Epoch 45/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7289 - accuracy: 0.6775\n",
      "Epoch 46/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7220 - accuracy: 0.6766\n",
      "Epoch 47/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7397 - accuracy: 0.6752\n",
      "Epoch 48/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7181 - accuracy: 0.6841\n",
      "Epoch 49/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7245 - accuracy: 0.6809\n",
      "Epoch 50/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7270 - accuracy: 0.6846\n",
      "Epoch 51/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7261 - accuracy: 0.6737\n",
      "Epoch 52/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7346 - accuracy: 0.6755\n",
      "Epoch 53/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7127 - accuracy: 0.6807\n",
      "Epoch 54/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7262 - accuracy: 0.6780\n",
      "Epoch 55/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7310 - accuracy: 0.6786\n",
      "Epoch 56/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7271 - accuracy: 0.6789\n",
      "Epoch 57/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6983 - accuracy: 0.6877\n",
      "Epoch 58/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7172 - accuracy: 0.6818\n",
      "Epoch 59/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7284 - accuracy: 0.6704\n",
      "Epoch 60/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7291 - accuracy: 0.6803\n",
      "Epoch 61/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7253 - accuracy: 0.6737\n",
      "Epoch 62/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7085 - accuracy: 0.6859\n",
      "Epoch 63/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7196 - accuracy: 0.6776\n",
      "Epoch 64/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7339 - accuracy: 0.6784\n",
      "Epoch 65/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7433 - accuracy: 0.6673\n",
      "Epoch 66/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7195 - accuracy: 0.6904\n",
      "Epoch 67/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7173 - accuracy: 0.6884\n",
      "Epoch 68/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7421 - accuracy: 0.6636\n",
      "Epoch 69/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7521 - accuracy: 0.6636\n",
      "Epoch 70/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7086 - accuracy: 0.6815\n",
      "Epoch 71/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7190 - accuracy: 0.6873\n",
      "Epoch 72/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7417 - accuracy: 0.6762\n",
      "Epoch 73/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7369 - accuracy: 0.6768\n",
      "Epoch 74/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7309 - accuracy: 0.6791\n",
      "Epoch 75/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7310 - accuracy: 0.6804\n",
      "Epoch 76/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7341 - accuracy: 0.6719\n",
      "Epoch 77/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7211 - accuracy: 0.6735\n",
      "Epoch 78/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7483 - accuracy: 0.6642\n",
      "Epoch 79/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6967 - accuracy: 0.6890\n",
      "Epoch 80/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7093 - accuracy: 0.6913\n",
      "Epoch 81/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7296 - accuracy: 0.6797\n",
      "Epoch 82/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7371 - accuracy: 0.6669\n",
      "Epoch 83/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7208 - accuracy: 0.6777\n",
      "Epoch 84/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7071 - accuracy: 0.6917\n",
      "Epoch 85/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7102 - accuracy: 0.6865\n",
      "Epoch 86/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7207 - accuracy: 0.6766\n",
      "Epoch 87/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7225 - accuracy: 0.6788\n",
      "Epoch 88/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7119 - accuracy: 0.6861\n",
      "Epoch 89/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7332 - accuracy: 0.6675\n",
      "Epoch 90/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7015 - accuracy: 0.6920\n",
      "Epoch 91/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7286 - accuracy: 0.6793\n",
      "Epoch 92/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7133 - accuracy: 0.6776\n",
      "Epoch 93/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7082 - accuracy: 0.6895\n",
      "Epoch 94/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7146 - accuracy: 0.6882\n",
      "Epoch 95/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7144 - accuracy: 0.6796\n",
      "Epoch 96/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7141 - accuracy: 0.6878\n",
      "Epoch 97/200\n",
      "252/252 [==============================] - 0s 998us/step - loss: 0.7297 - accuracy: 0.6785\n",
      "Epoch 98/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7148 - accuracy: 0.6928\n",
      "Epoch 99/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7160 - accuracy: 0.6886\n",
      "Epoch 100/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7194 - accuracy: 0.6827\n",
      "Epoch 101/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7127 - accuracy: 0.6881\n",
      "Epoch 102/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7337 - accuracy: 0.6804\n",
      "Epoch 103/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7128 - accuracy: 0.6892\n",
      "Epoch 104/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7348 - accuracy: 0.6773\n",
      "Epoch 105/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7248 - accuracy: 0.6828\n",
      "Epoch 106/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7304 - accuracy: 0.6806\n",
      "Epoch 107/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7221 - accuracy: 0.6879\n",
      "Epoch 108/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7210 - accuracy: 0.6891\n",
      "Epoch 109/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7233 - accuracy: 0.6862\n",
      "Epoch 110/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7207 - accuracy: 0.6837\n",
      "Epoch 111/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7243 - accuracy: 0.6822\n",
      "Epoch 112/200\n",
      "252/252 [==============================] - 0s 989us/step - loss: 0.7112 - accuracy: 0.6885\n",
      "Epoch 113/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7257 - accuracy: 0.6781\n",
      "Epoch 114/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7114 - accuracy: 0.6857\n",
      "Epoch 115/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7181 - accuracy: 0.6858\n",
      "Epoch 116/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7154 - accuracy: 0.6883\n",
      "Epoch 117/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7019 - accuracy: 0.6924\n",
      "Epoch 118/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7166 - accuracy: 0.6823\n",
      "Epoch 119/200\n",
      "252/252 [==============================] - 0s 998us/step - loss: 0.7024 - accuracy: 0.6880\n",
      "Epoch 120/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7128 - accuracy: 0.6954\n",
      "Epoch 121/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7323 - accuracy: 0.6850\n",
      "Epoch 122/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7214 - accuracy: 0.6885\n",
      "Epoch 123/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7317 - accuracy: 0.6739\n",
      "Epoch 124/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7364 - accuracy: 0.6769\n",
      "Epoch 125/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7171 - accuracy: 0.6856\n",
      "Epoch 126/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7344 - accuracy: 0.6702\n",
      "Epoch 127/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7261 - accuracy: 0.6890\n",
      "Epoch 128/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7093 - accuracy: 0.6998\n",
      "Epoch 129/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7244 - accuracy: 0.6840\n",
      "Epoch 130/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7365 - accuracy: 0.6806\n",
      "Epoch 131/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6957 - accuracy: 0.7041\n",
      "Epoch 132/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7354 - accuracy: 0.6748\n",
      "Epoch 133/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.6912\n",
      "Epoch 134/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7246 - accuracy: 0.6799\n",
      "Epoch 135/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7255 - accuracy: 0.6780\n",
      "Epoch 136/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7037 - accuracy: 0.6941\n",
      "Epoch 137/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7275 - accuracy: 0.6839\n",
      "Epoch 138/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7188 - accuracy: 0.6879\n",
      "Epoch 139/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7193 - accuracy: 0.6905\n",
      "Epoch 140/200\n",
      "252/252 [==============================] - 0s 994us/step - loss: 0.7235 - accuracy: 0.6883\n",
      "Epoch 141/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7150 - accuracy: 0.6872\n",
      "Epoch 142/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7269 - accuracy: 0.6889\n",
      "Epoch 143/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7158 - accuracy: 0.6893\n",
      "Epoch 144/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.7053\n",
      "Epoch 145/200\n",
      "252/252 [==============================] - 0s 991us/step - loss: 0.7145 - accuracy: 0.6890\n",
      "Epoch 146/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7015 - accuracy: 0.7124\n",
      "Epoch 147/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6969 - accuracy: 0.6917\n",
      "Epoch 148/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.6894\n",
      "Epoch 149/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7128 - accuracy: 0.6917\n",
      "Epoch 150/200\n",
      "252/252 [==============================] - 0s 988us/step - loss: 0.7134 - accuracy: 0.6867\n",
      "Epoch 151/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7180 - accuracy: 0.6780\n",
      "Epoch 152/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7232 - accuracy: 0.6867\n",
      "Epoch 153/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7257 - accuracy: 0.6787\n",
      "Epoch 154/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7259 - accuracy: 0.6737\n",
      "Epoch 155/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7067 - accuracy: 0.6966\n",
      "Epoch 156/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7256 - accuracy: 0.6791\n",
      "Epoch 157/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7262 - accuracy: 0.6794\n",
      "Epoch 158/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7197 - accuracy: 0.6767\n",
      "Epoch 159/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7193 - accuracy: 0.6846\n",
      "Epoch 160/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7238 - accuracy: 0.6870\n",
      "Epoch 161/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7052 - accuracy: 0.6961\n",
      "Epoch 162/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7124 - accuracy: 0.6891\n",
      "Epoch 163/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7157 - accuracy: 0.6868\n",
      "Epoch 164/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7257 - accuracy: 0.6702\n",
      "Epoch 165/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7314 - accuracy: 0.6803\n",
      "Epoch 166/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7169 - accuracy: 0.6843\n",
      "Epoch 167/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7167 - accuracy: 0.6831\n",
      "Epoch 168/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7099 - accuracy: 0.6848\n",
      "Epoch 169/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7077 - accuracy: 0.6911\n",
      "Epoch 170/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7179 - accuracy: 0.6950\n",
      "Epoch 171/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7097 - accuracy: 0.6883\n",
      "Epoch 172/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.6847\n",
      "Epoch 173/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7080 - accuracy: 0.6863\n",
      "Epoch 174/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7064 - accuracy: 0.6884\n",
      "Epoch 175/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7208 - accuracy: 0.6824\n",
      "Epoch 176/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7323 - accuracy: 0.6875\n",
      "Epoch 177/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7094 - accuracy: 0.6837\n",
      "Epoch 178/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7230 - accuracy: 0.6768\n",
      "Epoch 179/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.6955\n",
      "Epoch 180/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7065 - accuracy: 0.6922\n",
      "Epoch 181/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7151 - accuracy: 0.6867\n",
      "Epoch 182/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7286 - accuracy: 0.6828\n",
      "Epoch 183/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7058 - accuracy: 0.6969\n",
      "Epoch 184/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7068 - accuracy: 0.6868\n",
      "Epoch 185/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7203 - accuracy: 0.6828\n",
      "Epoch 186/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7174 - accuracy: 0.6830\n",
      "Epoch 187/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7183 - accuracy: 0.6764\n",
      "Epoch 188/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7188 - accuracy: 0.6826\n",
      "Epoch 189/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7235 - accuracy: 0.6743\n",
      "Epoch 190/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7102 - accuracy: 0.6846\n",
      "Epoch 191/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7214 - accuracy: 0.6738\n",
      "Epoch 192/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7123 - accuracy: 0.6927\n",
      "Epoch 193/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7177 - accuracy: 0.6797\n",
      "Epoch 194/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7226 - accuracy: 0.6922\n",
      "Epoch 195/200\n",
      "252/252 [==============================] - 0s 991us/step - loss: 0.7173 - accuracy: 0.6886\n",
      "Epoch 196/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7224 - accuracy: 0.6833\n",
      "Epoch 197/200\n",
      "252/252 [==============================] - 0s 997us/step - loss: 0.6989 - accuracy: 0.6968\n",
      "Epoch 198/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7071 - accuracy: 0.6849\n",
      "Epoch 199/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7247 - accuracy: 0.6885\n",
      "Epoch 200/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7104 - accuracy: 0.6845\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 815us/step - loss: 0.7773 - accuracy: 0.6393\n",
      "Acc:\n",
      "0.6392536163330078\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Acc:')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_228\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_686 (Dense)            (None, 14)                266       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_687 (Dense)            (None, 12)                180       \n",
      "_________________________________________________________________\n",
      "dense_688 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_689 (Dense)            (None, 3)                 39        \n",
      "=================================================================\n",
      "Total params: 641\n",
      "Trainable params: 641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu', input_shape=(18,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(12, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(12, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "252/252 [==============================] - 1s 1ms/step - loss: 1.0326 - accuracy: 0.5088\n",
      "Epoch 2/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7697 - accuracy: 0.6472\n",
      "Epoch 3/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7488 - accuracy: 0.6511\n",
      "Epoch 4/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7444 - accuracy: 0.6605\n",
      "Epoch 5/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7416 - accuracy: 0.6586\n",
      "Epoch 6/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7432 - accuracy: 0.6627\n",
      "Epoch 7/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7441 - accuracy: 0.6660\n",
      "Epoch 8/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7485 - accuracy: 0.6643\n",
      "Epoch 9/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7487 - accuracy: 0.6641\n",
      "Epoch 10/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7343 - accuracy: 0.6586\n",
      "Epoch 11/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7532 - accuracy: 0.6598\n",
      "Epoch 12/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7321 - accuracy: 0.6686\n",
      "Epoch 13/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7237 - accuracy: 0.6721\n",
      "Epoch 14/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7214 - accuracy: 0.6735\n",
      "Epoch 15/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7504 - accuracy: 0.6543\n",
      "Epoch 16/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7430 - accuracy: 0.6693\n",
      "Epoch 17/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7350 - accuracy: 0.6731\n",
      "Epoch 18/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7281 - accuracy: 0.6783\n",
      "Epoch 19/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7356 - accuracy: 0.6581\n",
      "Epoch 20/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7273 - accuracy: 0.6817\n",
      "Epoch 21/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7351 - accuracy: 0.6696\n",
      "Epoch 22/200\n",
      "252/252 [==============================] - 0s 1000us/step - loss: 0.7374 - accuracy: 0.6694\n",
      "Epoch 23/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7430 - accuracy: 0.6613\n",
      "Epoch 24/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7283 - accuracy: 0.6777\n",
      "Epoch 25/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7430 - accuracy: 0.6647\n",
      "Epoch 26/200\n",
      "252/252 [==============================] - 0s 1000us/step - loss: 0.7265 - accuracy: 0.6721\n",
      "Epoch 27/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7342 - accuracy: 0.6771\n",
      "Epoch 28/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7199 - accuracy: 0.6797\n",
      "Epoch 29/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7343 - accuracy: 0.6645\n",
      "Epoch 30/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7466 - accuracy: 0.6626\n",
      "Epoch 31/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7296 - accuracy: 0.6698\n",
      "Epoch 32/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7294 - accuracy: 0.6759\n",
      "Epoch 33/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7199 - accuracy: 0.6834\n",
      "Epoch 34/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7118 - accuracy: 0.6835\n",
      "Epoch 35/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7216 - accuracy: 0.6755\n",
      "Epoch 36/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7099 - accuracy: 0.6856\n",
      "Epoch 37/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7309 - accuracy: 0.6728\n",
      "Epoch 38/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7432 - accuracy: 0.6705\n",
      "Epoch 39/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7074 - accuracy: 0.6824\n",
      "Epoch 40/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7368 - accuracy: 0.6646\n",
      "Epoch 41/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7267 - accuracy: 0.6692\n",
      "Epoch 42/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7440 - accuracy: 0.6754\n",
      "Epoch 43/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7327 - accuracy: 0.6777\n",
      "Epoch 44/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7120 - accuracy: 0.6868\n",
      "Epoch 45/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7238 - accuracy: 0.6767\n",
      "Epoch 46/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7221 - accuracy: 0.6766\n",
      "Epoch 47/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7156 - accuracy: 0.6868\n",
      "Epoch 48/200\n",
      "252/252 [==============================] - 0s 999us/step - loss: 0.7596 - accuracy: 0.6676\n",
      "Epoch 49/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7244 - accuracy: 0.6848\n",
      "Epoch 50/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7444 - accuracy: 0.6680\n",
      "Epoch 51/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7232 - accuracy: 0.6818\n",
      "Epoch 52/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7265 - accuracy: 0.6828\n",
      "Epoch 53/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7305 - accuracy: 0.6686\n",
      "Epoch 54/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7184 - accuracy: 0.6756\n",
      "Epoch 55/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7447 - accuracy: 0.6609\n",
      "Epoch 56/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7014 - accuracy: 0.6929\n",
      "Epoch 57/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7322 - accuracy: 0.6828\n",
      "Epoch 58/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7290 - accuracy: 0.6706\n",
      "Epoch 59/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7109 - accuracy: 0.6850\n",
      "Epoch 60/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7320 - accuracy: 0.6683\n",
      "Epoch 61/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7166 - accuracy: 0.6855\n",
      "Epoch 62/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7398 - accuracy: 0.6776\n",
      "Epoch 63/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7372 - accuracy: 0.6667\n",
      "Epoch 64/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7307 - accuracy: 0.6658\n",
      "Epoch 65/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7149 - accuracy: 0.6831\n",
      "Epoch 66/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7038 - accuracy: 0.6906\n",
      "Epoch 67/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7244 - accuracy: 0.6818\n",
      "Epoch 68/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7098 - accuracy: 0.6872\n",
      "Epoch 69/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7299 - accuracy: 0.6741\n",
      "Epoch 70/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7239 - accuracy: 0.6812\n",
      "Epoch 71/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7221 - accuracy: 0.6865\n",
      "Epoch 72/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7066 - accuracy: 0.6982\n",
      "Epoch 73/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.7068\n",
      "Epoch 74/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7338 - accuracy: 0.6664\n",
      "Epoch 75/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7269 - accuracy: 0.6866\n",
      "Epoch 76/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7088 - accuracy: 0.6888\n",
      "Epoch 77/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7348 - accuracy: 0.6809\n",
      "Epoch 78/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7273 - accuracy: 0.6705\n",
      "Epoch 79/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7208 - accuracy: 0.6907\n",
      "Epoch 80/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7271 - accuracy: 0.6814\n",
      "Epoch 81/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7333 - accuracy: 0.6741\n",
      "Epoch 82/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7269 - accuracy: 0.6836\n",
      "Epoch 83/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7164 - accuracy: 0.6849\n",
      "Epoch 84/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7271 - accuracy: 0.6796\n",
      "Epoch 85/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7284 - accuracy: 0.6731\n",
      "Epoch 86/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7176 - accuracy: 0.6844\n",
      "Epoch 87/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.6959\n",
      "Epoch 88/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7247 - accuracy: 0.6728\n",
      "Epoch 89/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7316 - accuracy: 0.6738\n",
      "Epoch 90/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7081 - accuracy: 0.6785\n",
      "Epoch 91/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7199 - accuracy: 0.6821\n",
      "Epoch 92/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7127 - accuracy: 0.6883\n",
      "Epoch 93/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7196 - accuracy: 0.6823\n",
      "Epoch 94/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7326 - accuracy: 0.6794\n",
      "Epoch 95/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7153 - accuracy: 0.6867\n",
      "Epoch 96/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7190 - accuracy: 0.6867\n",
      "Epoch 97/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7211 - accuracy: 0.6825\n",
      "Epoch 98/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7053 - accuracy: 0.6942\n",
      "Epoch 99/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7174 - accuracy: 0.6812\n",
      "Epoch 100/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7087 - accuracy: 0.6876\n",
      "Epoch 101/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7168 - accuracy: 0.6903\n",
      "Epoch 102/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7192 - accuracy: 0.6873\n",
      "Epoch 103/200\n",
      "252/252 [==============================] - 0s 998us/step - loss: 0.7151 - accuracy: 0.6922\n",
      "Epoch 104/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7241 - accuracy: 0.6663\n",
      "Epoch 105/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7209 - accuracy: 0.6768\n",
      "Epoch 106/200\n",
      "252/252 [==============================] - 0s 996us/step - loss: 0.7133 - accuracy: 0.6886\n",
      "Epoch 107/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7069 - accuracy: 0.6902\n",
      "Epoch 108/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7505 - accuracy: 0.6684\n",
      "Epoch 109/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7100 - accuracy: 0.6871\n",
      "Epoch 110/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7285 - accuracy: 0.6893\n",
      "Epoch 111/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7178 - accuracy: 0.6963\n",
      "Epoch 112/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7011 - accuracy: 0.6926\n",
      "Epoch 113/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7086 - accuracy: 0.6876\n",
      "Epoch 114/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7103 - accuracy: 0.6855\n",
      "Epoch 115/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7120 - accuracy: 0.6848\n",
      "Epoch 116/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7192 - accuracy: 0.6816\n",
      "Epoch 117/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7194 - accuracy: 0.6853\n",
      "Epoch 118/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7077 - accuracy: 0.6872\n",
      "Epoch 119/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7169 - accuracy: 0.6797\n",
      "Epoch 120/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6961 - accuracy: 0.7013\n",
      "Epoch 121/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7126 - accuracy: 0.6887\n",
      "Epoch 122/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7062 - accuracy: 0.6908\n",
      "Epoch 123/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7194 - accuracy: 0.6769\n",
      "Epoch 124/200\n",
      "252/252 [==============================] - 0s 994us/step - loss: 0.7382 - accuracy: 0.6672\n",
      "Epoch 125/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7187 - accuracy: 0.6879\n",
      "Epoch 126/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7112 - accuracy: 0.6959\n",
      "Epoch 127/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7051 - accuracy: 0.6843\n",
      "Epoch 128/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7174 - accuracy: 0.6907\n",
      "Epoch 129/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7219 - accuracy: 0.6808\n",
      "Epoch 130/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7140 - accuracy: 0.6877\n",
      "Epoch 131/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7232 - accuracy: 0.6854\n",
      "Epoch 132/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7206 - accuracy: 0.6708\n",
      "Epoch 133/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7171 - accuracy: 0.6873\n",
      "Epoch 134/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7233 - accuracy: 0.6780\n",
      "Epoch 135/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7395 - accuracy: 0.6689\n",
      "Epoch 136/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7087 - accuracy: 0.6893\n",
      "Epoch 137/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7100 - accuracy: 0.6927\n",
      "Epoch 138/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7088 - accuracy: 0.6860\n",
      "Epoch 139/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7102 - accuracy: 0.6816\n",
      "Epoch 140/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7188 - accuracy: 0.6771\n",
      "Epoch 141/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7164 - accuracy: 0.6901\n",
      "Epoch 142/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7212 - accuracy: 0.6785\n",
      "Epoch 143/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7216 - accuracy: 0.6726\n",
      "Epoch 144/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7149 - accuracy: 0.6882\n",
      "Epoch 145/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7200 - accuracy: 0.6845\n",
      "Epoch 146/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7020 - accuracy: 0.6952\n",
      "Epoch 147/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7288 - accuracy: 0.6839\n",
      "Epoch 148/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7270 - accuracy: 0.6834\n",
      "Epoch 149/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7078 - accuracy: 0.6924\n",
      "Epoch 150/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7039 - accuracy: 0.6954\n",
      "Epoch 151/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7016 - accuracy: 0.7009\n",
      "Epoch 152/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7185 - accuracy: 0.6859\n",
      "Epoch 153/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.6947\n",
      "Epoch 154/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7011 - accuracy: 0.6871\n",
      "Epoch 155/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7194 - accuracy: 0.6888\n",
      "Epoch 156/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.6848\n",
      "Epoch 157/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7203 - accuracy: 0.6843\n",
      "Epoch 158/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7117 - accuracy: 0.6836\n",
      "Epoch 159/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7226 - accuracy: 0.6749\n",
      "Epoch 160/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7127 - accuracy: 0.6892\n",
      "Epoch 161/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7301 - accuracy: 0.6801\n",
      "Epoch 162/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7292 - accuracy: 0.6735\n",
      "Epoch 163/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7311 - accuracy: 0.6873\n",
      "Epoch 164/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6984 - accuracy: 0.6974\n",
      "Epoch 165/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7090 - accuracy: 0.6881\n",
      "Epoch 166/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7283 - accuracy: 0.6788\n",
      "Epoch 167/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7225 - accuracy: 0.6897\n",
      "Epoch 168/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7077 - accuracy: 0.6843\n",
      "Epoch 169/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7150 - accuracy: 0.6796\n",
      "Epoch 170/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6993 - accuracy: 0.7004\n",
      "Epoch 171/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7018 - accuracy: 0.6867\n",
      "Epoch 172/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7273 - accuracy: 0.6785\n",
      "Epoch 173/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7206 - accuracy: 0.6840\n",
      "Epoch 174/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.6795\n",
      "Epoch 175/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7047 - accuracy: 0.6946\n",
      "Epoch 176/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.6909\n",
      "Epoch 177/200\n",
      "252/252 [==============================] - 0s 998us/step - loss: 0.7137 - accuracy: 0.6900\n",
      "Epoch 178/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7047 - accuracy: 0.6891\n",
      "Epoch 179/200\n",
      "252/252 [==============================] - 0s 999us/step - loss: 0.7221 - accuracy: 0.6879\n",
      "Epoch 180/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7103 - accuracy: 0.6842\n",
      "Epoch 181/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7140 - accuracy: 0.6928\n",
      "Epoch 182/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7155 - accuracy: 0.6974\n",
      "Epoch 183/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7078 - accuracy: 0.6816\n",
      "Epoch 184/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7091 - accuracy: 0.6922\n",
      "Epoch 185/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7104 - accuracy: 0.6865\n",
      "Epoch 186/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7162 - accuracy: 0.6854\n",
      "Epoch 187/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7165 - accuracy: 0.6932\n",
      "Epoch 188/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7001 - accuracy: 0.6946\n",
      "Epoch 189/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7357 - accuracy: 0.6650\n",
      "Epoch 190/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.6970\n",
      "Epoch 191/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7293 - accuracy: 0.6820\n",
      "Epoch 192/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7189 - accuracy: 0.6886\n",
      "Epoch 193/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7283 - accuracy: 0.6806\n",
      "Epoch 194/200\n",
      "252/252 [==============================] - 0s 999us/step - loss: 0.7133 - accuracy: 0.6826\n",
      "Epoch 195/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.6919\n",
      "Epoch 196/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7185 - accuracy: 0.6824\n",
      "Epoch 197/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7171 - accuracy: 0.6750\n",
      "Epoch 198/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7169 - accuracy: 0.6719\n",
      "Epoch 199/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7220 - accuracy: 0.6791\n",
      "Epoch 200/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7239 - accuracy: 0.6748\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 822us/step - loss: 0.7690 - accuracy: 0.6413\n",
      "Acc:\n",
      "0.641326904296875\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Acc:')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_229\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_690 (Dense)            (None, 14)                266       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_691 (Dense)            (None, 12)                180       \n",
      "_________________________________________________________________\n",
      "dense_692 (Dense)            (None, 14)                182       \n",
      "_________________________________________________________________\n",
      "dense_693 (Dense)            (None, 3)                 45        \n",
      "=================================================================\n",
      "Total params: 673\n",
      "Trainable params: 673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu', input_shape=(18,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(12, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "252/252 [==============================] - 1s 1ms/step - loss: 1.0196 - accuracy: 0.4891\n",
      "Epoch 2/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7788 - accuracy: 0.6540\n",
      "Epoch 3/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7344 - accuracy: 0.6655\n",
      "Epoch 4/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7510 - accuracy: 0.6664\n",
      "Epoch 5/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7378 - accuracy: 0.6686\n",
      "Epoch 6/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7321 - accuracy: 0.6688\n",
      "Epoch 7/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7494 - accuracy: 0.6578\n",
      "Epoch 8/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7525 - accuracy: 0.6641\n",
      "Epoch 9/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7377 - accuracy: 0.6685\n",
      "Epoch 10/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7312 - accuracy: 0.6666\n",
      "Epoch 11/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7371 - accuracy: 0.6666\n",
      "Epoch 12/200\n",
      "252/252 [==============================] - 0s 997us/step - loss: 0.7401 - accuracy: 0.6629\n",
      "Epoch 13/200\n",
      "252/252 [==============================] - 0s 999us/step - loss: 0.7400 - accuracy: 0.6692\n",
      "Epoch 14/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7239 - accuracy: 0.6803\n",
      "Epoch 15/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7459 - accuracy: 0.6615\n",
      "Epoch 16/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7473 - accuracy: 0.6579\n",
      "Epoch 17/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7484 - accuracy: 0.6564\n",
      "Epoch 18/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7124 - accuracy: 0.6809\n",
      "Epoch 19/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7380 - accuracy: 0.6684\n",
      "Epoch 20/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7316 - accuracy: 0.6626\n",
      "Epoch 21/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7121 - accuracy: 0.6780\n",
      "Epoch 22/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7226 - accuracy: 0.6765\n",
      "Epoch 23/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7287 - accuracy: 0.6692\n",
      "Epoch 24/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7294 - accuracy: 0.6732\n",
      "Epoch 25/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7427 - accuracy: 0.6656\n",
      "Epoch 26/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7051 - accuracy: 0.6845\n",
      "Epoch 27/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7318 - accuracy: 0.6664\n",
      "Epoch 28/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7419 - accuracy: 0.6707\n",
      "Epoch 29/200\n",
      "252/252 [==============================] - 0s 998us/step - loss: 0.7346 - accuracy: 0.6629\n",
      "Epoch 30/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7366 - accuracy: 0.6668\n",
      "Epoch 31/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7241 - accuracy: 0.6726\n",
      "Epoch 32/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7311 - accuracy: 0.6691\n",
      "Epoch 33/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7332 - accuracy: 0.6668\n",
      "Epoch 34/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7234 - accuracy: 0.6785\n",
      "Epoch 35/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7370 - accuracy: 0.6734\n",
      "Epoch 36/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7358 - accuracy: 0.6779\n",
      "Epoch 37/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7361 - accuracy: 0.6683\n",
      "Epoch 38/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7311 - accuracy: 0.6734\n",
      "Epoch 39/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7318 - accuracy: 0.6794\n",
      "Epoch 40/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7210 - accuracy: 0.6809\n",
      "Epoch 41/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7294 - accuracy: 0.6681\n",
      "Epoch 42/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7340 - accuracy: 0.6716\n",
      "Epoch 43/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7363 - accuracy: 0.6861\n",
      "Epoch 44/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7154 - accuracy: 0.6946\n",
      "Epoch 45/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7141 - accuracy: 0.6749\n",
      "Epoch 46/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7017 - accuracy: 0.6887\n",
      "Epoch 47/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7212 - accuracy: 0.6857\n",
      "Epoch 48/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7346 - accuracy: 0.6781\n",
      "Epoch 49/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7261 - accuracy: 0.6742\n",
      "Epoch 50/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7231 - accuracy: 0.6837\n",
      "Epoch 51/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7325 - accuracy: 0.6747\n",
      "Epoch 52/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7177 - accuracy: 0.6822\n",
      "Epoch 53/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7222 - accuracy: 0.6906\n",
      "Epoch 54/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7216 - accuracy: 0.6788\n",
      "Epoch 55/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7375 - accuracy: 0.6753\n",
      "Epoch 56/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7204 - accuracy: 0.6912\n",
      "Epoch 57/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7327 - accuracy: 0.6773\n",
      "Epoch 58/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7109 - accuracy: 0.6921\n",
      "Epoch 59/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7152 - accuracy: 0.6800\n",
      "Epoch 60/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7321 - accuracy: 0.6767\n",
      "Epoch 61/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7108 - accuracy: 0.6823\n",
      "Epoch 62/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7290 - accuracy: 0.6864\n",
      "Epoch 63/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7267 - accuracy: 0.6854\n",
      "Epoch 64/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7236 - accuracy: 0.6767\n",
      "Epoch 65/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7091 - accuracy: 0.6866\n",
      "Epoch 66/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7158 - accuracy: 0.6807\n",
      "Epoch 67/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7173 - accuracy: 0.6927\n",
      "Epoch 68/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7023 - accuracy: 0.6908\n",
      "Epoch 69/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7219 - accuracy: 0.6860\n",
      "Epoch 70/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7395 - accuracy: 0.6754\n",
      "Epoch 71/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7098 - accuracy: 0.6959\n",
      "Epoch 72/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7279 - accuracy: 0.6851\n",
      "Epoch 73/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7214 - accuracy: 0.6862\n",
      "Epoch 74/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7194 - accuracy: 0.6737\n",
      "Epoch 75/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7201 - accuracy: 0.6856\n",
      "Epoch 76/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7155 - accuracy: 0.6782\n",
      "Epoch 77/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7191 - accuracy: 0.6850\n",
      "Epoch 78/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7169 - accuracy: 0.6930\n",
      "Epoch 79/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7090 - accuracy: 0.6980\n",
      "Epoch 80/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7214 - accuracy: 0.6878\n",
      "Epoch 81/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7135 - accuracy: 0.6913\n",
      "Epoch 82/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7145 - accuracy: 0.6876\n",
      "Epoch 83/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7235 - accuracy: 0.6848\n",
      "Epoch 84/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7130 - accuracy: 0.6879\n",
      "Epoch 85/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7058 - accuracy: 0.6900\n",
      "Epoch 86/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7259 - accuracy: 0.6745\n",
      "Epoch 87/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7167 - accuracy: 0.6927\n",
      "Epoch 88/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7239 - accuracy: 0.6763\n",
      "Epoch 89/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7304 - accuracy: 0.6841\n",
      "Epoch 90/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7195 - accuracy: 0.6906\n",
      "Epoch 91/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7258 - accuracy: 0.6725\n",
      "Epoch 92/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7196 - accuracy: 0.6817\n",
      "Epoch 93/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7220 - accuracy: 0.6773\n",
      "Epoch 94/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7143 - accuracy: 0.6816\n",
      "Epoch 95/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7034 - accuracy: 0.6884\n",
      "Epoch 96/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7113 - accuracy: 0.6929\n",
      "Epoch 97/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7266 - accuracy: 0.6837\n",
      "Epoch 98/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7230 - accuracy: 0.6857\n",
      "Epoch 99/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7113 - accuracy: 0.6881\n",
      "Epoch 100/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7206 - accuracy: 0.6775\n",
      "Epoch 101/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7360 - accuracy: 0.6745\n",
      "Epoch 102/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7143 - accuracy: 0.6766\n",
      "Epoch 103/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7222 - accuracy: 0.6836\n",
      "Epoch 104/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7193 - accuracy: 0.6859\n",
      "Epoch 105/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7250 - accuracy: 0.6812\n",
      "Epoch 106/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7161 - accuracy: 0.6819\n",
      "Epoch 107/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7182 - accuracy: 0.6851\n",
      "Epoch 108/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6965 - accuracy: 0.6931\n",
      "Epoch 109/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7122 - accuracy: 0.6966\n",
      "Epoch 110/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7160 - accuracy: 0.6957\n",
      "Epoch 111/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7222 - accuracy: 0.6775\n",
      "Epoch 112/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7112 - accuracy: 0.6974\n",
      "Epoch 113/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7009 - accuracy: 0.6936\n",
      "Epoch 114/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7115 - accuracy: 0.6791\n",
      "Epoch 115/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7128 - accuracy: 0.6948\n",
      "Epoch 116/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6992 - accuracy: 0.6932\n",
      "Epoch 117/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7266 - accuracy: 0.6775\n",
      "Epoch 118/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7192 - accuracy: 0.6856\n",
      "Epoch 119/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7072 - accuracy: 0.6881\n",
      "Epoch 120/200\n",
      "252/252 [==============================] - 0s 990us/step - loss: 0.7211 - accuracy: 0.6900\n",
      "Epoch 121/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.7002\n",
      "Epoch 122/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7136 - accuracy: 0.6982\n",
      "Epoch 123/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7151 - accuracy: 0.6871\n",
      "Epoch 124/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7097 - accuracy: 0.6941\n",
      "Epoch 125/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7045 - accuracy: 0.6907\n",
      "Epoch 126/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7217 - accuracy: 0.6885\n",
      "Epoch 127/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7091 - accuracy: 0.6915\n",
      "Epoch 128/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7080 - accuracy: 0.6883\n",
      "Epoch 129/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7046 - accuracy: 0.7065\n",
      "Epoch 130/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7116 - accuracy: 0.6877\n",
      "Epoch 131/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7188 - accuracy: 0.6900\n",
      "Epoch 132/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.7009\n",
      "Epoch 133/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7097 - accuracy: 0.6890\n",
      "Epoch 134/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7247 - accuracy: 0.6822\n",
      "Epoch 135/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7261 - accuracy: 0.6932\n",
      "Epoch 136/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.7099\n",
      "Epoch 137/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7098 - accuracy: 0.6884\n",
      "Epoch 138/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7296 - accuracy: 0.6772\n",
      "Epoch 139/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7219 - accuracy: 0.6842\n",
      "Epoch 140/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7116 - accuracy: 0.6941\n",
      "Epoch 141/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7186 - accuracy: 0.6864\n",
      "Epoch 142/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7131 - accuracy: 0.6834\n",
      "Epoch 143/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7164 - accuracy: 0.6885\n",
      "Epoch 144/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7091 - accuracy: 0.6973\n",
      "Epoch 145/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7083 - accuracy: 0.6969\n",
      "Epoch 146/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7022 - accuracy: 0.6995\n",
      "Epoch 147/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7173 - accuracy: 0.6897\n",
      "Epoch 148/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7136 - accuracy: 0.6955\n",
      "Epoch 149/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7170 - accuracy: 0.6951\n",
      "Epoch 150/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7035 - accuracy: 0.6972\n",
      "Epoch 151/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7175 - accuracy: 0.6970\n",
      "Epoch 152/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.7016\n",
      "Epoch 153/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7359 - accuracy: 0.6765\n",
      "Epoch 154/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7291 - accuracy: 0.6865\n",
      "Epoch 155/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7127 - accuracy: 0.6914\n",
      "Epoch 156/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7094 - accuracy: 0.6930\n",
      "Epoch 157/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7059 - accuracy: 0.6984\n",
      "Epoch 158/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7110 - accuracy: 0.6933\n",
      "Epoch 159/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7195 - accuracy: 0.6845\n",
      "Epoch 160/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7157 - accuracy: 0.6860\n",
      "Epoch 161/200\n",
      "252/252 [==============================] - 0s 995us/step - loss: 0.7223 - accuracy: 0.6861\n",
      "Epoch 162/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7116 - accuracy: 0.6932\n",
      "Epoch 163/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7062 - accuracy: 0.6915\n",
      "Epoch 164/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7306 - accuracy: 0.6841\n",
      "Epoch 165/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7088 - accuracy: 0.6921\n",
      "Epoch 166/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7153 - accuracy: 0.6893\n",
      "Epoch 167/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7340 - accuracy: 0.6770\n",
      "Epoch 168/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7052 - accuracy: 0.6999\n",
      "Epoch 169/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6972 - accuracy: 0.7017\n",
      "Epoch 170/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7192 - accuracy: 0.6927\n",
      "Epoch 171/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7288 - accuracy: 0.6900\n",
      "Epoch 172/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7085 - accuracy: 0.6861\n",
      "Epoch 173/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7151 - accuracy: 0.6938\n",
      "Epoch 174/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7014 - accuracy: 0.7019\n",
      "Epoch 175/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7097 - accuracy: 0.6999\n",
      "Epoch 176/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7080 - accuracy: 0.6954\n",
      "Epoch 177/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7102 - accuracy: 0.6916\n",
      "Epoch 178/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6983 - accuracy: 0.6927\n",
      "Epoch 179/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7058 - accuracy: 0.7003\n",
      "Epoch 180/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7119 - accuracy: 0.6959\n",
      "Epoch 181/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6994 - accuracy: 0.7041\n",
      "Epoch 182/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7145 - accuracy: 0.6937\n",
      "Epoch 183/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7229 - accuracy: 0.6853\n",
      "Epoch 184/200\n",
      "252/252 [==============================] - 0s 999us/step - loss: 0.6886 - accuracy: 0.7037\n",
      "Epoch 185/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7119 - accuracy: 0.6854\n",
      "Epoch 186/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7096 - accuracy: 0.6919\n",
      "Epoch 187/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7116 - accuracy: 0.6873\n",
      "Epoch 188/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7222 - accuracy: 0.6915\n",
      "Epoch 189/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7160 - accuracy: 0.6892\n",
      "Epoch 190/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7115 - accuracy: 0.6951\n",
      "Epoch 191/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7100 - accuracy: 0.6945\n",
      "Epoch 192/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7172 - accuracy: 0.6869\n",
      "Epoch 193/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.7040\n",
      "Epoch 194/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7170 - accuracy: 0.6935\n",
      "Epoch 195/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7094 - accuracy: 0.6958\n",
      "Epoch 196/200\n",
      "252/252 [==============================] - 0s 999us/step - loss: 0.7131 - accuracy: 0.6824\n",
      "Epoch 197/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7177 - accuracy: 0.6875\n",
      "Epoch 198/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.7032\n",
      "Epoch 199/200\n",
      "252/252 [==============================] - 0s 998us/step - loss: 0.7116 - accuracy: 0.6867\n",
      "Epoch 200/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.7012\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 817us/step - loss: 0.7712 - accuracy: 0.6399\n",
      "Acc:\n",
      "0.6399447321891785\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Acc:')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_230\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_694 (Dense)            (None, 14)                266       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_695 (Dense)            (None, 14)                210       \n",
      "_________________________________________________________________\n",
      "dense_696 (Dense)            (None, 14)                210       \n",
      "_________________________________________________________________\n",
      "dense_697 (Dense)            (None, 3)                 45        \n",
      "=================================================================\n",
      "Total params: 731\n",
      "Trainable params: 731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu', input_shape=(18,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "252/252 [==============================] - 1s 1ms/step - loss: 1.0262 - accuracy: 0.5054\n",
      "Epoch 2/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7783 - accuracy: 0.6454\n",
      "Epoch 3/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7429 - accuracy: 0.6626\n",
      "Epoch 4/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7537 - accuracy: 0.6542\n",
      "Epoch 5/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7473 - accuracy: 0.6597\n",
      "Epoch 6/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7450 - accuracy: 0.6712\n",
      "Epoch 7/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7462 - accuracy: 0.6606\n",
      "Epoch 8/200\n",
      "252/252 [==============================] - 0s 982us/step - loss: 0.7396 - accuracy: 0.6663\n",
      "Epoch 9/200\n",
      "252/252 [==============================] - 0s 995us/step - loss: 0.7423 - accuracy: 0.6666\n",
      "Epoch 10/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7413 - accuracy: 0.6628\n",
      "Epoch 11/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7306 - accuracy: 0.6655\n",
      "Epoch 12/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7410 - accuracy: 0.6639\n",
      "Epoch 13/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7430 - accuracy: 0.6570\n",
      "Epoch 14/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7474 - accuracy: 0.6595\n",
      "Epoch 15/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7467 - accuracy: 0.6556\n",
      "Epoch 16/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7419 - accuracy: 0.6641\n",
      "Epoch 17/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7379 - accuracy: 0.6624\n",
      "Epoch 18/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7328 - accuracy: 0.6678\n",
      "Epoch 19/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7276 - accuracy: 0.6605\n",
      "Epoch 20/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7356 - accuracy: 0.6650\n",
      "Epoch 21/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7185 - accuracy: 0.6740\n",
      "Epoch 22/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7154 - accuracy: 0.6800\n",
      "Epoch 23/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7221 - accuracy: 0.6790\n",
      "Epoch 24/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7239 - accuracy: 0.6687\n",
      "Epoch 25/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7387 - accuracy: 0.6633\n",
      "Epoch 26/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7284 - accuracy: 0.6687\n",
      "Epoch 27/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7316 - accuracy: 0.6722\n",
      "Epoch 28/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7332 - accuracy: 0.6665\n",
      "Epoch 29/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7230 - accuracy: 0.6788\n",
      "Epoch 30/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7102 - accuracy: 0.6746\n",
      "Epoch 31/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7284 - accuracy: 0.6700\n",
      "Epoch 32/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7236 - accuracy: 0.6786\n",
      "Epoch 33/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7355 - accuracy: 0.6663\n",
      "Epoch 34/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7235 - accuracy: 0.6742\n",
      "Epoch 35/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7278 - accuracy: 0.6710\n",
      "Epoch 36/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7250 - accuracy: 0.6783\n",
      "Epoch 37/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7290 - accuracy: 0.6665\n",
      "Epoch 38/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7161 - accuracy: 0.6810\n",
      "Epoch 39/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7195 - accuracy: 0.6772\n",
      "Epoch 40/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7177 - accuracy: 0.6772\n",
      "Epoch 41/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7220 - accuracy: 0.6871\n",
      "Epoch 42/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7303 - accuracy: 0.6842\n",
      "Epoch 43/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7359 - accuracy: 0.6714\n",
      "Epoch 44/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7229 - accuracy: 0.6710\n",
      "Epoch 45/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7160 - accuracy: 0.6802\n",
      "Epoch 46/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7301 - accuracy: 0.6645\n",
      "Epoch 47/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7499 - accuracy: 0.6605\n",
      "Epoch 48/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7212 - accuracy: 0.6774\n",
      "Epoch 49/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7369 - accuracy: 0.6752\n",
      "Epoch 50/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7167 - accuracy: 0.6882\n",
      "Epoch 51/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7375 - accuracy: 0.6782\n",
      "Epoch 52/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7309 - accuracy: 0.6800\n",
      "Epoch 53/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7226 - accuracy: 0.6755\n",
      "Epoch 54/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7298 - accuracy: 0.6748\n",
      "Epoch 55/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7384 - accuracy: 0.6812\n",
      "Epoch 56/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7293 - accuracy: 0.6767\n",
      "Epoch 57/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7156 - accuracy: 0.6821\n",
      "Epoch 58/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7245 - accuracy: 0.6730\n",
      "Epoch 59/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7237 - accuracy: 0.6811\n",
      "Epoch 60/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7257 - accuracy: 0.6683\n",
      "Epoch 61/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7426 - accuracy: 0.6710\n",
      "Epoch 62/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7262 - accuracy: 0.6809\n",
      "Epoch 63/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7239 - accuracy: 0.6828\n",
      "Epoch 64/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7253 - accuracy: 0.6775\n",
      "Epoch 65/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7146 - accuracy: 0.6806\n",
      "Epoch 66/200\n",
      "252/252 [==============================] - 0s 990us/step - loss: 0.7218 - accuracy: 0.6726\n",
      "Epoch 67/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7150 - accuracy: 0.6839\n",
      "Epoch 68/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7104 - accuracy: 0.6895\n",
      "Epoch 69/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7165 - accuracy: 0.6802\n",
      "Epoch 70/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7122 - accuracy: 0.6871\n",
      "Epoch 71/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7097 - accuracy: 0.6879\n",
      "Epoch 72/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7145 - accuracy: 0.6901\n",
      "Epoch 73/200\n",
      "252/252 [==============================] - 0s 999us/step - loss: 0.7139 - accuracy: 0.6805\n",
      "Epoch 74/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7186 - accuracy: 0.6719\n",
      "Epoch 75/200\n",
      "252/252 [==============================] - 0s 997us/step - loss: 0.7356 - accuracy: 0.6572\n",
      "Epoch 76/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7241 - accuracy: 0.6718\n",
      "Epoch 77/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7124 - accuracy: 0.6839\n",
      "Epoch 78/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7213 - accuracy: 0.6677\n",
      "Epoch 79/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7243 - accuracy: 0.6829\n",
      "Epoch 80/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7212 - accuracy: 0.6686\n",
      "Epoch 81/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7080 - accuracy: 0.6796\n",
      "Epoch 82/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7159 - accuracy: 0.6784\n",
      "Epoch 83/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7102 - accuracy: 0.6879\n",
      "Epoch 84/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7211 - accuracy: 0.6734\n",
      "Epoch 85/200\n",
      "252/252 [==============================] - 0s 1000us/step - loss: 0.7481 - accuracy: 0.6622\n",
      "Epoch 86/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7051 - accuracy: 0.6867\n",
      "Epoch 87/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7285 - accuracy: 0.6736\n",
      "Epoch 88/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7010 - accuracy: 0.6857\n",
      "Epoch 89/200\n",
      "252/252 [==============================] - 0s 996us/step - loss: 0.7234 - accuracy: 0.6780\n",
      "Epoch 90/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7195 - accuracy: 0.6772\n",
      "Epoch 91/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7251 - accuracy: 0.6822\n",
      "Epoch 92/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7143 - accuracy: 0.6748\n",
      "Epoch 93/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7145 - accuracy: 0.6846\n",
      "Epoch 94/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7110 - accuracy: 0.6759\n",
      "Epoch 95/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7159 - accuracy: 0.6787\n",
      "Epoch 96/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7083 - accuracy: 0.6832\n",
      "Epoch 97/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7024 - accuracy: 0.6887\n",
      "Epoch 98/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7210 - accuracy: 0.6771\n",
      "Epoch 99/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.6895\n",
      "Epoch 100/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7232 - accuracy: 0.6844\n",
      "Epoch 101/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7157 - accuracy: 0.6817\n",
      "Epoch 102/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.7007\n",
      "Epoch 103/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7252 - accuracy: 0.6731\n",
      "Epoch 104/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7059 - accuracy: 0.6941\n",
      "Epoch 105/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6993 - accuracy: 0.6876\n",
      "Epoch 106/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7071 - accuracy: 0.6879\n",
      "Epoch 107/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7207 - accuracy: 0.6747\n",
      "Epoch 108/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7082 - accuracy: 0.6888\n",
      "Epoch 109/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7239 - accuracy: 0.6847\n",
      "Epoch 110/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7031 - accuracy: 0.6930\n",
      "Epoch 111/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7197 - accuracy: 0.6788\n",
      "Epoch 112/200\n",
      "252/252 [==============================] - 0s 999us/step - loss: 0.7290 - accuracy: 0.6778\n",
      "Epoch 113/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7170 - accuracy: 0.6807\n",
      "Epoch 114/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7281 - accuracy: 0.6686\n",
      "Epoch 115/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7084 - accuracy: 0.6862\n",
      "Epoch 116/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7177 - accuracy: 0.6675\n",
      "Epoch 117/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7135 - accuracy: 0.6840\n",
      "Epoch 118/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7191 - accuracy: 0.6721\n",
      "Epoch 119/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7216 - accuracy: 0.6766\n",
      "Epoch 120/200\n",
      "252/252 [==============================] - 0s 999us/step - loss: 0.7318 - accuracy: 0.6808\n",
      "Epoch 121/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7318 - accuracy: 0.6834\n",
      "Epoch 122/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7200 - accuracy: 0.6761\n",
      "Epoch 123/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7103 - accuracy: 0.6836\n",
      "Epoch 124/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7130 - accuracy: 0.6869\n",
      "Epoch 125/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6978 - accuracy: 0.6922\n",
      "Epoch 126/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7167 - accuracy: 0.6798\n",
      "Epoch 127/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7187 - accuracy: 0.6793\n",
      "Epoch 128/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7248 - accuracy: 0.6784\n",
      "Epoch 129/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7075 - accuracy: 0.6942\n",
      "Epoch 130/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.6963\n",
      "Epoch 131/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7084 - accuracy: 0.6835\n",
      "Epoch 132/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7163 - accuracy: 0.6813\n",
      "Epoch 133/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6987 - accuracy: 0.6876\n",
      "Epoch 134/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7201 - accuracy: 0.6734\n",
      "Epoch 135/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7160 - accuracy: 0.6754\n",
      "Epoch 136/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7132 - accuracy: 0.6857\n",
      "Epoch 137/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7168 - accuracy: 0.6780\n",
      "Epoch 138/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7277 - accuracy: 0.6655\n",
      "Epoch 139/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7161 - accuracy: 0.6736\n",
      "Epoch 140/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7316 - accuracy: 0.6700\n",
      "Epoch 141/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7043 - accuracy: 0.6848\n",
      "Epoch 142/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7052 - accuracy: 0.6799\n",
      "Epoch 143/200\n",
      "252/252 [==============================] - 0s 999us/step - loss: 0.7012 - accuracy: 0.6870\n",
      "Epoch 144/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6966 - accuracy: 0.6886\n",
      "Epoch 145/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7376 - accuracy: 0.6665\n",
      "Epoch 146/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7220 - accuracy: 0.6735\n",
      "Epoch 147/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7196 - accuracy: 0.6686\n",
      "Epoch 148/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7106 - accuracy: 0.6867\n",
      "Epoch 149/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7265 - accuracy: 0.6804\n",
      "Epoch 150/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7314 - accuracy: 0.6714\n",
      "Epoch 151/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7108 - accuracy: 0.6803\n",
      "Epoch 152/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7186 - accuracy: 0.6859\n",
      "Epoch 153/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7165 - accuracy: 0.6792\n",
      "Epoch 154/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7226 - accuracy: 0.6852\n",
      "Epoch 155/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7208 - accuracy: 0.6864\n",
      "Epoch 156/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7192 - accuracy: 0.6817\n",
      "Epoch 157/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.6862\n",
      "Epoch 158/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7077 - accuracy: 0.6866\n",
      "Epoch 159/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7327 - accuracy: 0.6744\n",
      "Epoch 160/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7266 - accuracy: 0.6743\n",
      "Epoch 161/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7078 - accuracy: 0.6812\n",
      "Epoch 162/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7125 - accuracy: 0.6786\n",
      "Epoch 163/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7126 - accuracy: 0.6846\n",
      "Epoch 164/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7214 - accuracy: 0.6763\n",
      "Epoch 165/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7127 - accuracy: 0.6759\n",
      "Epoch 166/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.6914\n",
      "Epoch 167/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7124 - accuracy: 0.6778\n",
      "Epoch 168/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7219 - accuracy: 0.6770\n",
      "Epoch 169/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6995 - accuracy: 0.6939\n",
      "Epoch 170/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7244 - accuracy: 0.6870\n",
      "Epoch 171/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7336 - accuracy: 0.6602\n",
      "Epoch 172/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7104 - accuracy: 0.6827\n",
      "Epoch 173/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7073 - accuracy: 0.6888\n",
      "Epoch 174/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7089 - accuracy: 0.6793\n",
      "Epoch 175/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7117 - accuracy: 0.6856\n",
      "Epoch 176/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7168 - accuracy: 0.6808\n",
      "Epoch 177/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.6896\n",
      "Epoch 178/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.6947\n",
      "Epoch 179/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7005 - accuracy: 0.6890\n",
      "Epoch 180/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7088 - accuracy: 0.6795\n",
      "Epoch 181/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7101 - accuracy: 0.6849\n",
      "Epoch 182/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7241 - accuracy: 0.6860\n",
      "Epoch 183/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7088 - accuracy: 0.6888\n",
      "Epoch 184/200\n",
      "252/252 [==============================] - 0s 995us/step - loss: 0.7030 - accuracy: 0.6896\n",
      "Epoch 185/200\n",
      "252/252 [==============================] - 0s 996us/step - loss: 0.7130 - accuracy: 0.6829\n",
      "Epoch 186/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7257 - accuracy: 0.6845\n",
      "Epoch 187/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7209 - accuracy: 0.6780\n",
      "Epoch 188/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7184 - accuracy: 0.6771\n",
      "Epoch 189/200\n",
      "252/252 [==============================] - 0s 994us/step - loss: 0.7091 - accuracy: 0.6883\n",
      "Epoch 190/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7105 - accuracy: 0.6890\n",
      "Epoch 191/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7160 - accuracy: 0.6780\n",
      "Epoch 192/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7079 - accuracy: 0.6959\n",
      "Epoch 193/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7189 - accuracy: 0.6857\n",
      "Epoch 194/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7236 - accuracy: 0.6792\n",
      "Epoch 195/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7277 - accuracy: 0.6866\n",
      "Epoch 196/200\n",
      "252/252 [==============================] - 0s 996us/step - loss: 0.7063 - accuracy: 0.6968\n",
      "Epoch 197/200\n",
      "252/252 [==============================] - 0s 998us/step - loss: 0.7001 - accuracy: 0.6848\n",
      "Epoch 198/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7046 - accuracy: 0.6864\n",
      "Epoch 199/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7156 - accuracy: 0.6790\n",
      "Epoch 200/200\n",
      "252/252 [==============================] - 0s 999us/step - loss: 0.7239 - accuracy: 0.6767\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 811us/step - loss: 0.7762 - accuracy: 0.6344\n",
      "Acc:\n",
      "0.6344160437583923\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Acc:')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_231\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_698 (Dense)            (None, 14)                266       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_699 (Dense)            (None, 14)                210       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_700 (Dense)            (None, 14)                210       \n",
      "_________________________________________________________________\n",
      "dense_701 (Dense)            (None, 3)                 45        \n",
      "=================================================================\n",
      "Total params: 731\n",
      "Trainable params: 731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu', input_shape=(18,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "252/252 [==============================] - 1s 1ms/step - loss: 1.0384 - accuracy: 0.4905\n",
      "Epoch 2/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7945 - accuracy: 0.6454\n",
      "Epoch 3/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7523 - accuracy: 0.6636\n",
      "Epoch 4/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7822 - accuracy: 0.6528\n",
      "Epoch 5/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7491 - accuracy: 0.6710\n",
      "Epoch 6/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7513 - accuracy: 0.6682\n",
      "Epoch 7/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7620 - accuracy: 0.6568\n",
      "Epoch 8/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7549 - accuracy: 0.6719\n",
      "Epoch 9/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7407 - accuracy: 0.6696\n",
      "Epoch 10/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7558 - accuracy: 0.6681\n",
      "Epoch 11/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7680 - accuracy: 0.6535\n",
      "Epoch 12/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7470 - accuracy: 0.6609\n",
      "Epoch 13/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7383 - accuracy: 0.6706\n",
      "Epoch 14/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7557 - accuracy: 0.6654\n",
      "Epoch 15/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7533 - accuracy: 0.6503\n",
      "Epoch 16/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7490 - accuracy: 0.6653\n",
      "Epoch 17/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7449 - accuracy: 0.6554\n",
      "Epoch 18/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7497 - accuracy: 0.6614\n",
      "Epoch 19/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7538 - accuracy: 0.6622\n",
      "Epoch 20/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7526 - accuracy: 0.6610\n",
      "Epoch 21/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7511 - accuracy: 0.6590\n",
      "Epoch 22/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7429 - accuracy: 0.6682\n",
      "Epoch 23/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7419 - accuracy: 0.6651\n",
      "Epoch 24/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7325 - accuracy: 0.6747\n",
      "Epoch 25/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7381 - accuracy: 0.6752\n",
      "Epoch 26/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7282 - accuracy: 0.6654\n",
      "Epoch 27/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7457 - accuracy: 0.6727\n",
      "Epoch 28/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7426 - accuracy: 0.6626\n",
      "Epoch 29/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7460 - accuracy: 0.6675\n",
      "Epoch 30/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7436 - accuracy: 0.6622\n",
      "Epoch 31/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7342 - accuracy: 0.6700\n",
      "Epoch 32/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7299 - accuracy: 0.6658\n",
      "Epoch 33/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7428 - accuracy: 0.6633\n",
      "Epoch 34/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7365 - accuracy: 0.6715\n",
      "Epoch 35/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7319 - accuracy: 0.6728\n",
      "Epoch 36/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7510 - accuracy: 0.6743\n",
      "Epoch 37/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7292 - accuracy: 0.6817\n",
      "Epoch 38/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7398 - accuracy: 0.6610\n",
      "Epoch 39/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7266 - accuracy: 0.6770\n",
      "Epoch 40/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7377 - accuracy: 0.6707\n",
      "Epoch 41/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7308 - accuracy: 0.6790\n",
      "Epoch 42/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7461 - accuracy: 0.6773\n",
      "Epoch 43/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7307 - accuracy: 0.6834\n",
      "Epoch 44/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7396 - accuracy: 0.6748\n",
      "Epoch 45/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7384 - accuracy: 0.6646\n",
      "Epoch 46/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7548 - accuracy: 0.6593\n",
      "Epoch 47/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7331 - accuracy: 0.6771\n",
      "Epoch 48/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7387 - accuracy: 0.6700\n",
      "Epoch 49/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7340 - accuracy: 0.6701\n",
      "Epoch 50/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7435 - accuracy: 0.6623\n",
      "Epoch 51/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7430 - accuracy: 0.6646\n",
      "Epoch 52/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7307 - accuracy: 0.6720\n",
      "Epoch 53/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7333 - accuracy: 0.6815\n",
      "Epoch 54/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7334 - accuracy: 0.6713\n",
      "Epoch 55/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7375 - accuracy: 0.6636\n",
      "Epoch 56/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7201 - accuracy: 0.6857\n",
      "Epoch 57/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7188 - accuracy: 0.6878\n",
      "Epoch 58/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.6720\n",
      "Epoch 59/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7342 - accuracy: 0.6734\n",
      "Epoch 60/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7258 - accuracy: 0.6766\n",
      "Epoch 61/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7290 - accuracy: 0.6805\n",
      "Epoch 62/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7164 - accuracy: 0.6857\n",
      "Epoch 63/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7466 - accuracy: 0.6726\n",
      "Epoch 64/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7345 - accuracy: 0.6801\n",
      "Epoch 65/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7400 - accuracy: 0.6731\n",
      "Epoch 66/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7544 - accuracy: 0.6721\n",
      "Epoch 67/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7312 - accuracy: 0.6769\n",
      "Epoch 68/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7277 - accuracy: 0.6797\n",
      "Epoch 69/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7449 - accuracy: 0.6736\n",
      "Epoch 70/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7294 - accuracy: 0.6677\n",
      "Epoch 71/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7364 - accuracy: 0.6799\n",
      "Epoch 72/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7406 - accuracy: 0.6599\n",
      "Epoch 73/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7292 - accuracy: 0.6750\n",
      "Epoch 74/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7298 - accuracy: 0.6796\n",
      "Epoch 75/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7348 - accuracy: 0.6705\n",
      "Epoch 76/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7207 - accuracy: 0.6810\n",
      "Epoch 77/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7409 - accuracy: 0.6698\n",
      "Epoch 78/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7056 - accuracy: 0.6889\n",
      "Epoch 79/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7297 - accuracy: 0.6743\n",
      "Epoch 80/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7372 - accuracy: 0.6686\n",
      "Epoch 81/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7342 - accuracy: 0.6712\n",
      "Epoch 82/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7094 - accuracy: 0.6831\n",
      "Epoch 83/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7232 - accuracy: 0.6741\n",
      "Epoch 84/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7227 - accuracy: 0.6745\n",
      "Epoch 85/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7299 - accuracy: 0.6841\n",
      "Epoch 86/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7279 - accuracy: 0.6717\n",
      "Epoch 87/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7374 - accuracy: 0.6695\n",
      "Epoch 88/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7334 - accuracy: 0.6710\n",
      "Epoch 89/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7358 - accuracy: 0.6733\n",
      "Epoch 90/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7451 - accuracy: 0.6814\n",
      "Epoch 91/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7166 - accuracy: 0.6815\n",
      "Epoch 92/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7094 - accuracy: 0.6781\n",
      "Epoch 93/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7165 - accuracy: 0.6860\n",
      "Epoch 94/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7044 - accuracy: 0.7012\n",
      "Epoch 95/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7257 - accuracy: 0.6733\n",
      "Epoch 96/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6969 - accuracy: 0.6808\n",
      "Epoch 97/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7016 - accuracy: 0.6853\n",
      "Epoch 98/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7140 - accuracy: 0.6849\n",
      "Epoch 99/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7270 - accuracy: 0.6778\n",
      "Epoch 100/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7275 - accuracy: 0.6717\n",
      "Epoch 101/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7302 - accuracy: 0.6798\n",
      "Epoch 102/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7345 - accuracy: 0.6812\n",
      "Epoch 103/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7328 - accuracy: 0.6753\n",
      "Epoch 104/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7167 - accuracy: 0.6812\n",
      "Epoch 105/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7187 - accuracy: 0.6730\n",
      "Epoch 106/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7224 - accuracy: 0.6785\n",
      "Epoch 107/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7295 - accuracy: 0.6823\n",
      "Epoch 108/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7278 - accuracy: 0.6809\n",
      "Epoch 109/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7345 - accuracy: 0.6707\n",
      "Epoch 110/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7131 - accuracy: 0.6783\n",
      "Epoch 111/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7329 - accuracy: 0.6743\n",
      "Epoch 112/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7249 - accuracy: 0.6760\n",
      "Epoch 113/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7161 - accuracy: 0.6810\n",
      "Epoch 114/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7355 - accuracy: 0.6792\n",
      "Epoch 115/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7258 - accuracy: 0.6783\n",
      "Epoch 116/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7336 - accuracy: 0.6779\n",
      "Epoch 117/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7119 - accuracy: 0.6833\n",
      "Epoch 118/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7323 - accuracy: 0.6736\n",
      "Epoch 119/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7342 - accuracy: 0.6760\n",
      "Epoch 120/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7142 - accuracy: 0.6840\n",
      "Epoch 121/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7180 - accuracy: 0.6859\n",
      "Epoch 122/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7404 - accuracy: 0.6652\n",
      "Epoch 123/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7143 - accuracy: 0.6858\n",
      "Epoch 124/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7230 - accuracy: 0.6753\n",
      "Epoch 125/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7245 - accuracy: 0.6783\n",
      "Epoch 126/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7235 - accuracy: 0.6732\n",
      "Epoch 127/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7154 - accuracy: 0.6761\n",
      "Epoch 128/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7113 - accuracy: 0.6838\n",
      "Epoch 129/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7328 - accuracy: 0.6725\n",
      "Epoch 130/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7141 - accuracy: 0.6876\n",
      "Epoch 131/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7202 - accuracy: 0.6784\n",
      "Epoch 132/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7150 - accuracy: 0.6785\n",
      "Epoch 133/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7231 - accuracy: 0.6713\n",
      "Epoch 134/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7321 - accuracy: 0.6666\n",
      "Epoch 135/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7208 - accuracy: 0.6761\n",
      "Epoch 136/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7246 - accuracy: 0.6770\n",
      "Epoch 137/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7256 - accuracy: 0.6865\n",
      "Epoch 138/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7010 - accuracy: 0.6919\n",
      "Epoch 139/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7001 - accuracy: 0.6960\n",
      "Epoch 140/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7204 - accuracy: 0.6726\n",
      "Epoch 141/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.6918\n",
      "Epoch 142/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7272 - accuracy: 0.6745\n",
      "Epoch 143/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7160 - accuracy: 0.6856\n",
      "Epoch 144/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7329 - accuracy: 0.6743\n",
      "Epoch 145/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7230 - accuracy: 0.6779\n",
      "Epoch 146/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7336 - accuracy: 0.6719\n",
      "Epoch 147/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7130 - accuracy: 0.6847\n",
      "Epoch 148/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7148 - accuracy: 0.6856\n",
      "Epoch 149/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7315 - accuracy: 0.6743\n",
      "Epoch 150/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7275 - accuracy: 0.6789\n",
      "Epoch 151/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7158 - accuracy: 0.6815\n",
      "Epoch 152/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7365 - accuracy: 0.6612\n",
      "Epoch 153/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7280 - accuracy: 0.6758\n",
      "Epoch 154/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7411 - accuracy: 0.6726\n",
      "Epoch 155/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7169 - accuracy: 0.6837\n",
      "Epoch 156/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7105 - accuracy: 0.6816\n",
      "Epoch 157/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7269 - accuracy: 0.6838\n",
      "Epoch 158/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7165 - accuracy: 0.6900\n",
      "Epoch 159/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7166 - accuracy: 0.6878\n",
      "Epoch 160/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7312 - accuracy: 0.6694\n",
      "Epoch 161/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7276 - accuracy: 0.6833\n",
      "Epoch 162/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7314 - accuracy: 0.6808\n",
      "Epoch 163/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7097 - accuracy: 0.6893\n",
      "Epoch 164/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7330 - accuracy: 0.6817\n",
      "Epoch 165/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7396 - accuracy: 0.6814\n",
      "Epoch 166/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7321 - accuracy: 0.6718\n",
      "Epoch 167/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7141 - accuracy: 0.6809\n",
      "Epoch 168/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7201 - accuracy: 0.6741\n",
      "Epoch 169/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7318 - accuracy: 0.6893\n",
      "Epoch 170/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7159 - accuracy: 0.6894\n",
      "Epoch 171/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7231 - accuracy: 0.6794\n",
      "Epoch 172/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7084 - accuracy: 0.6851\n",
      "Epoch 173/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7291 - accuracy: 0.6758\n",
      "Epoch 174/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7109 - accuracy: 0.6820\n",
      "Epoch 175/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7371 - accuracy: 0.6762\n",
      "Epoch 176/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7032 - accuracy: 0.6871\n",
      "Epoch 177/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7148 - accuracy: 0.6771\n",
      "Epoch 178/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7143 - accuracy: 0.6883\n",
      "Epoch 179/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7127 - accuracy: 0.6852\n",
      "Epoch 180/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7210 - accuracy: 0.6864\n",
      "Epoch 181/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7334 - accuracy: 0.6783\n",
      "Epoch 182/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7389 - accuracy: 0.6682\n",
      "Epoch 183/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7348 - accuracy: 0.6764\n",
      "Epoch 184/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7303 - accuracy: 0.6679\n",
      "Epoch 185/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7141 - accuracy: 0.6844\n",
      "Epoch 186/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7173 - accuracy: 0.6828\n",
      "Epoch 187/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7199 - accuracy: 0.6935\n",
      "Epoch 188/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7213 - accuracy: 0.6877\n",
      "Epoch 189/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7372 - accuracy: 0.6736\n",
      "Epoch 190/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7337 - accuracy: 0.6767\n",
      "Epoch 191/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7286 - accuracy: 0.6755\n",
      "Epoch 192/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7114 - accuracy: 0.6811\n",
      "Epoch 193/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7404 - accuracy: 0.6725\n",
      "Epoch 194/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7189 - accuracy: 0.6836\n",
      "Epoch 195/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7085 - accuracy: 0.6878\n",
      "Epoch 196/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7212 - accuracy: 0.6763\n",
      "Epoch 197/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7347 - accuracy: 0.6725\n",
      "Epoch 198/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7263 - accuracy: 0.6782\n",
      "Epoch 199/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7127 - accuracy: 0.6741\n",
      "Epoch 200/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7242 - accuracy: 0.6889\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 908us/step - loss: 0.7859 - accuracy: 0.6455\n",
      "Acc:\n",
      "0.6454734206199646\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Acc:')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_232\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_702 (Dense)            (None, 16)                304       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_703 (Dense)            (None, 14)                238       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_704 (Dense)            (None, 14)                210       \n",
      "_________________________________________________________________\n",
      "dense_705 (Dense)            (None, 3)                 45        \n",
      "=================================================================\n",
      "Total params: 797\n",
      "Trainable params: 797\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, kernel_initializer='normal', activation='relu', input_shape=(18,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "252/252 [==============================] - 1s 1ms/step - loss: 1.0276 - accuracy: 0.5035\n",
      "Epoch 2/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7972 - accuracy: 0.6425\n",
      "Epoch 3/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7654 - accuracy: 0.6505\n",
      "Epoch 4/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7450 - accuracy: 0.6621\n",
      "Epoch 5/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7521 - accuracy: 0.6677\n",
      "Epoch 6/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7580 - accuracy: 0.6617\n",
      "Epoch 7/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7594 - accuracy: 0.6607\n",
      "Epoch 8/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7432 - accuracy: 0.6718\n",
      "Epoch 9/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7435 - accuracy: 0.6693\n",
      "Epoch 10/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7322 - accuracy: 0.6634\n",
      "Epoch 11/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7406 - accuracy: 0.6736\n",
      "Epoch 12/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7342 - accuracy: 0.6671\n",
      "Epoch 13/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7421 - accuracy: 0.6677\n",
      "Epoch 14/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7400 - accuracy: 0.6787\n",
      "Epoch 15/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7579 - accuracy: 0.6638\n",
      "Epoch 16/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7386 - accuracy: 0.6606\n",
      "Epoch 17/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7398 - accuracy: 0.6630\n",
      "Epoch 18/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7419 - accuracy: 0.6559\n",
      "Epoch 19/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7267 - accuracy: 0.6731\n",
      "Epoch 20/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7444 - accuracy: 0.6508\n",
      "Epoch 21/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7387 - accuracy: 0.6669\n",
      "Epoch 22/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7456 - accuracy: 0.6668\n",
      "Epoch 23/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7466 - accuracy: 0.6616\n",
      "Epoch 24/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7484 - accuracy: 0.6552\n",
      "Epoch 25/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7343 - accuracy: 0.6696\n",
      "Epoch 26/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7280 - accuracy: 0.6695\n",
      "Epoch 27/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7441 - accuracy: 0.6700\n",
      "Epoch 28/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7265 - accuracy: 0.6845\n",
      "Epoch 29/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7204 - accuracy: 0.6766\n",
      "Epoch 30/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7193 - accuracy: 0.6735\n",
      "Epoch 31/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7369 - accuracy: 0.6697\n",
      "Epoch 32/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7335 - accuracy: 0.6743\n",
      "Epoch 33/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7161 - accuracy: 0.6803\n",
      "Epoch 34/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7264 - accuracy: 0.6802\n",
      "Epoch 35/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7245 - accuracy: 0.6773\n",
      "Epoch 36/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7357 - accuracy: 0.6683\n",
      "Epoch 37/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7299 - accuracy: 0.6828\n",
      "Epoch 38/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7356 - accuracy: 0.6640\n",
      "Epoch 39/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7159 - accuracy: 0.6884\n",
      "Epoch 40/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7213 - accuracy: 0.6742\n",
      "Epoch 41/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7318 - accuracy: 0.6767\n",
      "Epoch 42/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7117 - accuracy: 0.6714\n",
      "Epoch 43/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7162 - accuracy: 0.6898\n",
      "Epoch 44/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7312 - accuracy: 0.6697\n",
      "Epoch 45/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7199 - accuracy: 0.6835\n",
      "Epoch 46/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7393 - accuracy: 0.6727\n",
      "Epoch 47/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7403 - accuracy: 0.6769\n",
      "Epoch 48/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7169 - accuracy: 0.6831\n",
      "Epoch 49/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7282 - accuracy: 0.6767\n",
      "Epoch 50/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.6745\n",
      "Epoch 51/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7446 - accuracy: 0.6635\n",
      "Epoch 52/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7196 - accuracy: 0.6775\n",
      "Epoch 53/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7351 - accuracy: 0.6675\n",
      "Epoch 54/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7230 - accuracy: 0.6792\n",
      "Epoch 55/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7291 - accuracy: 0.6755\n",
      "Epoch 56/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7234 - accuracy: 0.6843\n",
      "Epoch 57/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7295 - accuracy: 0.6702\n",
      "Epoch 58/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7112 - accuracy: 0.6912\n",
      "Epoch 59/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7215 - accuracy: 0.6736\n",
      "Epoch 60/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7281 - accuracy: 0.6723\n",
      "Epoch 61/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7237 - accuracy: 0.6852\n",
      "Epoch 62/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7312 - accuracy: 0.6701\n",
      "Epoch 63/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7344 - accuracy: 0.6712\n",
      "Epoch 64/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7210 - accuracy: 0.6709\n",
      "Epoch 65/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7389 - accuracy: 0.6680\n",
      "Epoch 66/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7273 - accuracy: 0.6752\n",
      "Epoch 67/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7259 - accuracy: 0.6749\n",
      "Epoch 68/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7327 - accuracy: 0.6771\n",
      "Epoch 69/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7234 - accuracy: 0.6781\n",
      "Epoch 70/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7249 - accuracy: 0.6766\n",
      "Epoch 71/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7133 - accuracy: 0.6898\n",
      "Epoch 72/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7258 - accuracy: 0.6823\n",
      "Epoch 73/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7317 - accuracy: 0.6771\n",
      "Epoch 74/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7262 - accuracy: 0.6801\n",
      "Epoch 75/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7182 - accuracy: 0.6885\n",
      "Epoch 76/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7189 - accuracy: 0.6778\n",
      "Epoch 77/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7303 - accuracy: 0.6721\n",
      "Epoch 78/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7181 - accuracy: 0.6751\n",
      "Epoch 79/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7246 - accuracy: 0.6789\n",
      "Epoch 80/200\n",
      "252/252 [==============================] - 0s 989us/step - loss: 0.7168 - accuracy: 0.6807\n",
      "Epoch 81/200\n",
      "252/252 [==============================] - 0s 975us/step - loss: 0.7346 - accuracy: 0.6718\n",
      "Epoch 82/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7217 - accuracy: 0.6829\n",
      "Epoch 83/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7201 - accuracy: 0.6845\n",
      "Epoch 84/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7224 - accuracy: 0.6769\n",
      "Epoch 85/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.7037\n",
      "Epoch 86/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7159 - accuracy: 0.6841\n",
      "Epoch 87/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7265 - accuracy: 0.6788\n",
      "Epoch 88/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7183 - accuracy: 0.6760\n",
      "Epoch 89/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7155 - accuracy: 0.6827\n",
      "Epoch 90/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7423 - accuracy: 0.6724\n",
      "Epoch 91/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7279 - accuracy: 0.6747\n",
      "Epoch 92/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7313 - accuracy: 0.6691\n",
      "Epoch 93/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7285 - accuracy: 0.6779\n",
      "Epoch 94/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7168 - accuracy: 0.6785\n",
      "Epoch 95/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7054 - accuracy: 0.6854\n",
      "Epoch 96/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7240 - accuracy: 0.6797\n",
      "Epoch 97/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7159 - accuracy: 0.6825\n",
      "Epoch 98/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7189 - accuracy: 0.6784\n",
      "Epoch 99/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7257 - accuracy: 0.6827\n",
      "Epoch 100/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7341 - accuracy: 0.6679\n",
      "Epoch 101/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7214 - accuracy: 0.6768\n",
      "Epoch 102/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7201 - accuracy: 0.6837\n",
      "Epoch 103/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7087 - accuracy: 0.6860\n",
      "Epoch 104/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7261 - accuracy: 0.6718\n",
      "Epoch 105/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7080 - accuracy: 0.6842\n",
      "Epoch 106/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7269 - accuracy: 0.6794\n",
      "Epoch 107/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7318 - accuracy: 0.6745\n",
      "Epoch 108/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7114 - accuracy: 0.6861\n",
      "Epoch 109/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7088 - accuracy: 0.6840\n",
      "Epoch 110/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7195 - accuracy: 0.6727\n",
      "Epoch 111/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7114 - accuracy: 0.6883\n",
      "Epoch 112/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6979 - accuracy: 0.6896\n",
      "Epoch 113/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7144 - accuracy: 0.6660\n",
      "Epoch 114/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7226 - accuracy: 0.6781\n",
      "Epoch 115/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7049 - accuracy: 0.6878\n",
      "Epoch 116/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7159 - accuracy: 0.6819\n",
      "Epoch 117/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7159 - accuracy: 0.6875\n",
      "Epoch 118/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7281 - accuracy: 0.6778\n",
      "Epoch 119/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.6944\n",
      "Epoch 120/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7260 - accuracy: 0.6797\n",
      "Epoch 121/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7069 - accuracy: 0.6835\n",
      "Epoch 122/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7114 - accuracy: 0.6921\n",
      "Epoch 123/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7130 - accuracy: 0.6915\n",
      "Epoch 124/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7056 - accuracy: 0.6877\n",
      "Epoch 125/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7298 - accuracy: 0.6784\n",
      "Epoch 126/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7034 - accuracy: 0.6853\n",
      "Epoch 127/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7265 - accuracy: 0.6708\n",
      "Epoch 128/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7209 - accuracy: 0.6848\n",
      "Epoch 129/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7083 - accuracy: 0.6795\n",
      "Epoch 130/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7015 - accuracy: 0.6885\n",
      "Epoch 131/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7020 - accuracy: 0.6838\n",
      "Epoch 132/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7144 - accuracy: 0.6914\n",
      "Epoch 133/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7358 - accuracy: 0.6663\n",
      "Epoch 134/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7263 - accuracy: 0.6726\n",
      "Epoch 135/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7093 - accuracy: 0.6817\n",
      "Epoch 136/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7271 - accuracy: 0.6749\n",
      "Epoch 137/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7258 - accuracy: 0.6764\n",
      "Epoch 138/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7293 - accuracy: 0.6746\n",
      "Epoch 139/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7286 - accuracy: 0.6853\n",
      "Epoch 140/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7137 - accuracy: 0.6846\n",
      "Epoch 141/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7207 - accuracy: 0.6784\n",
      "Epoch 142/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7087 - accuracy: 0.6878\n",
      "Epoch 143/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7428 - accuracy: 0.6706\n",
      "Epoch 144/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7230 - accuracy: 0.6896\n",
      "Epoch 145/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7187 - accuracy: 0.6850\n",
      "Epoch 146/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7239 - accuracy: 0.6881\n",
      "Epoch 147/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7086 - accuracy: 0.6827\n",
      "Epoch 148/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7077 - accuracy: 0.6892\n",
      "Epoch 149/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7169 - accuracy: 0.6785\n",
      "Epoch 150/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7062 - accuracy: 0.6835\n",
      "Epoch 151/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7286 - accuracy: 0.6716\n",
      "Epoch 152/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.6870\n",
      "Epoch 153/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7108 - accuracy: 0.6810\n",
      "Epoch 154/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7430 - accuracy: 0.6736\n",
      "Epoch 155/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7077 - accuracy: 0.6859\n",
      "Epoch 156/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7319 - accuracy: 0.6822\n",
      "Epoch 157/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7293 - accuracy: 0.6803\n",
      "Epoch 158/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7167 - accuracy: 0.6813\n",
      "Epoch 159/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7370 - accuracy: 0.6745\n",
      "Epoch 160/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7178 - accuracy: 0.6839\n",
      "Epoch 161/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7229 - accuracy: 0.6782\n",
      "Epoch 162/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7279 - accuracy: 0.6796\n",
      "Epoch 163/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7005 - accuracy: 0.6956\n",
      "Epoch 164/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7227 - accuracy: 0.6753\n",
      "Epoch 165/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7255 - accuracy: 0.6763\n",
      "Epoch 166/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7304 - accuracy: 0.6683\n",
      "Epoch 167/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7329 - accuracy: 0.6643\n",
      "Epoch 168/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7224 - accuracy: 0.6748\n",
      "Epoch 169/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7090 - accuracy: 0.6877\n",
      "Epoch 170/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7123 - accuracy: 0.6858\n",
      "Epoch 171/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7201 - accuracy: 0.6865\n",
      "Epoch 172/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6975 - accuracy: 0.6995\n",
      "Epoch 173/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7243 - accuracy: 0.6742\n",
      "Epoch 174/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7305 - accuracy: 0.6793\n",
      "Epoch 175/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7187 - accuracy: 0.6819\n",
      "Epoch 176/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7086 - accuracy: 0.6935\n",
      "Epoch 177/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7165 - accuracy: 0.6843\n",
      "Epoch 178/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7188 - accuracy: 0.6824\n",
      "Epoch 179/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7143 - accuracy: 0.6763\n",
      "Epoch 180/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7246 - accuracy: 0.6790\n",
      "Epoch 181/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7320 - accuracy: 0.6731\n",
      "Epoch 182/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7185 - accuracy: 0.6783\n",
      "Epoch 183/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6985 - accuracy: 0.6964\n",
      "Epoch 184/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7243 - accuracy: 0.6824\n",
      "Epoch 185/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7200 - accuracy: 0.6835\n",
      "Epoch 186/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.6858\n",
      "Epoch 187/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7069 - accuracy: 0.6912\n",
      "Epoch 188/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7018 - accuracy: 0.6916\n",
      "Epoch 189/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7152 - accuracy: 0.6833\n",
      "Epoch 190/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7147 - accuracy: 0.6747\n",
      "Epoch 191/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6976 - accuracy: 0.6893\n",
      "Epoch 192/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7168 - accuracy: 0.6882\n",
      "Epoch 193/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7308 - accuracy: 0.6707\n",
      "Epoch 194/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7187 - accuracy: 0.6816\n",
      "Epoch 195/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7052 - accuracy: 0.6840\n",
      "Epoch 196/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7180 - accuracy: 0.6785\n",
      "Epoch 197/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7068 - accuracy: 0.6936\n",
      "Epoch 198/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7362 - accuracy: 0.6718\n",
      "Epoch 199/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7313 - accuracy: 0.6779\n",
      "Epoch 200/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7162 - accuracy: 0.6827\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 829us/step - loss: 0.7953 - accuracy: 0.6220\n",
      "Acc:\n",
      "0.6219764947891235\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Acc:')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_233\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_706 (Dense)            (None, 16)                304       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_707 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_708 (Dense)            (None, 14)                238       \n",
      "_________________________________________________________________\n",
      "dense_709 (Dense)            (None, 3)                 45        \n",
      "=================================================================\n",
      "Total params: 859\n",
      "Trainable params: 859\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, kernel_initializer='normal', activation='relu', input_shape=(18,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "252/252 [==============================] - 1s 1ms/step - loss: 1.0182 - accuracy: 0.5011\n",
      "Epoch 2/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.8242 - accuracy: 0.6507\n",
      "Epoch 3/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7670 - accuracy: 0.6587\n",
      "Epoch 4/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7567 - accuracy: 0.6579\n",
      "Epoch 5/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7541 - accuracy: 0.6628\n",
      "Epoch 6/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7716 - accuracy: 0.6488\n",
      "Epoch 7/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7617 - accuracy: 0.6610\n",
      "Epoch 8/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7417 - accuracy: 0.6577\n",
      "Epoch 9/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7531 - accuracy: 0.6715\n",
      "Epoch 10/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7474 - accuracy: 0.6648\n",
      "Epoch 11/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7765 - accuracy: 0.6456\n",
      "Epoch 12/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7423 - accuracy: 0.6643\n",
      "Epoch 13/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7359 - accuracy: 0.6712\n",
      "Epoch 14/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7484 - accuracy: 0.6639\n",
      "Epoch 15/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7431 - accuracy: 0.6705\n",
      "Epoch 16/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7511 - accuracy: 0.6609\n",
      "Epoch 17/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7481 - accuracy: 0.6594\n",
      "Epoch 18/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7508 - accuracy: 0.6590\n",
      "Epoch 19/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7491 - accuracy: 0.6565\n",
      "Epoch 20/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7404 - accuracy: 0.6634\n",
      "Epoch 21/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7523 - accuracy: 0.6652\n",
      "Epoch 22/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7276 - accuracy: 0.6776\n",
      "Epoch 23/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7279 - accuracy: 0.6744\n",
      "Epoch 24/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7463 - accuracy: 0.6665\n",
      "Epoch 25/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7405 - accuracy: 0.6694\n",
      "Epoch 26/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7330 - accuracy: 0.6735\n",
      "Epoch 27/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7430 - accuracy: 0.6664\n",
      "Epoch 28/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7543 - accuracy: 0.6613\n",
      "Epoch 29/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7442 - accuracy: 0.6729\n",
      "Epoch 30/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7199 - accuracy: 0.6738\n",
      "Epoch 31/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7511 - accuracy: 0.6626\n",
      "Epoch 32/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7499 - accuracy: 0.6566\n",
      "Epoch 33/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7085 - accuracy: 0.6801\n",
      "Epoch 34/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7400 - accuracy: 0.6783\n",
      "Epoch 35/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7420 - accuracy: 0.6658\n",
      "Epoch 36/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7352 - accuracy: 0.6704\n",
      "Epoch 37/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7470 - accuracy: 0.6654\n",
      "Epoch 38/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7409 - accuracy: 0.6692\n",
      "Epoch 39/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7574 - accuracy: 0.6730\n",
      "Epoch 40/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7301 - accuracy: 0.6655\n",
      "Epoch 41/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7357 - accuracy: 0.6684\n",
      "Epoch 42/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7306 - accuracy: 0.6673\n",
      "Epoch 43/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7306 - accuracy: 0.6778\n",
      "Epoch 44/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7219 - accuracy: 0.6785\n",
      "Epoch 45/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7303 - accuracy: 0.6643\n",
      "Epoch 46/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7459 - accuracy: 0.6683\n",
      "Epoch 47/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7260 - accuracy: 0.6730\n",
      "Epoch 48/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7336 - accuracy: 0.6790\n",
      "Epoch 49/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7266 - accuracy: 0.6775\n",
      "Epoch 50/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7357 - accuracy: 0.6691\n",
      "Epoch 51/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7493 - accuracy: 0.6686\n",
      "Epoch 52/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7320 - accuracy: 0.6757\n",
      "Epoch 53/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7418 - accuracy: 0.6653\n",
      "Epoch 54/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7203 - accuracy: 0.6626\n",
      "Epoch 55/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7384 - accuracy: 0.6676\n",
      "Epoch 56/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7406 - accuracy: 0.6641\n",
      "Epoch 57/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7429 - accuracy: 0.6574\n",
      "Epoch 58/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7371 - accuracy: 0.6657\n",
      "Epoch 59/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7221 - accuracy: 0.6794\n",
      "Epoch 60/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7174 - accuracy: 0.6761\n",
      "Epoch 61/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7309 - accuracy: 0.6841\n",
      "Epoch 62/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7455 - accuracy: 0.6698\n",
      "Epoch 63/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7392 - accuracy: 0.6672\n",
      "Epoch 64/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7192 - accuracy: 0.6840\n",
      "Epoch 65/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7343 - accuracy: 0.6741\n",
      "Epoch 66/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7355 - accuracy: 0.6760\n",
      "Epoch 67/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7455 - accuracy: 0.6726\n",
      "Epoch 68/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7311 - accuracy: 0.6678\n",
      "Epoch 69/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7293 - accuracy: 0.6772\n",
      "Epoch 70/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7284 - accuracy: 0.6740\n",
      "Epoch 71/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7066 - accuracy: 0.6886\n",
      "Epoch 72/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7209 - accuracy: 0.6752\n",
      "Epoch 73/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7526 - accuracy: 0.6570\n",
      "Epoch 74/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7310 - accuracy: 0.6715\n",
      "Epoch 75/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7194 - accuracy: 0.6769\n",
      "Epoch 76/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7326 - accuracy: 0.6696\n",
      "Epoch 77/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7374 - accuracy: 0.6663\n",
      "Epoch 78/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7249 - accuracy: 0.6780\n",
      "Epoch 79/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7371 - accuracy: 0.6809\n",
      "Epoch 80/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7178 - accuracy: 0.6775\n",
      "Epoch 81/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7271 - accuracy: 0.6788\n",
      "Epoch 82/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7330 - accuracy: 0.6757\n",
      "Epoch 83/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7314 - accuracy: 0.6758\n",
      "Epoch 84/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7414 - accuracy: 0.6704\n",
      "Epoch 85/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7481 - accuracy: 0.6703\n",
      "Epoch 86/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7142 - accuracy: 0.6769\n",
      "Epoch 87/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7438 - accuracy: 0.6713\n",
      "Epoch 88/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7279 - accuracy: 0.6799\n",
      "Epoch 89/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7367 - accuracy: 0.6815\n",
      "Epoch 90/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7291 - accuracy: 0.6745\n",
      "Epoch 91/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7348 - accuracy: 0.6731\n",
      "Epoch 92/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7295 - accuracy: 0.6840\n",
      "Epoch 93/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7292 - accuracy: 0.6705\n",
      "Epoch 94/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7279 - accuracy: 0.6765\n",
      "Epoch 95/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7157 - accuracy: 0.6732\n",
      "Epoch 96/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7265 - accuracy: 0.6817\n",
      "Epoch 97/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7455 - accuracy: 0.6753\n",
      "Epoch 98/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7312 - accuracy: 0.6758\n",
      "Epoch 99/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7253 - accuracy: 0.6763\n",
      "Epoch 100/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7325 - accuracy: 0.6658\n",
      "Epoch 101/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7159 - accuracy: 0.6858\n",
      "Epoch 102/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7302 - accuracy: 0.6739\n",
      "Epoch 103/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7256 - accuracy: 0.6676\n",
      "Epoch 104/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7488 - accuracy: 0.6642\n",
      "Epoch 105/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7511 - accuracy: 0.6589\n",
      "Epoch 106/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7482 - accuracy: 0.6674\n",
      "Epoch 107/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7182 - accuracy: 0.6835\n",
      "Epoch 108/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7389 - accuracy: 0.6717\n",
      "Epoch 109/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7226 - accuracy: 0.6846\n",
      "Epoch 110/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7266 - accuracy: 0.6746\n",
      "Epoch 111/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7443 - accuracy: 0.6607\n",
      "Epoch 112/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7311 - accuracy: 0.6668\n",
      "Epoch 113/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7147 - accuracy: 0.6818\n",
      "Epoch 114/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7277 - accuracy: 0.6873\n",
      "Epoch 115/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7332 - accuracy: 0.6665\n",
      "Epoch 116/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7513 - accuracy: 0.6709\n",
      "Epoch 117/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7321 - accuracy: 0.6791\n",
      "Epoch 118/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7318 - accuracy: 0.6771\n",
      "Epoch 119/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7297 - accuracy: 0.6702\n",
      "Epoch 120/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7301 - accuracy: 0.6826\n",
      "Epoch 121/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7494 - accuracy: 0.6719\n",
      "Epoch 122/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7364 - accuracy: 0.6698\n",
      "Epoch 123/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7137 - accuracy: 0.6898\n",
      "Epoch 124/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7292 - accuracy: 0.6703\n",
      "Epoch 125/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7264 - accuracy: 0.6713\n",
      "Epoch 126/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7348 - accuracy: 0.6746\n",
      "Epoch 127/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7348 - accuracy: 0.6672\n",
      "Epoch 128/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7124 - accuracy: 0.6880\n",
      "Epoch 129/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7265 - accuracy: 0.6807\n",
      "Epoch 130/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7384 - accuracy: 0.6680\n",
      "Epoch 131/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7201 - accuracy: 0.6789\n",
      "Epoch 132/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7324 - accuracy: 0.6696\n",
      "Epoch 133/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7178 - accuracy: 0.6753\n",
      "Epoch 134/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7287 - accuracy: 0.6662\n",
      "Epoch 135/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7178 - accuracy: 0.6829\n",
      "Epoch 136/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7164 - accuracy: 0.6805\n",
      "Epoch 137/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7381 - accuracy: 0.6717\n",
      "Epoch 138/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7491 - accuracy: 0.6743\n",
      "Epoch 139/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7274 - accuracy: 0.6783\n",
      "Epoch 140/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7313 - accuracy: 0.6868\n",
      "Epoch 141/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7339 - accuracy: 0.6775\n",
      "Epoch 142/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7380 - accuracy: 0.6725\n",
      "Epoch 143/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7294 - accuracy: 0.6713\n",
      "Epoch 144/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7176 - accuracy: 0.6736\n",
      "Epoch 145/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7312 - accuracy: 0.6702\n",
      "Epoch 146/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7254 - accuracy: 0.6747\n",
      "Epoch 147/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7222 - accuracy: 0.6825\n",
      "Epoch 148/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7357 - accuracy: 0.6794\n",
      "Epoch 149/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7264 - accuracy: 0.6834\n",
      "Epoch 150/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7272 - accuracy: 0.6689\n",
      "Epoch 151/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7290 - accuracy: 0.6735\n",
      "Epoch 152/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7223 - accuracy: 0.6807\n",
      "Epoch 153/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7256 - accuracy: 0.6841\n",
      "Epoch 154/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7509 - accuracy: 0.6629\n",
      "Epoch 155/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7149 - accuracy: 0.6901\n",
      "Epoch 156/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7300 - accuracy: 0.6851\n",
      "Epoch 157/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7118 - accuracy: 0.6831\n",
      "Epoch 158/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7228 - accuracy: 0.6804\n",
      "Epoch 159/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7280 - accuracy: 0.6715\n",
      "Epoch 160/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7296 - accuracy: 0.6857\n",
      "Epoch 161/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7090 - accuracy: 0.6881\n",
      "Epoch 162/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7376 - accuracy: 0.6758\n",
      "Epoch 163/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7068 - accuracy: 0.6912\n",
      "Epoch 164/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7298 - accuracy: 0.6851\n",
      "Epoch 165/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7333 - accuracy: 0.6777\n",
      "Epoch 166/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7316 - accuracy: 0.6922\n",
      "Epoch 167/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7083 - accuracy: 0.6919\n",
      "Epoch 168/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7304 - accuracy: 0.6785\n",
      "Epoch 169/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7179 - accuracy: 0.6864\n",
      "Epoch 170/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7409 - accuracy: 0.6760\n",
      "Epoch 171/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7527 - accuracy: 0.6656\n",
      "Epoch 172/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7254 - accuracy: 0.6892\n",
      "Epoch 173/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7100 - accuracy: 0.6962\n",
      "Epoch 174/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7236 - accuracy: 0.6770\n",
      "Epoch 175/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7304 - accuracy: 0.6775\n",
      "Epoch 176/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7224 - accuracy: 0.6892\n",
      "Epoch 177/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7394 - accuracy: 0.6720\n",
      "Epoch 178/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7159 - accuracy: 0.6880\n",
      "Epoch 179/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7233 - accuracy: 0.6867\n",
      "Epoch 180/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7212 - accuracy: 0.6842\n",
      "Epoch 181/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7327 - accuracy: 0.6754\n",
      "Epoch 182/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7204 - accuracy: 0.6865\n",
      "Epoch 183/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7321 - accuracy: 0.6678\n",
      "Epoch 184/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7228 - accuracy: 0.6842\n",
      "Epoch 185/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7331 - accuracy: 0.6753\n",
      "Epoch 186/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7414 - accuracy: 0.6730\n",
      "Epoch 187/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7391 - accuracy: 0.6796\n",
      "Epoch 188/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7115 - accuracy: 0.7017\n",
      "Epoch 189/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7343 - accuracy: 0.6881\n",
      "Epoch 190/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7247 - accuracy: 0.6755\n",
      "Epoch 191/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7153 - accuracy: 0.6788\n",
      "Epoch 192/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7198 - accuracy: 0.6905\n",
      "Epoch 193/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7269 - accuracy: 0.6740\n",
      "Epoch 194/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7036 - accuracy: 0.6942\n",
      "Epoch 195/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7069 - accuracy: 0.6958\n",
      "Epoch 196/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7394 - accuracy: 0.6843\n",
      "Epoch 197/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7455 - accuracy: 0.6733\n",
      "Epoch 198/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7466 - accuracy: 0.6745\n",
      "Epoch 199/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7161 - accuracy: 0.6958\n",
      "Epoch 200/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7174 - accuracy: 0.6903\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 802us/step - loss: 0.7979 - accuracy: 0.6379\n",
      "Acc:\n",
      "0.6378714442253113\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Acc:')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_234\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_710 (Dense)            (None, 16)                304       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_711 (Dense)            (None, 14)                238       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_712 (Dense)            (None, 10)                150       \n",
      "_________________________________________________________________\n",
      "dense_713 (Dense)            (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 725\n",
      "Trainable params: 725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, kernel_initializer='normal', activation='relu', input_shape=(18,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "252/252 [==============================] - 1s 1ms/step - loss: 1.0295 - accuracy: 0.5018\n",
      "Epoch 2/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7894 - accuracy: 0.6494\n",
      "Epoch 3/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7590 - accuracy: 0.6579\n",
      "Epoch 4/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7546 - accuracy: 0.6608\n",
      "Epoch 5/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7493 - accuracy: 0.6590\n",
      "Epoch 6/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7641 - accuracy: 0.6586\n",
      "Epoch 7/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7689 - accuracy: 0.6483\n",
      "Epoch 8/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7465 - accuracy: 0.6639\n",
      "Epoch 9/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7435 - accuracy: 0.6587\n",
      "Epoch 10/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7382 - accuracy: 0.6734\n",
      "Epoch 11/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7516 - accuracy: 0.6565\n",
      "Epoch 12/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7543 - accuracy: 0.6626\n",
      "Epoch 13/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7508 - accuracy: 0.6589\n",
      "Epoch 14/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7324 - accuracy: 0.6603\n",
      "Epoch 15/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7400 - accuracy: 0.6627\n",
      "Epoch 16/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7550 - accuracy: 0.6679\n",
      "Epoch 17/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7537 - accuracy: 0.6605\n",
      "Epoch 18/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7262 - accuracy: 0.6781\n",
      "Epoch 19/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7510 - accuracy: 0.6608\n",
      "Epoch 20/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7464 - accuracy: 0.6726\n",
      "Epoch 21/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7516 - accuracy: 0.6748\n",
      "Epoch 22/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7351 - accuracy: 0.6731\n",
      "Epoch 23/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7313 - accuracy: 0.6780\n",
      "Epoch 24/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7225 - accuracy: 0.6753\n",
      "Epoch 25/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7267 - accuracy: 0.6763\n",
      "Epoch 26/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7315 - accuracy: 0.6691\n",
      "Epoch 27/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7396 - accuracy: 0.6673\n",
      "Epoch 28/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7286 - accuracy: 0.6782\n",
      "Epoch 29/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7309 - accuracy: 0.6692\n",
      "Epoch 30/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7279 - accuracy: 0.6835\n",
      "Epoch 31/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7292 - accuracy: 0.6787\n",
      "Epoch 32/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7409 - accuracy: 0.6632\n",
      "Epoch 33/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7659 - accuracy: 0.6545\n",
      "Epoch 34/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7384 - accuracy: 0.6639\n",
      "Epoch 35/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7143 - accuracy: 0.6781\n",
      "Epoch 36/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7298 - accuracy: 0.6727\n",
      "Epoch 37/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7419 - accuracy: 0.6687\n",
      "Epoch 38/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7241 - accuracy: 0.6860\n",
      "Epoch 39/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7254 - accuracy: 0.6869\n",
      "Epoch 40/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7333 - accuracy: 0.6706\n",
      "Epoch 41/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7242 - accuracy: 0.6803\n",
      "Epoch 42/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7308 - accuracy: 0.6717\n",
      "Epoch 43/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7288 - accuracy: 0.6714\n",
      "Epoch 44/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7345 - accuracy: 0.6702\n",
      "Epoch 45/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7266 - accuracy: 0.6740\n",
      "Epoch 46/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7305 - accuracy: 0.6732\n",
      "Epoch 47/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7226 - accuracy: 0.6866\n",
      "Epoch 48/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7265 - accuracy: 0.6795\n",
      "Epoch 49/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7293 - accuracy: 0.6789\n",
      "Epoch 50/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7296 - accuracy: 0.6687\n",
      "Epoch 51/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7263 - accuracy: 0.6792\n",
      "Epoch 52/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7066 - accuracy: 0.6911\n",
      "Epoch 53/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7265 - accuracy: 0.6850\n",
      "Epoch 54/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7278 - accuracy: 0.6755\n",
      "Epoch 55/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7393 - accuracy: 0.6711\n",
      "Epoch 56/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7305 - accuracy: 0.6783\n",
      "Epoch 57/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7482 - accuracy: 0.6722\n",
      "Epoch 58/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7333 - accuracy: 0.6709\n",
      "Epoch 59/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7323 - accuracy: 0.6689\n",
      "Epoch 60/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7280 - accuracy: 0.6743\n",
      "Epoch 61/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7253 - accuracy: 0.6804\n",
      "Epoch 62/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7212 - accuracy: 0.6729\n",
      "Epoch 63/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7292 - accuracy: 0.6726\n",
      "Epoch 64/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7227 - accuracy: 0.6911\n",
      "Epoch 65/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6980 - accuracy: 0.6912\n",
      "Epoch 66/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7312 - accuracy: 0.6885\n",
      "Epoch 67/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7179 - accuracy: 0.6882\n",
      "Epoch 68/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7108 - accuracy: 0.6840\n",
      "Epoch 69/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7213 - accuracy: 0.6823\n",
      "Epoch 70/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.6803\n",
      "Epoch 71/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7217 - accuracy: 0.6855\n",
      "Epoch 72/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7394 - accuracy: 0.6726\n",
      "Epoch 73/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7174 - accuracy: 0.6903\n",
      "Epoch 74/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7214 - accuracy: 0.6859\n",
      "Epoch 75/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7169 - accuracy: 0.6907\n",
      "Epoch 76/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7268 - accuracy: 0.6759\n",
      "Epoch 77/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7227 - accuracy: 0.6812\n",
      "Epoch 78/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7282 - accuracy: 0.6809\n",
      "Epoch 79/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7143 - accuracy: 0.6854\n",
      "Epoch 80/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7143 - accuracy: 0.6825\n",
      "Epoch 81/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7169 - accuracy: 0.6835\n",
      "Epoch 82/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7173 - accuracy: 0.6804\n",
      "Epoch 83/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7167 - accuracy: 0.6816\n",
      "Epoch 84/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7010 - accuracy: 0.6905\n",
      "Epoch 85/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7090 - accuracy: 0.6899\n",
      "Epoch 86/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7305 - accuracy: 0.6774\n",
      "Epoch 87/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6993 - accuracy: 0.6932\n",
      "Epoch 88/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7107 - accuracy: 0.6864\n",
      "Epoch 89/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7210 - accuracy: 0.6706\n",
      "Epoch 90/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7148 - accuracy: 0.6834\n",
      "Epoch 91/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7318 - accuracy: 0.6772\n",
      "Epoch 92/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7353 - accuracy: 0.6738\n",
      "Epoch 93/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7179 - accuracy: 0.6828\n",
      "Epoch 94/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7233 - accuracy: 0.6793\n",
      "Epoch 95/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7344 - accuracy: 0.6782\n",
      "Epoch 96/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7225 - accuracy: 0.6764\n",
      "Epoch 97/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7413 - accuracy: 0.6762\n",
      "Epoch 98/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7377 - accuracy: 0.6798\n",
      "Epoch 99/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7474 - accuracy: 0.6638\n",
      "Epoch 100/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7035 - accuracy: 0.6875\n",
      "Epoch 101/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6992 - accuracy: 0.6913\n",
      "Epoch 102/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7064 - accuracy: 0.6905\n",
      "Epoch 103/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7217 - accuracy: 0.6922\n",
      "Epoch 104/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7109 - accuracy: 0.6871\n",
      "Epoch 105/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7121 - accuracy: 0.6886\n",
      "Epoch 106/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7064 - accuracy: 0.6783\n",
      "Epoch 107/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7142 - accuracy: 0.6850\n",
      "Epoch 108/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7215 - accuracy: 0.6794\n",
      "Epoch 109/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7262 - accuracy: 0.6788\n",
      "Epoch 110/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7209 - accuracy: 0.6806\n",
      "Epoch 111/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7104 - accuracy: 0.6908\n",
      "Epoch 112/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7041 - accuracy: 0.6958\n",
      "Epoch 113/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7208 - accuracy: 0.6884\n",
      "Epoch 114/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7203 - accuracy: 0.6826\n",
      "Epoch 115/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7225 - accuracy: 0.6808\n",
      "Epoch 116/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7088 - accuracy: 0.6973\n",
      "Epoch 117/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7259 - accuracy: 0.6880\n",
      "Epoch 118/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7231 - accuracy: 0.6833\n",
      "Epoch 119/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7178 - accuracy: 0.6909\n",
      "Epoch 120/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7188 - accuracy: 0.6806\n",
      "Epoch 121/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7323 - accuracy: 0.6786\n",
      "Epoch 122/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7271 - accuracy: 0.6790\n",
      "Epoch 123/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7126 - accuracy: 0.6848\n",
      "Epoch 124/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7205 - accuracy: 0.6857\n",
      "Epoch 125/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7148 - accuracy: 0.6883\n",
      "Epoch 126/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7288 - accuracy: 0.6793\n",
      "Epoch 127/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7353 - accuracy: 0.6788\n",
      "Epoch 128/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7249 - accuracy: 0.6860\n",
      "Epoch 129/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7227 - accuracy: 0.6788\n",
      "Epoch 130/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7147 - accuracy: 0.6867\n",
      "Epoch 131/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7121 - accuracy: 0.6936\n",
      "Epoch 132/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7134 - accuracy: 0.6933\n",
      "Epoch 133/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7176 - accuracy: 0.6859\n",
      "Epoch 134/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7283 - accuracy: 0.6789\n",
      "Epoch 135/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7175 - accuracy: 0.6966\n",
      "Epoch 136/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7322 - accuracy: 0.6842\n",
      "Epoch 137/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7084 - accuracy: 0.6804\n",
      "Epoch 138/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7080 - accuracy: 0.6920\n",
      "Epoch 139/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7375 - accuracy: 0.6732\n",
      "Epoch 140/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7072 - accuracy: 0.6916\n",
      "Epoch 141/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7135 - accuracy: 0.6796\n",
      "Epoch 142/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7093 - accuracy: 0.6911\n",
      "Epoch 143/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7437 - accuracy: 0.6690\n",
      "Epoch 144/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7191 - accuracy: 0.6894\n",
      "Epoch 145/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7338 - accuracy: 0.6807\n",
      "Epoch 146/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7296 - accuracy: 0.6718\n",
      "Epoch 147/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7151 - accuracy: 0.6825\n",
      "Epoch 148/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7229 - accuracy: 0.6815\n",
      "Epoch 149/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7160 - accuracy: 0.6875\n",
      "Epoch 150/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7099 - accuracy: 0.6926\n",
      "Epoch 151/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7081 - accuracy: 0.6936\n",
      "Epoch 152/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.7021\n",
      "Epoch 153/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7035 - accuracy: 0.6858\n",
      "Epoch 154/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7190 - accuracy: 0.6863\n",
      "Epoch 155/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7099 - accuracy: 0.6964\n",
      "Epoch 156/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7289 - accuracy: 0.6797\n",
      "Epoch 157/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7266 - accuracy: 0.6823\n",
      "Epoch 158/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7243 - accuracy: 0.6761\n",
      "Epoch 159/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7349 - accuracy: 0.6810\n",
      "Epoch 160/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7084 - accuracy: 0.6883\n",
      "Epoch 161/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7159 - accuracy: 0.6963\n",
      "Epoch 162/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7305 - accuracy: 0.6802\n",
      "Epoch 163/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7219 - accuracy: 0.6833\n",
      "Epoch 164/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7029 - accuracy: 0.6873\n",
      "Epoch 165/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7104 - accuracy: 0.6923\n",
      "Epoch 166/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7083 - accuracy: 0.6877\n",
      "Epoch 167/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7157 - accuracy: 0.6792\n",
      "Epoch 168/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7263 - accuracy: 0.6813\n",
      "Epoch 169/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7328 - accuracy: 0.6658\n",
      "Epoch 170/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7130 - accuracy: 0.6854\n",
      "Epoch 171/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7224 - accuracy: 0.6771\n",
      "Epoch 172/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7302 - accuracy: 0.6795\n",
      "Epoch 173/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7215 - accuracy: 0.6840\n",
      "Epoch 174/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7070 - accuracy: 0.6808\n",
      "Epoch 175/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7355 - accuracy: 0.6698\n",
      "Epoch 176/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7191 - accuracy: 0.6820\n",
      "Epoch 177/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7141 - accuracy: 0.6834\n",
      "Epoch 178/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6979 - accuracy: 0.6937\n",
      "Epoch 179/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7171 - accuracy: 0.6811\n",
      "Epoch 180/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7274 - accuracy: 0.6780\n",
      "Epoch 181/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7292 - accuracy: 0.6754\n",
      "Epoch 182/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7135 - accuracy: 0.6846\n",
      "Epoch 183/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7299 - accuracy: 0.6778\n",
      "Epoch 184/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7252 - accuracy: 0.6824\n",
      "Epoch 185/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7181 - accuracy: 0.6853\n",
      "Epoch 186/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7110 - accuracy: 0.6812\n",
      "Epoch 187/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7235 - accuracy: 0.6844\n",
      "Epoch 188/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7159 - accuracy: 0.6889\n",
      "Epoch 189/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7266 - accuracy: 0.6793\n",
      "Epoch 190/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7386 - accuracy: 0.6724\n",
      "Epoch 191/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7281 - accuracy: 0.6809\n",
      "Epoch 192/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7130 - accuracy: 0.6833\n",
      "Epoch 193/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7307 - accuracy: 0.6835\n",
      "Epoch 194/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7297 - accuracy: 0.6696\n",
      "Epoch 195/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7307 - accuracy: 0.6831\n",
      "Epoch 196/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7246 - accuracy: 0.6874\n",
      "Epoch 197/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7102 - accuracy: 0.6927\n",
      "Epoch 198/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7282 - accuracy: 0.6831\n",
      "Epoch 199/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7179 - accuracy: 0.6812\n",
      "Epoch 200/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7324 - accuracy: 0.6792\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 0.7764 - accuracy: 0.6441\n",
      "Acc:\n",
      "0.6440912485122681\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Acc:')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_235\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_714 (Dense)            (None, 16)                304       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_715 (Dense)            (None, 14)                238       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_716 (Dense)            (None, 8)                 120       \n",
      "_________________________________________________________________\n",
      "dense_717 (Dense)            (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 689\n",
      "Trainable params: 689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, kernel_initializer='normal', activation='relu', input_shape=(18,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "252/252 [==============================] - 1s 1ms/step - loss: 1.0335 - accuracy: 0.5257\n",
      "Epoch 2/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7873 - accuracy: 0.6481\n",
      "Epoch 3/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7757 - accuracy: 0.6452\n",
      "Epoch 4/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7563 - accuracy: 0.6607\n",
      "Epoch 5/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7430 - accuracy: 0.6705\n",
      "Epoch 6/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7458 - accuracy: 0.6728\n",
      "Epoch 7/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7505 - accuracy: 0.6535\n",
      "Epoch 8/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7418 - accuracy: 0.6658\n",
      "Epoch 9/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7584 - accuracy: 0.6626\n",
      "Epoch 10/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7467 - accuracy: 0.6624\n",
      "Epoch 11/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7362 - accuracy: 0.6695\n",
      "Epoch 12/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7418 - accuracy: 0.6693\n",
      "Epoch 13/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7381 - accuracy: 0.6678\n",
      "Epoch 14/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7425 - accuracy: 0.6652\n",
      "Epoch 15/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7388 - accuracy: 0.6739\n",
      "Epoch 16/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7535 - accuracy: 0.6657\n",
      "Epoch 17/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7461 - accuracy: 0.6581\n",
      "Epoch 18/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7323 - accuracy: 0.6735\n",
      "Epoch 19/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7160 - accuracy: 0.6788\n",
      "Epoch 20/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7547 - accuracy: 0.6619\n",
      "Epoch 21/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7250 - accuracy: 0.6627\n",
      "Epoch 22/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7169 - accuracy: 0.6763\n",
      "Epoch 23/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7258 - accuracy: 0.6761\n",
      "Epoch 24/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7290 - accuracy: 0.6751\n",
      "Epoch 25/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7297 - accuracy: 0.6731\n",
      "Epoch 26/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7241 - accuracy: 0.6799\n",
      "Epoch 27/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7231 - accuracy: 0.6688\n",
      "Epoch 28/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7377 - accuracy: 0.6722\n",
      "Epoch 29/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7216 - accuracy: 0.6868\n",
      "Epoch 30/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7193 - accuracy: 0.6816\n",
      "Epoch 31/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7019 - accuracy: 0.6854\n",
      "Epoch 32/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7299 - accuracy: 0.6828\n",
      "Epoch 33/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7374 - accuracy: 0.6715\n",
      "Epoch 34/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7228 - accuracy: 0.6872\n",
      "Epoch 35/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7245 - accuracy: 0.6772\n",
      "Epoch 36/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7484 - accuracy: 0.6653\n",
      "Epoch 37/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7313 - accuracy: 0.6727\n",
      "Epoch 38/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7392 - accuracy: 0.6685\n",
      "Epoch 39/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7250 - accuracy: 0.6782\n",
      "Epoch 40/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7335 - accuracy: 0.6773\n",
      "Epoch 41/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7479 - accuracy: 0.6559\n",
      "Epoch 42/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7096 - accuracy: 0.6810\n",
      "Epoch 43/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7328 - accuracy: 0.6757\n",
      "Epoch 44/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7392 - accuracy: 0.6698\n",
      "Epoch 45/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7173 - accuracy: 0.6803\n",
      "Epoch 46/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7324 - accuracy: 0.6771\n",
      "Epoch 47/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7285 - accuracy: 0.6704\n",
      "Epoch 48/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7156 - accuracy: 0.6670\n",
      "Epoch 49/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7223 - accuracy: 0.6804\n",
      "Epoch 50/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7159 - accuracy: 0.6759\n",
      "Epoch 51/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7191 - accuracy: 0.6746\n",
      "Epoch 52/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7249 - accuracy: 0.6780\n",
      "Epoch 53/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7294 - accuracy: 0.6668\n",
      "Epoch 54/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7332 - accuracy: 0.6662\n",
      "Epoch 55/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7298 - accuracy: 0.6757\n",
      "Epoch 56/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7269 - accuracy: 0.6809\n",
      "Epoch 57/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7231 - accuracy: 0.6814\n",
      "Epoch 58/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7532 - accuracy: 0.6618\n",
      "Epoch 59/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7161 - accuracy: 0.6848\n",
      "Epoch 60/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7476 - accuracy: 0.6645\n",
      "Epoch 61/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7120 - accuracy: 0.6831\n",
      "Epoch 62/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7128 - accuracy: 0.6812\n",
      "Epoch 63/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7289 - accuracy: 0.6834\n",
      "Epoch 64/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7189 - accuracy: 0.6910\n",
      "Epoch 65/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7238 - accuracy: 0.6764\n",
      "Epoch 66/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7128 - accuracy: 0.6854\n",
      "Epoch 67/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7222 - accuracy: 0.6860\n",
      "Epoch 68/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7295 - accuracy: 0.6789\n",
      "Epoch 69/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7239 - accuracy: 0.6856\n",
      "Epoch 70/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7325 - accuracy: 0.6758\n",
      "Epoch 71/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7337 - accuracy: 0.6760\n",
      "Epoch 72/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7199 - accuracy: 0.6860\n",
      "Epoch 73/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7304 - accuracy: 0.6731\n",
      "Epoch 74/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7379 - accuracy: 0.6731\n",
      "Epoch 75/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7201 - accuracy: 0.6852\n",
      "Epoch 76/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7326 - accuracy: 0.6832\n",
      "Epoch 77/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7289 - accuracy: 0.6775\n",
      "Epoch 78/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7282 - accuracy: 0.6759\n",
      "Epoch 79/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7045 - accuracy: 0.7012\n",
      "Epoch 80/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7019 - accuracy: 0.6973\n",
      "Epoch 81/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7120 - accuracy: 0.6842\n",
      "Epoch 82/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7337 - accuracy: 0.6763\n",
      "Epoch 83/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7294 - accuracy: 0.6880\n",
      "Epoch 84/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7263 - accuracy: 0.6792\n",
      "Epoch 85/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7260 - accuracy: 0.6843\n",
      "Epoch 86/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7243 - accuracy: 0.6864\n",
      "Epoch 87/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7226 - accuracy: 0.6865\n",
      "Epoch 88/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7216 - accuracy: 0.6818\n",
      "Epoch 89/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7216 - accuracy: 0.6893\n",
      "Epoch 90/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6985 - accuracy: 0.6986\n",
      "Epoch 91/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7292 - accuracy: 0.6840\n",
      "Epoch 92/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7264 - accuracy: 0.6801\n",
      "Epoch 93/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7068 - accuracy: 0.6909\n",
      "Epoch 94/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7323 - accuracy: 0.6847\n",
      "Epoch 95/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7212 - accuracy: 0.6904\n",
      "Epoch 96/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7045 - accuracy: 0.6921\n",
      "Epoch 97/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7111 - accuracy: 0.6858\n",
      "Epoch 98/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7386 - accuracy: 0.6777\n",
      "Epoch 99/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7414 - accuracy: 0.6751\n",
      "Epoch 100/200\n",
      "252/252 [==============================] - 0s 994us/step - loss: 0.7273 - accuracy: 0.6802\n",
      "Epoch 101/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7242 - accuracy: 0.6742\n",
      "Epoch 102/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7196 - accuracy: 0.6831\n",
      "Epoch 103/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7204 - accuracy: 0.6820\n",
      "Epoch 104/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7170 - accuracy: 0.6874\n",
      "Epoch 105/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.6943\n",
      "Epoch 106/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7282 - accuracy: 0.6891\n",
      "Epoch 107/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7107 - accuracy: 0.6845\n",
      "Epoch 108/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7172 - accuracy: 0.6883\n",
      "Epoch 109/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7245 - accuracy: 0.6822\n",
      "Epoch 110/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7173 - accuracy: 0.6935\n",
      "Epoch 111/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7238 - accuracy: 0.6815\n",
      "Epoch 112/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7150 - accuracy: 0.6832\n",
      "Epoch 113/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7085 - accuracy: 0.6905\n",
      "Epoch 114/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7225 - accuracy: 0.6792\n",
      "Epoch 115/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7144 - accuracy: 0.6961\n",
      "Epoch 116/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7303 - accuracy: 0.6852\n",
      "Epoch 117/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7236 - accuracy: 0.6876\n",
      "Epoch 118/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7231 - accuracy: 0.6875\n",
      "Epoch 119/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7340 - accuracy: 0.6726\n",
      "Epoch 120/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7174 - accuracy: 0.6849\n",
      "Epoch 121/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7224 - accuracy: 0.6942\n",
      "Epoch 122/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7194 - accuracy: 0.6943\n",
      "Epoch 123/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7276 - accuracy: 0.6839\n",
      "Epoch 124/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7369 - accuracy: 0.6816\n",
      "Epoch 125/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7235 - accuracy: 0.6928\n",
      "Epoch 126/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7096 - accuracy: 0.6925\n",
      "Epoch 127/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7282 - accuracy: 0.6864\n",
      "Epoch 128/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7136 - accuracy: 0.6881\n",
      "Epoch 129/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.6922\n",
      "Epoch 130/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7092 - accuracy: 0.6961\n",
      "Epoch 131/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7299 - accuracy: 0.6824\n",
      "Epoch 132/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7226 - accuracy: 0.6899\n",
      "Epoch 133/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7256 - accuracy: 0.6780\n",
      "Epoch 134/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7258 - accuracy: 0.6916\n",
      "Epoch 135/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7325 - accuracy: 0.6782\n",
      "Epoch 136/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7252 - accuracy: 0.6867\n",
      "Epoch 137/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7202 - accuracy: 0.6834\n",
      "Epoch 138/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7138 - accuracy: 0.6855\n",
      "Epoch 139/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7172 - accuracy: 0.6808\n",
      "Epoch 140/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7312 - accuracy: 0.6773\n",
      "Epoch 141/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7000 - accuracy: 0.6989\n",
      "Epoch 142/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7307 - accuracy: 0.6853\n",
      "Epoch 143/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7072 - accuracy: 0.6948\n",
      "Epoch 144/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6987 - accuracy: 0.6971\n",
      "Epoch 145/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7182 - accuracy: 0.6857\n",
      "Epoch 146/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7017 - accuracy: 0.6939\n",
      "Epoch 147/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7195 - accuracy: 0.6927\n",
      "Epoch 148/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7136 - accuracy: 0.6942\n",
      "Epoch 149/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7339 - accuracy: 0.6853\n",
      "Epoch 150/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7135 - accuracy: 0.6894\n",
      "Epoch 151/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7330 - accuracy: 0.6884\n",
      "Epoch 152/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7099 - accuracy: 0.6953\n",
      "Epoch 153/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7314 - accuracy: 0.6855\n",
      "Epoch 154/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7154 - accuracy: 0.6754\n",
      "Epoch 155/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7348 - accuracy: 0.6814\n",
      "Epoch 156/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7266 - accuracy: 0.6823\n",
      "Epoch 157/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7289 - accuracy: 0.6894\n",
      "Epoch 158/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7370 - accuracy: 0.6752\n",
      "Epoch 159/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7121 - accuracy: 0.6897\n",
      "Epoch 160/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7304 - accuracy: 0.6758\n",
      "Epoch 161/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7156 - accuracy: 0.6888\n",
      "Epoch 162/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7289 - accuracy: 0.6828\n",
      "Epoch 163/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7243 - accuracy: 0.6875\n",
      "Epoch 164/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7175 - accuracy: 0.6794\n",
      "Epoch 165/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7290 - accuracy: 0.6773\n",
      "Epoch 166/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7110 - accuracy: 0.6935\n",
      "Epoch 167/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7155 - accuracy: 0.6893\n",
      "Epoch 168/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7502 - accuracy: 0.6808\n",
      "Epoch 169/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7176 - accuracy: 0.6901\n",
      "Epoch 170/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7073 - accuracy: 0.6975\n",
      "Epoch 171/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7353 - accuracy: 0.6885\n",
      "Epoch 172/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6964 - accuracy: 0.6975\n",
      "Epoch 173/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7168 - accuracy: 0.6756\n",
      "Epoch 174/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7192 - accuracy: 0.6841\n",
      "Epoch 175/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7245 - accuracy: 0.6902\n",
      "Epoch 176/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7147 - accuracy: 0.6833\n",
      "Epoch 177/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7190 - accuracy: 0.6928\n",
      "Epoch 178/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7192 - accuracy: 0.6904\n",
      "Epoch 179/200\n",
      "252/252 [==============================] - 0s 992us/step - loss: 0.7034 - accuracy: 0.6963\n",
      "Epoch 180/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7157 - accuracy: 0.6825\n",
      "Epoch 181/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7386 - accuracy: 0.6733\n",
      "Epoch 182/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7254 - accuracy: 0.6791\n",
      "Epoch 183/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7204 - accuracy: 0.6902\n",
      "Epoch 184/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7065 - accuracy: 0.6889\n",
      "Epoch 185/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7214 - accuracy: 0.6780\n",
      "Epoch 186/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6984 - accuracy: 0.7068\n",
      "Epoch 187/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6993 - accuracy: 0.6993\n",
      "Epoch 188/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.6991\n",
      "Epoch 189/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7215 - accuracy: 0.6821\n",
      "Epoch 190/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7296 - accuracy: 0.6794\n",
      "Epoch 191/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7073 - accuracy: 0.6928\n",
      "Epoch 192/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7257 - accuracy: 0.6864\n",
      "Epoch 193/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7313 - accuracy: 0.6768\n",
      "Epoch 194/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7158 - accuracy: 0.6962\n",
      "Epoch 195/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7101 - accuracy: 0.6913\n",
      "Epoch 196/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7430 - accuracy: 0.6738\n",
      "Epoch 197/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7133 - accuracy: 0.6928\n",
      "Epoch 198/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7131 - accuracy: 0.6871\n",
      "Epoch 199/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7203 - accuracy: 0.6866\n",
      "Epoch 200/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7127 - accuracy: 0.6917\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 918us/step - loss: 0.7776 - accuracy: 0.6337\n",
      "Acc:\n",
      "0.6337249279022217\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Acc:')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_236\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_718 (Dense)            (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_719 (Dense)            (None, 14)                266       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_720 (Dense)            (None, 10)                150       \n",
      "_________________________________________________________________\n",
      "dense_721 (Dense)            (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 791\n",
      "Trainable params: 791\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(18, kernel_initializer='normal', activation='relu', input_shape=(18,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "252/252 [==============================] - 1s 1ms/step - loss: 1.0504 - accuracy: 0.4863\n",
      "Epoch 2/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7773 - accuracy: 0.6546\n",
      "Epoch 3/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7769 - accuracy: 0.6389\n",
      "Epoch 4/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7559 - accuracy: 0.6610\n",
      "Epoch 5/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7610 - accuracy: 0.6594\n",
      "Epoch 6/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7763 - accuracy: 0.6447\n",
      "Epoch 7/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7478 - accuracy: 0.6690\n",
      "Epoch 8/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7477 - accuracy: 0.6589\n",
      "Epoch 9/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7440 - accuracy: 0.6610\n",
      "Epoch 10/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7347 - accuracy: 0.6736\n",
      "Epoch 11/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7422 - accuracy: 0.6601\n",
      "Epoch 12/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7462 - accuracy: 0.6743\n",
      "Epoch 13/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7343 - accuracy: 0.6701\n",
      "Epoch 14/200\n",
      "252/252 [==============================] - 0s 998us/step - loss: 0.7443 - accuracy: 0.6630\n",
      "Epoch 15/200\n",
      "252/252 [==============================] - 0s 978us/step - loss: 0.7321 - accuracy: 0.6654\n",
      "Epoch 16/200\n",
      "252/252 [==============================] - 0s 992us/step - loss: 0.7547 - accuracy: 0.6628\n",
      "Epoch 17/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7473 - accuracy: 0.6677\n",
      "Epoch 18/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7251 - accuracy: 0.6848\n",
      "Epoch 19/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7232 - accuracy: 0.6694\n",
      "Epoch 20/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7597 - accuracy: 0.6665\n",
      "Epoch 21/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7302 - accuracy: 0.6709\n",
      "Epoch 22/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7303 - accuracy: 0.6810\n",
      "Epoch 23/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7341 - accuracy: 0.6715\n",
      "Epoch 24/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7275 - accuracy: 0.6754\n",
      "Epoch 25/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7271 - accuracy: 0.6777\n",
      "Epoch 26/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7193 - accuracy: 0.6748\n",
      "Epoch 27/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7233 - accuracy: 0.6806\n",
      "Epoch 28/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7322 - accuracy: 0.6627\n",
      "Epoch 29/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7252 - accuracy: 0.6879\n",
      "Epoch 30/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7316 - accuracy: 0.6745\n",
      "Epoch 31/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7346 - accuracy: 0.6784\n",
      "Epoch 32/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7362 - accuracy: 0.6735\n",
      "Epoch 33/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7171 - accuracy: 0.6777\n",
      "Epoch 34/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7194 - accuracy: 0.6800\n",
      "Epoch 35/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7223 - accuracy: 0.6731\n",
      "Epoch 36/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7332 - accuracy: 0.6829\n",
      "Epoch 37/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7386 - accuracy: 0.6725\n",
      "Epoch 38/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7150 - accuracy: 0.6866\n",
      "Epoch 39/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7301 - accuracy: 0.6774\n",
      "Epoch 40/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7200 - accuracy: 0.6852\n",
      "Epoch 41/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7210 - accuracy: 0.6823\n",
      "Epoch 42/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7215 - accuracy: 0.6793\n",
      "Epoch 43/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7172 - accuracy: 0.6889\n",
      "Epoch 44/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7244 - accuracy: 0.6855\n",
      "Epoch 45/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7180 - accuracy: 0.6846\n",
      "Epoch 46/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7278 - accuracy: 0.6718\n",
      "Epoch 47/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7414 - accuracy: 0.6703\n",
      "Epoch 48/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7288 - accuracy: 0.6687\n",
      "Epoch 49/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7186 - accuracy: 0.6786\n",
      "Epoch 50/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7302 - accuracy: 0.6669\n",
      "Epoch 51/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7091 - accuracy: 0.6929\n",
      "Epoch 52/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7245 - accuracy: 0.6767\n",
      "Epoch 53/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7340 - accuracy: 0.6762\n",
      "Epoch 54/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7328 - accuracy: 0.6782\n",
      "Epoch 55/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7177 - accuracy: 0.6901\n",
      "Epoch 56/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7211 - accuracy: 0.6934\n",
      "Epoch 57/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7302 - accuracy: 0.6808\n",
      "Epoch 58/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7182 - accuracy: 0.6803\n",
      "Epoch 59/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7135 - accuracy: 0.6897\n",
      "Epoch 60/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7330 - accuracy: 0.6827\n",
      "Epoch 61/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7114 - accuracy: 0.6868\n",
      "Epoch 62/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7211 - accuracy: 0.6845\n",
      "Epoch 63/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7304 - accuracy: 0.6797\n",
      "Epoch 64/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7213 - accuracy: 0.6845\n",
      "Epoch 65/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7342 - accuracy: 0.6840\n",
      "Epoch 66/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7116 - accuracy: 0.6935\n",
      "Epoch 67/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7179 - accuracy: 0.6873\n",
      "Epoch 68/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7312 - accuracy: 0.6766\n",
      "Epoch 69/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7297 - accuracy: 0.6745\n",
      "Epoch 70/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7157 - accuracy: 0.6812\n",
      "Epoch 71/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7128 - accuracy: 0.6979\n",
      "Epoch 72/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7202 - accuracy: 0.6878\n",
      "Epoch 73/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7160 - accuracy: 0.6877\n",
      "Epoch 74/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7033 - accuracy: 0.6896\n",
      "Epoch 75/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7077 - accuracy: 0.6953\n",
      "Epoch 76/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7120 - accuracy: 0.6950\n",
      "Epoch 77/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7239 - accuracy: 0.6890\n",
      "Epoch 78/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6986 - accuracy: 0.6985\n",
      "Epoch 79/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7265 - accuracy: 0.6762\n",
      "Epoch 80/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7394 - accuracy: 0.6768\n",
      "Epoch 81/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7282 - accuracy: 0.6848\n",
      "Epoch 82/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7348 - accuracy: 0.6753\n",
      "Epoch 83/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7229 - accuracy: 0.6883\n",
      "Epoch 84/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7370 - accuracy: 0.6853\n",
      "Epoch 85/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7267 - accuracy: 0.6826\n",
      "Epoch 86/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7256 - accuracy: 0.6837\n",
      "Epoch 87/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7073 - accuracy: 0.7069\n",
      "Epoch 88/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7089 - accuracy: 0.6948\n",
      "Epoch 89/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7127 - accuracy: 0.6910\n",
      "Epoch 90/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7134 - accuracy: 0.6818\n",
      "Epoch 91/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7115 - accuracy: 0.6868\n",
      "Epoch 92/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7102 - accuracy: 0.6916\n",
      "Epoch 93/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7171 - accuracy: 0.6865\n",
      "Epoch 94/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7118 - accuracy: 0.6883\n",
      "Epoch 95/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7226 - accuracy: 0.6904\n",
      "Epoch 96/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7251 - accuracy: 0.6869\n",
      "Epoch 97/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7242 - accuracy: 0.6809\n",
      "Epoch 98/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7329 - accuracy: 0.6814\n",
      "Epoch 99/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7321 - accuracy: 0.6828\n",
      "Epoch 100/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7215 - accuracy: 0.6843\n",
      "Epoch 101/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7053 - accuracy: 0.6890\n",
      "Epoch 102/200\n",
      "252/252 [==============================] - 0s 999us/step - loss: 0.7230 - accuracy: 0.6807\n",
      "Epoch 103/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7078 - accuracy: 0.6914\n",
      "Epoch 104/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7046 - accuracy: 0.6905\n",
      "Epoch 105/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7191 - accuracy: 0.6813\n",
      "Epoch 106/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7236 - accuracy: 0.6875\n",
      "Epoch 107/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7303 - accuracy: 0.6838\n",
      "Epoch 108/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7158 - accuracy: 0.6883\n",
      "Epoch 109/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7157 - accuracy: 0.6857\n",
      "Epoch 110/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7183 - accuracy: 0.6955\n",
      "Epoch 111/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7112 - accuracy: 0.6941\n",
      "Epoch 112/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7056 - accuracy: 0.6922\n",
      "Epoch 113/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7108 - accuracy: 0.6910\n",
      "Epoch 114/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7010 - accuracy: 0.6975\n",
      "Epoch 115/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7037 - accuracy: 0.6933\n",
      "Epoch 116/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7041 - accuracy: 0.7027\n",
      "Epoch 117/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7186 - accuracy: 0.6879\n",
      "Epoch 118/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7463 - accuracy: 0.6776\n",
      "Epoch 119/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7274 - accuracy: 0.6899\n",
      "Epoch 120/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7258 - accuracy: 0.6878\n",
      "Epoch 121/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7236 - accuracy: 0.6889\n",
      "Epoch 122/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7197 - accuracy: 0.6858\n",
      "Epoch 123/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7062 - accuracy: 0.6942\n",
      "Epoch 124/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7221 - accuracy: 0.6935\n",
      "Epoch 125/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.6900\n",
      "Epoch 126/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7156 - accuracy: 0.6901\n",
      "Epoch 127/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7090 - accuracy: 0.6982\n",
      "Epoch 128/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7038 - accuracy: 0.7001\n",
      "Epoch 129/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7127 - accuracy: 0.6874\n",
      "Epoch 130/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7268 - accuracy: 0.6876\n",
      "Epoch 131/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7162 - accuracy: 0.6850\n",
      "Epoch 132/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7312 - accuracy: 0.6852\n",
      "Epoch 133/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7287 - accuracy: 0.6873\n",
      "Epoch 134/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6962 - accuracy: 0.6939\n",
      "Epoch 135/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7143 - accuracy: 0.6934\n",
      "Epoch 136/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7275 - accuracy: 0.6821\n",
      "Epoch 137/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7175 - accuracy: 0.6908\n",
      "Epoch 138/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7037 - accuracy: 0.7064\n",
      "Epoch 139/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7147 - accuracy: 0.6878\n",
      "Epoch 140/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.6877\n",
      "Epoch 141/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7187 - accuracy: 0.6866\n",
      "Epoch 142/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7044 - accuracy: 0.6858\n",
      "Epoch 143/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6984 - accuracy: 0.6929\n",
      "Epoch 144/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.6917\n",
      "Epoch 145/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.6992\n",
      "Epoch 146/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7062 - accuracy: 0.7019\n",
      "Epoch 147/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7278 - accuracy: 0.6823\n",
      "Epoch 148/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.6975\n",
      "Epoch 149/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7196 - accuracy: 0.6838\n",
      "Epoch 150/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7162 - accuracy: 0.6920\n",
      "Epoch 151/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7055 - accuracy: 0.6900\n",
      "Epoch 152/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7196 - accuracy: 0.6877\n",
      "Epoch 153/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7275 - accuracy: 0.6885\n",
      "Epoch 154/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7236 - accuracy: 0.6986\n",
      "Epoch 155/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7064 - accuracy: 0.6912\n",
      "Epoch 156/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7131 - accuracy: 0.6856\n",
      "Epoch 157/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7117 - accuracy: 0.6959\n",
      "Epoch 158/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7126 - accuracy: 0.6907\n",
      "Epoch 159/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7140 - accuracy: 0.6996\n",
      "Epoch 160/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7018 - accuracy: 0.6959\n",
      "Epoch 161/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7221 - accuracy: 0.6848\n",
      "Epoch 162/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7050 - accuracy: 0.6979\n",
      "Epoch 163/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7061 - accuracy: 0.7065\n",
      "Epoch 164/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7232 - accuracy: 0.6874\n",
      "Epoch 165/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6965 - accuracy: 0.6970\n",
      "Epoch 166/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7121 - accuracy: 0.6842\n",
      "Epoch 167/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7178 - accuracy: 0.6871\n",
      "Epoch 168/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7073 - accuracy: 0.6872\n",
      "Epoch 169/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7108 - accuracy: 0.6899\n",
      "Epoch 170/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7242 - accuracy: 0.6844\n",
      "Epoch 171/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7184 - accuracy: 0.6956\n",
      "Epoch 172/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7352 - accuracy: 0.6825\n",
      "Epoch 173/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7189 - accuracy: 0.6840\n",
      "Epoch 174/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7089 - accuracy: 0.6929\n",
      "Epoch 175/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.6936\n",
      "Epoch 176/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7165 - accuracy: 0.6885\n",
      "Epoch 177/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7026 - accuracy: 0.6992\n",
      "Epoch 178/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7248 - accuracy: 0.6853\n",
      "Epoch 179/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7151 - accuracy: 0.6949\n",
      "Epoch 180/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7148 - accuracy: 0.6921\n",
      "Epoch 181/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7089 - accuracy: 0.6907\n",
      "Epoch 182/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7153 - accuracy: 0.6904\n",
      "Epoch 183/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7017 - accuracy: 0.6901\n",
      "Epoch 184/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7198 - accuracy: 0.6753\n",
      "Epoch 185/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7013 - accuracy: 0.6940\n",
      "Epoch 186/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7063 - accuracy: 0.6935\n",
      "Epoch 187/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7006 - accuracy: 0.7074\n",
      "Epoch 188/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7333 - accuracy: 0.6824\n",
      "Epoch 189/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7144 - accuracy: 0.7006\n",
      "Epoch 190/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7193 - accuracy: 0.6988\n",
      "Epoch 191/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.6931\n",
      "Epoch 192/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7134 - accuracy: 0.6878\n",
      "Epoch 193/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7204 - accuracy: 0.6844\n",
      "Epoch 194/200\n",
      "252/252 [==============================] - 0s 997us/step - loss: 0.7062 - accuracy: 0.6900\n",
      "Epoch 195/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7096 - accuracy: 0.6915\n",
      "Epoch 196/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7148 - accuracy: 0.6914\n",
      "Epoch 197/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7104 - accuracy: 0.6934\n",
      "Epoch 198/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7147 - accuracy: 0.7005\n",
      "Epoch 199/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7045 - accuracy: 0.6969\n",
      "Epoch 200/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7071 - accuracy: 0.6925\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 790us/step - loss: 0.7766 - accuracy: 0.6455\n",
      "Acc:\n",
      "0.6454734206199646\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Acc:')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_237\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_722 (Dense)            (None, 24)                456       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_723 (Dense)            (None, 14)                350       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_724 (Dense)            (None, 8)                 120       \n",
      "_________________________________________________________________\n",
      "dense_725 (Dense)            (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 953\n",
      "Trainable params: 953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(24, kernel_initializer='normal', activation='relu', input_shape=(18,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "252/252 [==============================] - 1s 1ms/step - loss: 1.0353 - accuracy: 0.4518\n",
      "Epoch 2/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.8544 - accuracy: 0.6482\n",
      "Epoch 3/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7750 - accuracy: 0.6501\n",
      "Epoch 4/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7607 - accuracy: 0.6577\n",
      "Epoch 5/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7619 - accuracy: 0.6571\n",
      "Epoch 6/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7470 - accuracy: 0.6588\n",
      "Epoch 7/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7475 - accuracy: 0.6559\n",
      "Epoch 8/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7505 - accuracy: 0.6579\n",
      "Epoch 9/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7597 - accuracy: 0.6505\n",
      "Epoch 10/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7463 - accuracy: 0.6690\n",
      "Epoch 11/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7493 - accuracy: 0.6547\n",
      "Epoch 12/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7484 - accuracy: 0.6604\n",
      "Epoch 13/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7440 - accuracy: 0.6700\n",
      "Epoch 14/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7334 - accuracy: 0.6718\n",
      "Epoch 15/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7365 - accuracy: 0.6698\n",
      "Epoch 16/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7361 - accuracy: 0.6650\n",
      "Epoch 17/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7475 - accuracy: 0.6654\n",
      "Epoch 18/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7380 - accuracy: 0.6732\n",
      "Epoch 19/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7249 - accuracy: 0.6771\n",
      "Epoch 20/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7240 - accuracy: 0.6799\n",
      "Epoch 21/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7411 - accuracy: 0.6587\n",
      "Epoch 22/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7495 - accuracy: 0.6706\n",
      "Epoch 23/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7396 - accuracy: 0.6700\n",
      "Epoch 24/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7333 - accuracy: 0.6643\n",
      "Epoch 25/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7406 - accuracy: 0.6660\n",
      "Epoch 26/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7459 - accuracy: 0.6600\n",
      "Epoch 27/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7246 - accuracy: 0.6721\n",
      "Epoch 28/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7449 - accuracy: 0.6625\n",
      "Epoch 29/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7321 - accuracy: 0.6805\n",
      "Epoch 30/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7310 - accuracy: 0.6719\n",
      "Epoch 31/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7327 - accuracy: 0.6741\n",
      "Epoch 32/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7336 - accuracy: 0.6701\n",
      "Epoch 33/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7371 - accuracy: 0.6741\n",
      "Epoch 34/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7236 - accuracy: 0.6825\n",
      "Epoch 35/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7131 - accuracy: 0.6798\n",
      "Epoch 36/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7136 - accuracy: 0.6871\n",
      "Epoch 37/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7223 - accuracy: 0.6836\n",
      "Epoch 38/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7148 - accuracy: 0.6851\n",
      "Epoch 39/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7309 - accuracy: 0.6755\n",
      "Epoch 40/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7285 - accuracy: 0.6714\n",
      "Epoch 41/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7354 - accuracy: 0.6763\n",
      "Epoch 42/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7224 - accuracy: 0.6774\n",
      "Epoch 43/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7125 - accuracy: 0.6786\n",
      "Epoch 44/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7191 - accuracy: 0.6791\n",
      "Epoch 45/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7120 - accuracy: 0.6884\n",
      "Epoch 46/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7094 - accuracy: 0.6895\n",
      "Epoch 47/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7343 - accuracy: 0.6709\n",
      "Epoch 48/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7094 - accuracy: 0.6875\n",
      "Epoch 49/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7333 - accuracy: 0.6711\n",
      "Epoch 50/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7251 - accuracy: 0.6768\n",
      "Epoch 51/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.6760\n",
      "Epoch 52/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7186 - accuracy: 0.6835\n",
      "Epoch 53/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7515 - accuracy: 0.6582\n",
      "Epoch 54/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7316 - accuracy: 0.6718\n",
      "Epoch 55/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7164 - accuracy: 0.6798\n",
      "Epoch 56/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7339 - accuracy: 0.6653\n",
      "Epoch 57/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7155 - accuracy: 0.6824\n",
      "Epoch 58/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.6776\n",
      "Epoch 59/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7241 - accuracy: 0.6814\n",
      "Epoch 60/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6968 - accuracy: 0.7015\n",
      "Epoch 61/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7113 - accuracy: 0.6829\n",
      "Epoch 62/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7259 - accuracy: 0.6823\n",
      "Epoch 63/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7096 - accuracy: 0.6901\n",
      "Epoch 64/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7244 - accuracy: 0.6888\n",
      "Epoch 65/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7189 - accuracy: 0.6827\n",
      "Epoch 66/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7157 - accuracy: 0.6892\n",
      "Epoch 67/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7243 - accuracy: 0.6824\n",
      "Epoch 68/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7458 - accuracy: 0.6707\n",
      "Epoch 69/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7133 - accuracy: 0.6855\n",
      "Epoch 70/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7088 - accuracy: 0.6942\n",
      "Epoch 71/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7270 - accuracy: 0.6795\n",
      "Epoch 72/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7327 - accuracy: 0.6771\n",
      "Epoch 73/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7214 - accuracy: 0.6885\n",
      "Epoch 74/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7186 - accuracy: 0.6752\n",
      "Epoch 75/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7212 - accuracy: 0.6889\n",
      "Epoch 76/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7148 - accuracy: 0.6891\n",
      "Epoch 77/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7114 - accuracy: 0.6934\n",
      "Epoch 78/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7176 - accuracy: 0.6846\n",
      "Epoch 79/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7048 - accuracy: 0.6860\n",
      "Epoch 80/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7140 - accuracy: 0.6865\n",
      "Epoch 81/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7297 - accuracy: 0.6786\n",
      "Epoch 82/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7094 - accuracy: 0.6884\n",
      "Epoch 83/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7192 - accuracy: 0.6816\n",
      "Epoch 84/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7255 - accuracy: 0.6826\n",
      "Epoch 85/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7265 - accuracy: 0.6835\n",
      "Epoch 86/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6968 - accuracy: 0.6933\n",
      "Epoch 87/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7249 - accuracy: 0.6865\n",
      "Epoch 88/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7183 - accuracy: 0.6884\n",
      "Epoch 89/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7027 - accuracy: 0.6828\n",
      "Epoch 90/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7100 - accuracy: 0.7025\n",
      "Epoch 91/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7134 - accuracy: 0.6944\n",
      "Epoch 92/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7323 - accuracy: 0.6869\n",
      "Epoch 93/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7128 - accuracy: 0.6969\n",
      "Epoch 94/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7264 - accuracy: 0.6866\n",
      "Epoch 95/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7164 - accuracy: 0.6867\n",
      "Epoch 96/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7220 - accuracy: 0.6898\n",
      "Epoch 97/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7185 - accuracy: 0.6851\n",
      "Epoch 98/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7269 - accuracy: 0.6860\n",
      "Epoch 99/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7123 - accuracy: 0.6871\n",
      "Epoch 100/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7195 - accuracy: 0.6880\n",
      "Epoch 101/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7066 - accuracy: 0.6901\n",
      "Epoch 102/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7242 - accuracy: 0.6811\n",
      "Epoch 103/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7268 - accuracy: 0.6778\n",
      "Epoch 104/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6984 - accuracy: 0.6975\n",
      "Epoch 105/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7142 - accuracy: 0.6871\n",
      "Epoch 106/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7015 - accuracy: 0.6972\n",
      "Epoch 107/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7062 - accuracy: 0.6918\n",
      "Epoch 108/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7225 - accuracy: 0.6889\n",
      "Epoch 109/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7022 - accuracy: 0.6947\n",
      "Epoch 110/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.7046\n",
      "Epoch 111/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7225 - accuracy: 0.6860\n",
      "Epoch 112/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7215 - accuracy: 0.6852\n",
      "Epoch 113/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7052 - accuracy: 0.6853\n",
      "Epoch 114/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7172 - accuracy: 0.6842\n",
      "Epoch 115/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7166 - accuracy: 0.6903\n",
      "Epoch 116/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.6941\n",
      "Epoch 117/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7055 - accuracy: 0.7018\n",
      "Epoch 118/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7263 - accuracy: 0.6851\n",
      "Epoch 119/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.7103\n",
      "Epoch 120/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6985 - accuracy: 0.6996\n",
      "Epoch 121/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7188 - accuracy: 0.6878\n",
      "Epoch 122/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7150 - accuracy: 0.6899\n",
      "Epoch 123/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7120 - accuracy: 0.6892\n",
      "Epoch 124/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7289 - accuracy: 0.6854\n",
      "Epoch 125/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7135 - accuracy: 0.6918\n",
      "Epoch 126/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7109 - accuracy: 0.6994\n",
      "Epoch 127/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6994 - accuracy: 0.6968\n",
      "Epoch 128/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7196 - accuracy: 0.6810\n",
      "Epoch 129/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7148 - accuracy: 0.6979\n",
      "Epoch 130/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7197 - accuracy: 0.6914\n",
      "Epoch 131/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7122 - accuracy: 0.6948\n",
      "Epoch 132/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6954 - accuracy: 0.7007\n",
      "Epoch 133/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.6935\n",
      "Epoch 134/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7066 - accuracy: 0.6858\n",
      "Epoch 135/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7338 - accuracy: 0.6871\n",
      "Epoch 136/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7064 - accuracy: 0.6936\n",
      "Epoch 137/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7324 - accuracy: 0.6876\n",
      "Epoch 138/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7166 - accuracy: 0.6918\n",
      "Epoch 139/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7019 - accuracy: 0.6987\n",
      "Epoch 140/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7348 - accuracy: 0.6868\n",
      "Epoch 141/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7065 - accuracy: 0.6927\n",
      "Epoch 142/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6976 - accuracy: 0.7012\n",
      "Epoch 143/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7195 - accuracy: 0.6894\n",
      "Epoch 144/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7182 - accuracy: 0.6921\n",
      "Epoch 145/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7245 - accuracy: 0.6949\n",
      "Epoch 146/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7055 - accuracy: 0.7018\n",
      "Epoch 147/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7312 - accuracy: 0.6806\n",
      "Epoch 148/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7126 - accuracy: 0.6971\n",
      "Epoch 149/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7018 - accuracy: 0.6877\n",
      "Epoch 150/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7246 - accuracy: 0.6966\n",
      "Epoch 151/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7025 - accuracy: 0.6952\n",
      "Epoch 152/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7184 - accuracy: 0.6934\n",
      "Epoch 153/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7144 - accuracy: 0.6876\n",
      "Epoch 154/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6992 - accuracy: 0.6946\n",
      "Epoch 155/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7021 - accuracy: 0.6982\n",
      "Epoch 156/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7085 - accuracy: 0.7021\n",
      "Epoch 157/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7128 - accuracy: 0.6912\n",
      "Epoch 158/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7138 - accuracy: 0.6911\n",
      "Epoch 159/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7234 - accuracy: 0.6885\n",
      "Epoch 160/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7016 - accuracy: 0.7043\n",
      "Epoch 161/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7031 - accuracy: 0.6959\n",
      "Epoch 162/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6956 - accuracy: 0.7027\n",
      "Epoch 163/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7053 - accuracy: 0.6965\n",
      "Epoch 164/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7054 - accuracy: 0.6985\n",
      "Epoch 165/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.6970\n",
      "Epoch 166/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7152 - accuracy: 0.6930\n",
      "Epoch 167/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7041 - accuracy: 0.7018\n",
      "Epoch 168/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7124 - accuracy: 0.6981\n",
      "Epoch 169/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7168 - accuracy: 0.6945\n",
      "Epoch 170/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7130 - accuracy: 0.6922\n",
      "Epoch 171/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7228 - accuracy: 0.6927\n",
      "Epoch 172/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7089 - accuracy: 0.6917\n",
      "Epoch 173/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6997 - accuracy: 0.7051\n",
      "Epoch 174/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6980 - accuracy: 0.7026\n",
      "Epoch 175/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7142 - accuracy: 0.6923\n",
      "Epoch 176/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.6997\n",
      "Epoch 177/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7204 - accuracy: 0.6860\n",
      "Epoch 178/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.7046\n",
      "Epoch 179/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.7042\n",
      "Epoch 180/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7122 - accuracy: 0.6986\n",
      "Epoch 181/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7144 - accuracy: 0.6893\n",
      "Epoch 182/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7030 - accuracy: 0.7020\n",
      "Epoch 183/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7076 - accuracy: 0.7055\n",
      "Epoch 184/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7162 - accuracy: 0.6919\n",
      "Epoch 185/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.7085\n",
      "Epoch 186/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7184 - accuracy: 0.6947\n",
      "Epoch 187/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7101 - accuracy: 0.6869\n",
      "Epoch 188/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7088 - accuracy: 0.6938\n",
      "Epoch 189/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.7143\n",
      "Epoch 190/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.7064\n",
      "Epoch 191/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7299 - accuracy: 0.6831\n",
      "Epoch 192/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7057 - accuracy: 0.7003\n",
      "Epoch 193/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7131 - accuracy: 0.6906\n",
      "Epoch 194/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6957 - accuracy: 0.7094\n",
      "Epoch 195/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7148 - accuracy: 0.6942\n",
      "Epoch 196/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7150 - accuracy: 0.6937\n",
      "Epoch 197/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6992 - accuracy: 0.7020\n",
      "Epoch 198/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7050 - accuracy: 0.6953\n",
      "Epoch 199/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7224 - accuracy: 0.6959\n",
      "Epoch 200/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7088 - accuracy: 0.7100\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 980us/step - loss: 0.7842 - accuracy: 0.6323\n",
      "Acc:\n",
      "0.6323427557945251\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Acc:')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_238\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_726 (Dense)            (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_727 (Dense)            (None, 14)                266       \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_728 (Dense)            (None, 8)                 120       \n",
      "_________________________________________________________________\n",
      "dense_729 (Dense)            (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_730 (Dense)            (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 803\n",
      "Trainable params: 803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(18, kernel_initializer='normal', activation='relu', input_shape=(18,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "252/252 [==============================] - 1s 1ms/step - loss: 1.0892 - accuracy: 0.4568\n",
      "Epoch 2/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 1.0658 - accuracy: 0.4644\n",
      "Epoch 3/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.9151 - accuracy: 0.6327\n",
      "Epoch 4/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7748 - accuracy: 0.6620\n",
      "Epoch 5/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7783 - accuracy: 0.6425\n",
      "Epoch 6/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7649 - accuracy: 0.6475\n",
      "Epoch 7/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7694 - accuracy: 0.6562\n",
      "Epoch 8/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7443 - accuracy: 0.6667\n",
      "Epoch 9/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7678 - accuracy: 0.6484\n",
      "Epoch 10/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7362 - accuracy: 0.6705\n",
      "Epoch 11/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7390 - accuracy: 0.6621\n",
      "Epoch 12/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7412 - accuracy: 0.6663\n",
      "Epoch 13/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7343 - accuracy: 0.6630\n",
      "Epoch 14/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7295 - accuracy: 0.6614\n",
      "Epoch 15/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7430 - accuracy: 0.6695\n",
      "Epoch 16/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7414 - accuracy: 0.6688\n",
      "Epoch 17/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7304 - accuracy: 0.6798\n",
      "Epoch 18/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7512 - accuracy: 0.6714\n",
      "Epoch 19/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7572 - accuracy: 0.6527\n",
      "Epoch 20/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7402 - accuracy: 0.6667\n",
      "Epoch 21/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7399 - accuracy: 0.6675\n",
      "Epoch 22/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7364 - accuracy: 0.6654\n",
      "Epoch 23/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7579 - accuracy: 0.6550\n",
      "Epoch 24/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7214 - accuracy: 0.6814\n",
      "Epoch 25/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7396 - accuracy: 0.6722\n",
      "Epoch 26/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7320 - accuracy: 0.6697\n",
      "Epoch 27/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7404 - accuracy: 0.6591\n",
      "Epoch 28/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7507 - accuracy: 0.6641\n",
      "Epoch 29/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7251 - accuracy: 0.6611\n",
      "Epoch 30/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7270 - accuracy: 0.6702\n",
      "Epoch 31/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7323 - accuracy: 0.6783\n",
      "Epoch 32/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7270 - accuracy: 0.6754\n",
      "Epoch 33/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7269 - accuracy: 0.6692\n",
      "Epoch 34/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7247 - accuracy: 0.6754\n",
      "Epoch 35/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7358 - accuracy: 0.6699\n",
      "Epoch 36/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7173 - accuracy: 0.6726\n",
      "Epoch 37/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7292 - accuracy: 0.6727\n",
      "Epoch 38/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7057 - accuracy: 0.6824\n",
      "Epoch 39/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7272 - accuracy: 0.6602\n",
      "Epoch 40/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7239 - accuracy: 0.6732\n",
      "Epoch 41/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7277 - accuracy: 0.6629\n",
      "Epoch 42/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7342 - accuracy: 0.6639\n",
      "Epoch 43/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7251 - accuracy: 0.6724\n",
      "Epoch 44/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7364 - accuracy: 0.6741\n",
      "Epoch 45/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7409 - accuracy: 0.6679\n",
      "Epoch 46/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7206 - accuracy: 0.6754\n",
      "Epoch 47/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7257 - accuracy: 0.6738\n",
      "Epoch 48/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7315 - accuracy: 0.6735\n",
      "Epoch 49/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7367 - accuracy: 0.6623\n",
      "Epoch 50/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7395 - accuracy: 0.6708\n",
      "Epoch 51/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7257 - accuracy: 0.6717\n",
      "Epoch 52/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7424 - accuracy: 0.6732\n",
      "Epoch 53/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7193 - accuracy: 0.6762\n",
      "Epoch 54/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7319 - accuracy: 0.6719\n",
      "Epoch 55/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7260 - accuracy: 0.6700\n",
      "Epoch 56/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7202 - accuracy: 0.6625\n",
      "Epoch 57/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7103 - accuracy: 0.6806\n",
      "Epoch 58/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7239 - accuracy: 0.6686\n",
      "Epoch 59/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7281 - accuracy: 0.6708\n",
      "Epoch 60/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7143 - accuracy: 0.6781\n",
      "Epoch 61/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7241 - accuracy: 0.6769\n",
      "Epoch 62/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7231 - accuracy: 0.6790\n",
      "Epoch 63/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7305 - accuracy: 0.6729\n",
      "Epoch 64/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7072 - accuracy: 0.6822\n",
      "Epoch 65/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7390 - accuracy: 0.6700\n",
      "Epoch 66/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7227 - accuracy: 0.6725\n",
      "Epoch 67/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7349 - accuracy: 0.6718\n",
      "Epoch 68/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7059 - accuracy: 0.6808\n",
      "Epoch 69/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7158 - accuracy: 0.6821\n",
      "Epoch 70/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7192 - accuracy: 0.6772\n",
      "Epoch 71/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7164 - accuracy: 0.6802\n",
      "Epoch 72/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7332 - accuracy: 0.6676\n",
      "Epoch 73/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7265 - accuracy: 0.6755\n",
      "Epoch 74/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7041 - accuracy: 0.6956\n",
      "Epoch 75/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7285 - accuracy: 0.6725\n",
      "Epoch 76/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7337 - accuracy: 0.6673\n",
      "Epoch 77/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7127 - accuracy: 0.6793\n",
      "Epoch 78/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7155 - accuracy: 0.6804\n",
      "Epoch 79/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7255 - accuracy: 0.6640\n",
      "Epoch 80/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7168 - accuracy: 0.6778\n",
      "Epoch 81/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7152 - accuracy: 0.6817\n",
      "Epoch 82/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7184 - accuracy: 0.6767\n",
      "Epoch 83/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7248 - accuracy: 0.6752\n",
      "Epoch 84/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7409 - accuracy: 0.6661\n",
      "Epoch 85/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7362 - accuracy: 0.6685\n",
      "Epoch 86/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7195 - accuracy: 0.6877\n",
      "Epoch 87/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7094 - accuracy: 0.6782\n",
      "Epoch 88/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.6788\n",
      "Epoch 89/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7149 - accuracy: 0.6855\n",
      "Epoch 90/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7137 - accuracy: 0.6755\n",
      "Epoch 91/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7241 - accuracy: 0.6768\n",
      "Epoch 92/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7209 - accuracy: 0.6731\n",
      "Epoch 93/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7160 - accuracy: 0.6778\n",
      "Epoch 94/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7057 - accuracy: 0.6806\n",
      "Epoch 95/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.6718\n",
      "Epoch 96/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7113 - accuracy: 0.6750\n",
      "Epoch 97/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7247 - accuracy: 0.6857\n",
      "Epoch 98/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7189 - accuracy: 0.6818\n",
      "Epoch 99/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7411 - accuracy: 0.6689\n",
      "Epoch 100/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7122 - accuracy: 0.6775\n",
      "Epoch 101/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7252 - accuracy: 0.6773\n",
      "Epoch 102/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.6921\n",
      "Epoch 103/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7113 - accuracy: 0.6705\n",
      "Epoch 104/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7209 - accuracy: 0.6795\n",
      "Epoch 105/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7158 - accuracy: 0.6733\n",
      "Epoch 106/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7127 - accuracy: 0.6729\n",
      "Epoch 107/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7235 - accuracy: 0.6753\n",
      "Epoch 108/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7158 - accuracy: 0.6895\n",
      "Epoch 109/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7253 - accuracy: 0.6741\n",
      "Epoch 110/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7217 - accuracy: 0.6741\n",
      "Epoch 111/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7216 - accuracy: 0.6692\n",
      "Epoch 112/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7086 - accuracy: 0.6879\n",
      "Epoch 113/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7187 - accuracy: 0.6745\n",
      "Epoch 114/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7156 - accuracy: 0.6866\n",
      "Epoch 115/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7282 - accuracy: 0.6677\n",
      "Epoch 116/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7210 - accuracy: 0.6852\n",
      "Epoch 117/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7283 - accuracy: 0.6770\n",
      "Epoch 118/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7109 - accuracy: 0.6786\n",
      "Epoch 119/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7202 - accuracy: 0.6782\n",
      "Epoch 120/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7130 - accuracy: 0.6816\n",
      "Epoch 121/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7175 - accuracy: 0.6769\n",
      "Epoch 122/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7153 - accuracy: 0.6722\n",
      "Epoch 123/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7092 - accuracy: 0.6871\n",
      "Epoch 124/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6993 - accuracy: 0.6854\n",
      "Epoch 125/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7196 - accuracy: 0.6852\n",
      "Epoch 126/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7163 - accuracy: 0.6771\n",
      "Epoch 127/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7106 - accuracy: 0.6854\n",
      "Epoch 128/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6970 - accuracy: 0.6956\n",
      "Epoch 129/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7226 - accuracy: 0.6788\n",
      "Epoch 130/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7226 - accuracy: 0.6736\n",
      "Epoch 131/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7070 - accuracy: 0.6829\n",
      "Epoch 132/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7201 - accuracy: 0.6796\n",
      "Epoch 133/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.6928\n",
      "Epoch 134/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7195 - accuracy: 0.6807\n",
      "Epoch 135/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7247 - accuracy: 0.6680\n",
      "Epoch 136/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7199 - accuracy: 0.6871\n",
      "Epoch 137/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7084 - accuracy: 0.6854\n",
      "Epoch 138/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7283 - accuracy: 0.6734\n",
      "Epoch 139/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7047 - accuracy: 0.6843\n",
      "Epoch 140/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7170 - accuracy: 0.6813\n",
      "Epoch 141/200\n",
      "252/252 [==============================] - 0s 2ms/step - loss: 0.7156 - accuracy: 0.6618\n",
      "Epoch 142/200\n",
      "252/252 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.6894\n",
      "Epoch 143/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7175 - accuracy: 0.6732\n",
      "Epoch 144/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7231 - accuracy: 0.6771\n",
      "Epoch 145/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7245 - accuracy: 0.6838\n",
      "Epoch 146/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.6943\n",
      "Epoch 147/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7107 - accuracy: 0.6854\n",
      "Epoch 148/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7191 - accuracy: 0.6872\n",
      "Epoch 149/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7126 - accuracy: 0.6833\n",
      "Epoch 150/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6966 - accuracy: 0.6840\n",
      "Epoch 151/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7201 - accuracy: 0.6788\n",
      "Epoch 152/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7029 - accuracy: 0.6866\n",
      "Epoch 153/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6998 - accuracy: 0.6907\n",
      "Epoch 154/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7028 - accuracy: 0.6878\n",
      "Epoch 155/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7178 - accuracy: 0.6789\n",
      "Epoch 156/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7280 - accuracy: 0.6627\n",
      "Epoch 157/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7186 - accuracy: 0.6861\n",
      "Epoch 158/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7104 - accuracy: 0.6933\n",
      "Epoch 159/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6985 - accuracy: 0.6927\n",
      "Epoch 160/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7260 - accuracy: 0.6863\n",
      "Epoch 161/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7253 - accuracy: 0.6727\n",
      "Epoch 162/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7247 - accuracy: 0.6752\n",
      "Epoch 163/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7130 - accuracy: 0.6889\n",
      "Epoch 164/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7086 - accuracy: 0.6829\n",
      "Epoch 165/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7063 - accuracy: 0.6947\n",
      "Epoch 166/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7067 - accuracy: 0.6946\n",
      "Epoch 167/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7287 - accuracy: 0.6837\n",
      "Epoch 168/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7111 - accuracy: 0.6878\n",
      "Epoch 169/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7188 - accuracy: 0.6836\n",
      "Epoch 170/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7074 - accuracy: 0.6897\n",
      "Epoch 171/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7338 - accuracy: 0.6768\n",
      "Epoch 172/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6995 - accuracy: 0.6850\n",
      "Epoch 173/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7059 - accuracy: 0.6812\n",
      "Epoch 174/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7263 - accuracy: 0.6678\n",
      "Epoch 175/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7191 - accuracy: 0.6804\n",
      "Epoch 176/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7240 - accuracy: 0.6766\n",
      "Epoch 177/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7029 - accuracy: 0.6744\n",
      "Epoch 178/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7165 - accuracy: 0.6740\n",
      "Epoch 179/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7236 - accuracy: 0.6696\n",
      "Epoch 180/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7161 - accuracy: 0.6778\n",
      "Epoch 181/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7033 - accuracy: 0.6944\n",
      "Epoch 182/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7327 - accuracy: 0.6739\n",
      "Epoch 183/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7019 - accuracy: 0.6823\n",
      "Epoch 184/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7180 - accuracy: 0.6832\n",
      "Epoch 185/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7112 - accuracy: 0.6793\n",
      "Epoch 186/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7225 - accuracy: 0.6805\n",
      "Epoch 187/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7051 - accuracy: 0.6846\n",
      "Epoch 188/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7473 - accuracy: 0.6662\n",
      "Epoch 189/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7167 - accuracy: 0.6826\n",
      "Epoch 190/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7087 - accuracy: 0.6891\n",
      "Epoch 191/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7133 - accuracy: 0.6816\n",
      "Epoch 192/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7418 - accuracy: 0.6684\n",
      "Epoch 193/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7063 - accuracy: 0.6764\n",
      "Epoch 194/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7294 - accuracy: 0.6680\n",
      "Epoch 195/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.6944\n",
      "Epoch 196/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7247 - accuracy: 0.6844\n",
      "Epoch 197/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.6949\n",
      "Epoch 198/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7035 - accuracy: 0.6869\n",
      "Epoch 199/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7155 - accuracy: 0.6762\n",
      "Epoch 200/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7145 - accuracy: 0.6810\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step - loss: 0.7915 - accuracy: 0.6213\n",
      "Acc:\n",
      "0.6212854385375977\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Acc:')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_239\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_731 (Dense)            (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_732 (Dense)            (None, 14)                266       \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_733 (Dense)            (None, 8)                 120       \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_734 (Dense)            (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_735 (Dense)            (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 803\n",
      "Trainable params: 803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(18, kernel_initializer='normal', activation='relu', input_shape=(18,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "252/252 [==============================] - 2s 1ms/step - loss: 1.0509 - accuracy: 0.4682\n",
      "Epoch 2/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.8378 - accuracy: 0.6438\n",
      "Epoch 3/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7678 - accuracy: 0.6686\n",
      "Epoch 4/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7577 - accuracy: 0.6574\n",
      "Epoch 5/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7585 - accuracy: 0.6584\n",
      "Epoch 6/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7784 - accuracy: 0.6506\n",
      "Epoch 7/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7808 - accuracy: 0.6505\n",
      "Epoch 8/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7490 - accuracy: 0.6669\n",
      "Epoch 9/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7718 - accuracy: 0.6502\n",
      "Epoch 10/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7644 - accuracy: 0.6591\n",
      "Epoch 11/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7639 - accuracy: 0.6621\n",
      "Epoch 12/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7708 - accuracy: 0.6612\n",
      "Epoch 13/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7638 - accuracy: 0.6615\n",
      "Epoch 14/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7802 - accuracy: 0.6603\n",
      "Epoch 15/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7521 - accuracy: 0.6671\n",
      "Epoch 16/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7673 - accuracy: 0.6531\n",
      "Epoch 17/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7679 - accuracy: 0.6560\n",
      "Epoch 18/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7474 - accuracy: 0.6711\n",
      "Epoch 19/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7492 - accuracy: 0.6692\n",
      "Epoch 20/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7739 - accuracy: 0.6586\n",
      "Epoch 21/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7607 - accuracy: 0.6589\n",
      "Epoch 22/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7625 - accuracy: 0.6598\n",
      "Epoch 23/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7566 - accuracy: 0.6713\n",
      "Epoch 24/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7484 - accuracy: 0.6752\n",
      "Epoch 25/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7582 - accuracy: 0.6591\n",
      "Epoch 26/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7591 - accuracy: 0.6593\n",
      "Epoch 27/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7516 - accuracy: 0.6723\n",
      "Epoch 28/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7343 - accuracy: 0.6774\n",
      "Epoch 29/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7478 - accuracy: 0.6690\n",
      "Epoch 30/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7491 - accuracy: 0.6667\n",
      "Epoch 31/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7222 - accuracy: 0.6809\n",
      "Epoch 32/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7408 - accuracy: 0.6767\n",
      "Epoch 33/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7621 - accuracy: 0.6560\n",
      "Epoch 34/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7487 - accuracy: 0.6636\n",
      "Epoch 35/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7470 - accuracy: 0.6678\n",
      "Epoch 36/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7257 - accuracy: 0.6730\n",
      "Epoch 37/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7318 - accuracy: 0.6727\n",
      "Epoch 38/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7495 - accuracy: 0.6731\n",
      "Epoch 39/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7564 - accuracy: 0.6627\n",
      "Epoch 40/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7308 - accuracy: 0.6733\n",
      "Epoch 41/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7306 - accuracy: 0.6715\n",
      "Epoch 42/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7426 - accuracy: 0.6668\n",
      "Epoch 43/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7367 - accuracy: 0.6849\n",
      "Epoch 44/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7199 - accuracy: 0.6776\n",
      "Epoch 45/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7477 - accuracy: 0.6591\n",
      "Epoch 46/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7361 - accuracy: 0.6616\n",
      "Epoch 47/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7353 - accuracy: 0.6639\n",
      "Epoch 48/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7369 - accuracy: 0.6697\n",
      "Epoch 49/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7258 - accuracy: 0.6758\n",
      "Epoch 50/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7329 - accuracy: 0.6690\n",
      "Epoch 51/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7395 - accuracy: 0.6686\n",
      "Epoch 52/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7553 - accuracy: 0.6693\n",
      "Epoch 53/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7530 - accuracy: 0.6555\n",
      "Epoch 54/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7415 - accuracy: 0.6586\n",
      "Epoch 55/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7488 - accuracy: 0.6630\n",
      "Epoch 56/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7369 - accuracy: 0.6752\n",
      "Epoch 57/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7279 - accuracy: 0.6682\n",
      "Epoch 58/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7477 - accuracy: 0.6752\n",
      "Epoch 59/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7291 - accuracy: 0.6711\n",
      "Epoch 60/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7586 - accuracy: 0.6549\n",
      "Epoch 61/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7522 - accuracy: 0.6799\n",
      "Epoch 62/200\n",
      "252/252 [==============================] - 0s 2ms/step - loss: 0.7464 - accuracy: 0.6627\n",
      "Epoch 63/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7439 - accuracy: 0.6618\n",
      "Epoch 64/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7282 - accuracy: 0.6768\n",
      "Epoch 65/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7270 - accuracy: 0.6820\n",
      "Epoch 66/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7416 - accuracy: 0.6651\n",
      "Epoch 67/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7440 - accuracy: 0.6639\n",
      "Epoch 68/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7248 - accuracy: 0.6658\n",
      "Epoch 69/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7255 - accuracy: 0.6830\n",
      "Epoch 70/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7255 - accuracy: 0.6830\n",
      "Epoch 71/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7445 - accuracy: 0.6666\n",
      "Epoch 72/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7259 - accuracy: 0.6842\n",
      "Epoch 73/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7449 - accuracy: 0.6660\n",
      "Epoch 74/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7359 - accuracy: 0.6757\n",
      "Epoch 75/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7336 - accuracy: 0.6692\n",
      "Epoch 76/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7408 - accuracy: 0.6704\n",
      "Epoch 77/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7333 - accuracy: 0.6735\n",
      "Epoch 78/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7268 - accuracy: 0.6812\n",
      "Epoch 79/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7329 - accuracy: 0.6769\n",
      "Epoch 80/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7456 - accuracy: 0.6722\n",
      "Epoch 81/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7219 - accuracy: 0.6740\n",
      "Epoch 82/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7460 - accuracy: 0.6612\n",
      "Epoch 83/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7378 - accuracy: 0.6749\n",
      "Epoch 84/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7387 - accuracy: 0.6778\n",
      "Epoch 85/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7288 - accuracy: 0.6629\n",
      "Epoch 86/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7338 - accuracy: 0.6731\n",
      "Epoch 87/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7314 - accuracy: 0.6713\n",
      "Epoch 88/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7295 - accuracy: 0.6804\n",
      "Epoch 89/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7336 - accuracy: 0.6700\n",
      "Epoch 90/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7257 - accuracy: 0.6715\n",
      "Epoch 91/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7339 - accuracy: 0.6628\n",
      "Epoch 92/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7464 - accuracy: 0.6655\n",
      "Epoch 93/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7223 - accuracy: 0.6718\n",
      "Epoch 94/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7178 - accuracy: 0.6728\n",
      "Epoch 95/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7189 - accuracy: 0.6815\n",
      "Epoch 96/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7465 - accuracy: 0.6665\n",
      "Epoch 97/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7325 - accuracy: 0.6719\n",
      "Epoch 98/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7350 - accuracy: 0.6687\n",
      "Epoch 99/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7290 - accuracy: 0.6703\n",
      "Epoch 100/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7427 - accuracy: 0.6583\n",
      "Epoch 101/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7231 - accuracy: 0.6717\n",
      "Epoch 102/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7447 - accuracy: 0.6592\n",
      "Epoch 103/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7179 - accuracy: 0.6679\n",
      "Epoch 104/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7299 - accuracy: 0.6766\n",
      "Epoch 105/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7133 - accuracy: 0.6822\n",
      "Epoch 106/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7290 - accuracy: 0.6719\n",
      "Epoch 107/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7364 - accuracy: 0.6717\n",
      "Epoch 108/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7122 - accuracy: 0.6752\n",
      "Epoch 109/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7378 - accuracy: 0.6705\n",
      "Epoch 110/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7340 - accuracy: 0.6790\n",
      "Epoch 111/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7392 - accuracy: 0.6717\n",
      "Epoch 112/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7173 - accuracy: 0.6880\n",
      "Epoch 113/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7229 - accuracy: 0.6805\n",
      "Epoch 114/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7377 - accuracy: 0.6624\n",
      "Epoch 115/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7345 - accuracy: 0.6735\n",
      "Epoch 116/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7296 - accuracy: 0.6794\n",
      "Epoch 117/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7336 - accuracy: 0.6700\n",
      "Epoch 118/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7359 - accuracy: 0.6688\n",
      "Epoch 119/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7127 - accuracy: 0.6889\n",
      "Epoch 120/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7025 - accuracy: 0.6908\n",
      "Epoch 121/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7358 - accuracy: 0.6722\n",
      "Epoch 122/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7227 - accuracy: 0.6789\n",
      "Epoch 123/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7468 - accuracy: 0.6711\n",
      "Epoch 124/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7324 - accuracy: 0.6756\n",
      "Epoch 125/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7377 - accuracy: 0.6720\n",
      "Epoch 126/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7396 - accuracy: 0.6721\n",
      "Epoch 127/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7336 - accuracy: 0.6768\n",
      "Epoch 128/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7319 - accuracy: 0.6706\n",
      "Epoch 129/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7333 - accuracy: 0.6702\n",
      "Epoch 130/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7424 - accuracy: 0.6721\n",
      "Epoch 131/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7457 - accuracy: 0.6586\n",
      "Epoch 132/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7365 - accuracy: 0.6689\n",
      "Epoch 133/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.6751\n",
      "Epoch 134/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7298 - accuracy: 0.6759\n",
      "Epoch 135/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7419 - accuracy: 0.6686\n",
      "Epoch 136/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7389 - accuracy: 0.6669\n",
      "Epoch 137/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7335 - accuracy: 0.6741\n",
      "Epoch 138/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7385 - accuracy: 0.6725\n",
      "Epoch 139/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7190 - accuracy: 0.6840\n",
      "Epoch 140/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7250 - accuracy: 0.6735\n",
      "Epoch 141/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7263 - accuracy: 0.6748\n",
      "Epoch 142/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7231 - accuracy: 0.6808\n",
      "Epoch 143/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7281 - accuracy: 0.6807\n",
      "Epoch 144/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7177 - accuracy: 0.6764\n",
      "Epoch 145/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7403 - accuracy: 0.6642\n",
      "Epoch 146/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7166 - accuracy: 0.6788\n",
      "Epoch 147/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7234 - accuracy: 0.6716\n",
      "Epoch 148/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7417 - accuracy: 0.6624\n",
      "Epoch 149/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7260 - accuracy: 0.6693\n",
      "Epoch 150/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7328 - accuracy: 0.6770\n",
      "Epoch 151/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7338 - accuracy: 0.6789\n",
      "Epoch 152/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7420 - accuracy: 0.6717\n",
      "Epoch 153/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7540 - accuracy: 0.6652\n",
      "Epoch 154/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7499 - accuracy: 0.6559\n",
      "Epoch 155/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7230 - accuracy: 0.6888\n",
      "Epoch 156/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7402 - accuracy: 0.6738\n",
      "Epoch 157/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7434 - accuracy: 0.6681\n",
      "Epoch 158/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7241 - accuracy: 0.6857\n",
      "Epoch 159/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7170 - accuracy: 0.6780\n",
      "Epoch 160/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7420 - accuracy: 0.6710\n",
      "Epoch 161/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7256 - accuracy: 0.6831\n",
      "Epoch 162/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7319 - accuracy: 0.6739\n",
      "Epoch 163/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7465 - accuracy: 0.6548\n",
      "Epoch 164/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7104 - accuracy: 0.6828\n",
      "Epoch 165/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7390 - accuracy: 0.6812\n",
      "Epoch 166/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7491 - accuracy: 0.6583\n",
      "Epoch 167/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7254 - accuracy: 0.6768\n",
      "Epoch 168/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7166 - accuracy: 0.6782\n",
      "Epoch 169/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7091 - accuracy: 0.6846\n",
      "Epoch 170/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7256 - accuracy: 0.6700\n",
      "Epoch 171/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7223 - accuracy: 0.6874\n",
      "Epoch 172/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7292 - accuracy: 0.6830\n",
      "Epoch 173/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7337 - accuracy: 0.6731\n",
      "Epoch 174/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7359 - accuracy: 0.6731\n",
      "Epoch 175/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7203 - accuracy: 0.6835\n",
      "Epoch 176/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7184 - accuracy: 0.6781\n",
      "Epoch 177/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7452 - accuracy: 0.6723\n",
      "Epoch 178/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7316 - accuracy: 0.6712\n",
      "Epoch 179/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7340 - accuracy: 0.6815\n",
      "Epoch 180/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7209 - accuracy: 0.6786\n",
      "Epoch 181/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7358 - accuracy: 0.6730\n",
      "Epoch 182/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7376 - accuracy: 0.6799\n",
      "Epoch 183/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7103 - accuracy: 0.6766\n",
      "Epoch 184/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7317 - accuracy: 0.6869\n",
      "Epoch 185/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7303 - accuracy: 0.6822\n",
      "Epoch 186/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7270 - accuracy: 0.6795\n",
      "Epoch 187/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7317 - accuracy: 0.6836\n",
      "Epoch 188/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7239 - accuracy: 0.6853\n",
      "Epoch 189/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7498 - accuracy: 0.6707\n",
      "Epoch 190/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7402 - accuracy: 0.6792\n",
      "Epoch 191/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7335 - accuracy: 0.6624\n",
      "Epoch 192/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7345 - accuracy: 0.6729\n",
      "Epoch 193/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7146 - accuracy: 0.6882\n",
      "Epoch 194/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7250 - accuracy: 0.6855\n",
      "Epoch 195/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7288 - accuracy: 0.6817\n",
      "Epoch 196/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7248 - accuracy: 0.6859\n",
      "Epoch 197/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7455 - accuracy: 0.6669\n",
      "Epoch 198/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7361 - accuracy: 0.6728\n",
      "Epoch 199/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7241 - accuracy: 0.6888\n",
      "Epoch 200/200\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7399 - accuracy: 0.6781\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 850us/step - loss: 0.7897 - accuracy: 0.6420\n",
      "Acc:\n",
      "0.6420179605484009\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Acc:')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, y tras ejecutar multiples veces cada opción de arquitectura, se determinó que el modelo más adecuado es el de la estructura 18/14/10/3, con dropout de 0.3 en la primera y la segunda capa. Para determinar que este fue el mejor modelo, se reviso cuidadosamente el accuracy que obtenia con el dataset de testeo, ya que de esta forma nos aseguramos que no se trate solamente de un caso de overfiting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_240\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_736 (Dense)            (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_737 (Dense)            (None, 14)                266       \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_738 (Dense)            (None, 10)                150       \n",
      "_________________________________________________________________\n",
      "dense_739 (Dense)            (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 791\n",
      "Trainable params: 791\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(18, kernel_initializer='normal', activation='relu', input_shape=(18,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "252/252 [==============================] - 1s 1ms/step - loss: 1.0361 - accuracy: 0.5093\n",
      "Epoch 2/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7838 - accuracy: 0.6473\n",
      "Epoch 3/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7613 - accuracy: 0.6444\n",
      "Epoch 4/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7373 - accuracy: 0.6656\n",
      "Epoch 5/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7538 - accuracy: 0.6618\n",
      "Epoch 6/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7491 - accuracy: 0.6607\n",
      "Epoch 7/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7589 - accuracy: 0.6577\n",
      "Epoch 8/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7522 - accuracy: 0.6574\n",
      "Epoch 9/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7639 - accuracy: 0.6480\n",
      "Epoch 10/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7455 - accuracy: 0.6630\n",
      "Epoch 11/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7460 - accuracy: 0.6702\n",
      "Epoch 12/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7475 - accuracy: 0.6625\n",
      "Epoch 13/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7369 - accuracy: 0.6611\n",
      "Epoch 14/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7317 - accuracy: 0.6700\n",
      "Epoch 15/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7506 - accuracy: 0.6658\n",
      "Epoch 16/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7449 - accuracy: 0.6734\n",
      "Epoch 17/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7543 - accuracy: 0.6597\n",
      "Epoch 18/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7328 - accuracy: 0.6761\n",
      "Epoch 19/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7472 - accuracy: 0.6644\n",
      "Epoch 20/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7356 - accuracy: 0.6727\n",
      "Epoch 21/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7387 - accuracy: 0.6725\n",
      "Epoch 22/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7393 - accuracy: 0.6740\n",
      "Epoch 23/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7385 - accuracy: 0.6788\n",
      "Epoch 24/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7557 - accuracy: 0.6627\n",
      "Epoch 25/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7352 - accuracy: 0.6649\n",
      "Epoch 26/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7306 - accuracy: 0.6774\n",
      "Epoch 27/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7473 - accuracy: 0.6683\n",
      "Epoch 28/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7347 - accuracy: 0.6813\n",
      "Epoch 29/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7496 - accuracy: 0.6670\n",
      "Epoch 30/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7152 - accuracy: 0.6849\n",
      "Epoch 31/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7498 - accuracy: 0.6715\n",
      "Epoch 32/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7202 - accuracy: 0.6747\n",
      "Epoch 33/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7233 - accuracy: 0.6833\n",
      "Epoch 34/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7315 - accuracy: 0.6792\n",
      "Epoch 35/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7551 - accuracy: 0.6659\n",
      "Epoch 36/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7386 - accuracy: 0.6749\n",
      "Epoch 37/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7387 - accuracy: 0.6757\n",
      "Epoch 38/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7341 - accuracy: 0.6782\n",
      "Epoch 39/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7422 - accuracy: 0.6678\n",
      "Epoch 40/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7404 - accuracy: 0.6741\n",
      "Epoch 41/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7304 - accuracy: 0.6776\n",
      "Epoch 42/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7231 - accuracy: 0.6798\n",
      "Epoch 43/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7060 - accuracy: 0.6789\n",
      "Epoch 44/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7393 - accuracy: 0.6737\n",
      "Epoch 45/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7308 - accuracy: 0.6860\n",
      "Epoch 46/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7246 - accuracy: 0.6830\n",
      "Epoch 47/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7210 - accuracy: 0.6833\n",
      "Epoch 48/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7411 - accuracy: 0.6751\n",
      "Epoch 49/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7432 - accuracy: 0.6682\n",
      "Epoch 50/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7238 - accuracy: 0.6831\n",
      "Epoch 51/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7363 - accuracy: 0.6739\n",
      "Epoch 52/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.6806\n",
      "Epoch 53/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7119 - accuracy: 0.6869\n",
      "Epoch 54/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7176 - accuracy: 0.6897\n",
      "Epoch 55/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7293 - accuracy: 0.6783\n",
      "Epoch 56/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7268 - accuracy: 0.6769\n",
      "Epoch 57/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7255 - accuracy: 0.6806\n",
      "Epoch 58/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7183 - accuracy: 0.6859\n",
      "Epoch 59/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7336 - accuracy: 0.6705\n",
      "Epoch 60/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7168 - accuracy: 0.6818\n",
      "Epoch 61/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7200 - accuracy: 0.6920\n",
      "Epoch 62/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7352 - accuracy: 0.6701\n",
      "Epoch 63/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7142 - accuracy: 0.6873\n",
      "Epoch 64/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7187 - accuracy: 0.6920\n",
      "Epoch 65/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7288 - accuracy: 0.6837\n",
      "Epoch 66/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7446 - accuracy: 0.6809\n",
      "Epoch 67/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7104 - accuracy: 0.6922\n",
      "Epoch 68/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7195 - accuracy: 0.6835\n",
      "Epoch 69/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7162 - accuracy: 0.6837\n",
      "Epoch 70/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7157 - accuracy: 0.6954\n",
      "Epoch 71/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7083 - accuracy: 0.6958\n",
      "Epoch 72/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7303 - accuracy: 0.6774\n",
      "Epoch 73/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7217 - accuracy: 0.6818\n",
      "Epoch 74/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7197 - accuracy: 0.6947\n",
      "Epoch 75/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7170 - accuracy: 0.6908\n",
      "Epoch 76/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7181 - accuracy: 0.6850\n",
      "Epoch 77/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7249 - accuracy: 0.6921\n",
      "Epoch 78/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.6814\n",
      "Epoch 79/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7171 - accuracy: 0.6932\n",
      "Epoch 80/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7224 - accuracy: 0.6888\n",
      "Epoch 81/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7226 - accuracy: 0.6939\n",
      "Epoch 82/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7368 - accuracy: 0.6797\n",
      "Epoch 83/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7195 - accuracy: 0.6853\n",
      "Epoch 84/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7149 - accuracy: 0.6909\n",
      "Epoch 85/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7025 - accuracy: 0.6898\n",
      "Epoch 86/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7085 - accuracy: 0.6970\n",
      "Epoch 87/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7180 - accuracy: 0.6835\n",
      "Epoch 88/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7210 - accuracy: 0.6855\n",
      "Epoch 89/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7119 - accuracy: 0.6927\n",
      "Epoch 90/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7036 - accuracy: 0.6967\n",
      "Epoch 91/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6998 - accuracy: 0.6992\n",
      "Epoch 92/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7267 - accuracy: 0.6893\n",
      "Epoch 93/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7134 - accuracy: 0.7014\n",
      "Epoch 94/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7188 - accuracy: 0.6941\n",
      "Epoch 95/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7226 - accuracy: 0.6899\n",
      "Epoch 96/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7203 - accuracy: 0.6883\n",
      "Epoch 97/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7002 - accuracy: 0.7037\n",
      "Epoch 98/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7200 - accuracy: 0.6924\n",
      "Epoch 99/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7304 - accuracy: 0.6812\n",
      "Epoch 100/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7130 - accuracy: 0.6936\n",
      "Epoch 101/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7182 - accuracy: 0.6877\n",
      "Epoch 102/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7384 - accuracy: 0.6859\n",
      "Epoch 103/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7108 - accuracy: 0.6935\n",
      "Epoch 104/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7169 - accuracy: 0.6851\n",
      "Epoch 105/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7239 - accuracy: 0.6856\n",
      "Epoch 106/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7089 - accuracy: 0.6957\n",
      "Epoch 107/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7148 - accuracy: 0.6884\n",
      "Epoch 108/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7320 - accuracy: 0.6849\n",
      "Epoch 109/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7228 - accuracy: 0.6877\n",
      "Epoch 110/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7395 - accuracy: 0.6766\n",
      "Epoch 111/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7204 - accuracy: 0.6925\n",
      "Epoch 112/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7142 - accuracy: 0.6905\n",
      "Epoch 113/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6986 - accuracy: 0.6969\n",
      "Epoch 114/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7173 - accuracy: 0.6969\n",
      "Epoch 115/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7303 - accuracy: 0.6851\n",
      "Epoch 116/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7227 - accuracy: 0.6779\n",
      "Epoch 117/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7050 - accuracy: 0.6840\n",
      "Epoch 118/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.7019\n",
      "Epoch 119/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7119 - accuracy: 0.6998\n",
      "Epoch 120/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7289 - accuracy: 0.6828\n",
      "Epoch 121/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7189 - accuracy: 0.6922\n",
      "Epoch 122/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7189 - accuracy: 0.6862\n",
      "Epoch 123/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7087 - accuracy: 0.6922\n",
      "Epoch 124/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.6992\n",
      "Epoch 125/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7173 - accuracy: 0.6938\n",
      "Epoch 126/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7169 - accuracy: 0.6896\n",
      "Epoch 127/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6987 - accuracy: 0.7027\n",
      "Epoch 128/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7328 - accuracy: 0.6963\n",
      "Epoch 129/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7094 - accuracy: 0.6927\n",
      "Epoch 130/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7258 - accuracy: 0.6822\n",
      "Epoch 131/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7373 - accuracy: 0.6861\n",
      "Epoch 132/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7165 - accuracy: 0.6858\n",
      "Epoch 133/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7508 - accuracy: 0.6669\n",
      "Epoch 134/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7207 - accuracy: 0.6952\n",
      "Epoch 135/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7185 - accuracy: 0.6880\n",
      "Epoch 136/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7043 - accuracy: 0.6906\n",
      "Epoch 137/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7155 - accuracy: 0.7016\n",
      "Epoch 138/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7205 - accuracy: 0.6894\n",
      "Epoch 139/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7015 - accuracy: 0.7019\n",
      "Epoch 140/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7277 - accuracy: 0.6772\n",
      "Epoch 141/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7056 - accuracy: 0.6988\n",
      "Epoch 142/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7217 - accuracy: 0.6832\n",
      "Epoch 143/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7118 - accuracy: 0.6905\n",
      "Epoch 144/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7116 - accuracy: 0.6888\n",
      "Epoch 145/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7081 - accuracy: 0.6939\n",
      "Epoch 146/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7232 - accuracy: 0.6843\n",
      "Epoch 147/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7339 - accuracy: 0.6907\n",
      "Epoch 148/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7347 - accuracy: 0.6753\n",
      "Epoch 149/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.6979\n",
      "Epoch 150/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7190 - accuracy: 0.6841\n",
      "Epoch 151/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7316 - accuracy: 0.6833\n",
      "Epoch 152/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.6990\n",
      "Epoch 153/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7059 - accuracy: 0.7001\n",
      "Epoch 154/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7071 - accuracy: 0.6921\n",
      "Epoch 155/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7154 - accuracy: 0.6837\n",
      "Epoch 156/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7016 - accuracy: 0.7009\n",
      "Epoch 157/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7156 - accuracy: 0.7010\n",
      "Epoch 158/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7176 - accuracy: 0.6798\n",
      "Epoch 159/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7093 - accuracy: 0.6970\n",
      "Epoch 160/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7080 - accuracy: 0.6930\n",
      "Epoch 161/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7176 - accuracy: 0.6938\n",
      "Epoch 162/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7246 - accuracy: 0.6821\n",
      "Epoch 163/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7148 - accuracy: 0.6817\n",
      "Epoch 164/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7351 - accuracy: 0.6816\n",
      "Epoch 165/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7259 - accuracy: 0.6892\n",
      "Epoch 166/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7097 - accuracy: 0.6992\n",
      "Epoch 167/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7062 - accuracy: 0.6929\n",
      "Epoch 168/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.6933\n",
      "Epoch 169/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7240 - accuracy: 0.6889\n",
      "Epoch 170/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6982 - accuracy: 0.6932\n",
      "Epoch 171/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7097 - accuracy: 0.6964\n",
      "Epoch 172/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7253 - accuracy: 0.6822\n",
      "Epoch 173/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7160 - accuracy: 0.6942\n",
      "Epoch 174/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7113 - accuracy: 0.6930\n",
      "Epoch 175/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7169 - accuracy: 0.6884\n",
      "Epoch 176/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6967 - accuracy: 0.6926\n",
      "Epoch 177/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7287 - accuracy: 0.6722\n",
      "Epoch 178/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7182 - accuracy: 0.6815\n",
      "Epoch 179/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7047 - accuracy: 0.6933\n",
      "Epoch 180/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.6988\n",
      "Epoch 181/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6963 - accuracy: 0.7039\n",
      "Epoch 182/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6981 - accuracy: 0.6995\n",
      "Epoch 183/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7162 - accuracy: 0.6881\n",
      "Epoch 184/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7066 - accuracy: 0.6812\n",
      "Epoch 185/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7044 - accuracy: 0.6937\n",
      "Epoch 186/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7039 - accuracy: 0.7019\n",
      "Epoch 187/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7023 - accuracy: 0.6967\n",
      "Epoch 188/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7194 - accuracy: 0.6929\n",
      "Epoch 189/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7133 - accuracy: 0.6900\n",
      "Epoch 190/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7297 - accuracy: 0.6862\n",
      "Epoch 191/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7151 - accuracy: 0.6876\n",
      "Epoch 192/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7097 - accuracy: 0.6921\n",
      "Epoch 193/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7136 - accuracy: 0.6926\n",
      "Epoch 194/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7253 - accuracy: 0.6785\n",
      "Epoch 195/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7079 - accuracy: 0.6993\n",
      "Epoch 196/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7048 - accuracy: 0.6970\n",
      "Epoch 197/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7125 - accuracy: 0.6823\n",
      "Epoch 198/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7106 - accuracy: 0.6922\n",
      "Epoch 199/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6953 - accuracy: 0.6960\n",
      "Epoch 200/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7235 - accuracy: 0.6789\n",
      "Epoch 201/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7065 - accuracy: 0.6881\n",
      "Epoch 202/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7136 - accuracy: 0.6952\n",
      "Epoch 203/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7047 - accuracy: 0.6974\n",
      "Epoch 204/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7172 - accuracy: 0.6796\n",
      "Epoch 205/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7152 - accuracy: 0.6862\n",
      "Epoch 206/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7080 - accuracy: 0.7019\n",
      "Epoch 207/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7002 - accuracy: 0.6970\n",
      "Epoch 208/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7106 - accuracy: 0.6968\n",
      "Epoch 209/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7114 - accuracy: 0.6815\n",
      "Epoch 210/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7103 - accuracy: 0.6922\n",
      "Epoch 211/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7131 - accuracy: 0.6947\n",
      "Epoch 212/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7190 - accuracy: 0.6996\n",
      "Epoch 213/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7217 - accuracy: 0.6879\n",
      "Epoch 214/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7018 - accuracy: 0.6963\n",
      "Epoch 215/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7156 - accuracy: 0.6798\n",
      "Epoch 216/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7294 - accuracy: 0.6879\n",
      "Epoch 217/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7062 - accuracy: 0.7015\n",
      "Epoch 218/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7255 - accuracy: 0.6826\n",
      "Epoch 219/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7449 - accuracy: 0.6917\n",
      "Epoch 220/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7137 - accuracy: 0.6815\n",
      "Epoch 221/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7141 - accuracy: 0.6935\n",
      "Epoch 222/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7135 - accuracy: 0.6827\n",
      "Epoch 223/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7242 - accuracy: 0.6833\n",
      "Epoch 224/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7111 - accuracy: 0.6975\n",
      "Epoch 225/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.7099\n",
      "Epoch 226/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7167 - accuracy: 0.6825\n",
      "Epoch 227/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7235 - accuracy: 0.6910\n",
      "Epoch 228/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7263 - accuracy: 0.6892\n",
      "Epoch 229/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7114 - accuracy: 0.6935\n",
      "Epoch 230/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7094 - accuracy: 0.6894\n",
      "Epoch 231/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7188 - accuracy: 0.6998\n",
      "Epoch 232/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.7070\n",
      "Epoch 233/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.7042\n",
      "Epoch 234/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7189 - accuracy: 0.6955\n",
      "Epoch 235/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7214 - accuracy: 0.6842\n",
      "Epoch 236/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7055 - accuracy: 0.6938\n",
      "Epoch 237/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7105 - accuracy: 0.6898\n",
      "Epoch 238/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7248 - accuracy: 0.6835\n",
      "Epoch 239/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7224 - accuracy: 0.6874\n",
      "Epoch 240/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7198 - accuracy: 0.7007\n",
      "Epoch 241/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7203 - accuracy: 0.6911\n",
      "Epoch 242/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7258 - accuracy: 0.6923\n",
      "Epoch 243/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7370 - accuracy: 0.6833\n",
      "Epoch 244/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7196 - accuracy: 0.6916\n",
      "Epoch 245/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7362 - accuracy: 0.6728\n",
      "Epoch 246/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6993 - accuracy: 0.7017\n",
      "Epoch 247/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7074 - accuracy: 0.6916\n",
      "Epoch 248/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6994 - accuracy: 0.6996\n",
      "Epoch 249/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7242 - accuracy: 0.6878\n",
      "Epoch 250/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7102 - accuracy: 0.6984\n",
      "Epoch 251/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7147 - accuracy: 0.6920\n",
      "Epoch 252/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7269 - accuracy: 0.6851\n",
      "Epoch 253/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7128 - accuracy: 0.6801\n",
      "Epoch 254/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7112 - accuracy: 0.6893\n",
      "Epoch 255/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7100 - accuracy: 0.6945\n",
      "Epoch 256/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7197 - accuracy: 0.6947\n",
      "Epoch 257/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7163 - accuracy: 0.6826\n",
      "Epoch 258/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.7037\n",
      "Epoch 259/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7093 - accuracy: 0.6972\n",
      "Epoch 260/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.6955\n",
      "Epoch 261/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7184 - accuracy: 0.7029\n",
      "Epoch 262/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7107 - accuracy: 0.7019\n",
      "Epoch 263/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7239 - accuracy: 0.6931\n",
      "Epoch 264/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6972 - accuracy: 0.7082\n",
      "Epoch 265/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7324 - accuracy: 0.6832\n",
      "Epoch 266/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7062 - accuracy: 0.7028\n",
      "Epoch 267/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7284 - accuracy: 0.6953\n",
      "Epoch 268/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7086 - accuracy: 0.6991\n",
      "Epoch 269/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7019 - accuracy: 0.6989\n",
      "Epoch 270/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7065 - accuracy: 0.6944\n",
      "Epoch 271/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7143 - accuracy: 0.6951\n",
      "Epoch 272/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7052 - accuracy: 0.6945\n",
      "Epoch 273/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7327 - accuracy: 0.6893\n",
      "Epoch 274/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7105 - accuracy: 0.6841\n",
      "Epoch 275/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.7008\n",
      "Epoch 276/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7190 - accuracy: 0.6882\n",
      "Epoch 277/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6996 - accuracy: 0.7010\n",
      "Epoch 278/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7105 - accuracy: 0.6916\n",
      "Epoch 279/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7187 - accuracy: 0.6924\n",
      "Epoch 280/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7188 - accuracy: 0.6890\n",
      "Epoch 281/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6997 - accuracy: 0.7062\n",
      "Epoch 282/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7212 - accuracy: 0.6921\n",
      "Epoch 283/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6987 - accuracy: 0.7022\n",
      "Epoch 284/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7229 - accuracy: 0.6810\n",
      "Epoch 285/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7095 - accuracy: 0.6900\n",
      "Epoch 286/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7008 - accuracy: 0.7066\n",
      "Epoch 287/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7233 - accuracy: 0.6871\n",
      "Epoch 288/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7043 - accuracy: 0.6945\n",
      "Epoch 289/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7087 - accuracy: 0.6807\n",
      "Epoch 290/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7060 - accuracy: 0.7017\n",
      "Epoch 291/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7186 - accuracy: 0.6941\n",
      "Epoch 292/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7278 - accuracy: 0.6852\n",
      "Epoch 293/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7339 - accuracy: 0.6838\n",
      "Epoch 294/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7179 - accuracy: 0.6967\n",
      "Epoch 295/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7136 - accuracy: 0.6903\n",
      "Epoch 296/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7268 - accuracy: 0.6824\n",
      "Epoch 297/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7241 - accuracy: 0.6820\n",
      "Epoch 298/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.7058\n",
      "Epoch 299/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7150 - accuracy: 0.6869\n",
      "Epoch 300/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7156 - accuracy: 0.6928\n",
      "Epoch 301/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7215 - accuracy: 0.6889\n",
      "Epoch 302/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7233 - accuracy: 0.6880\n",
      "Epoch 303/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7226 - accuracy: 0.6835\n",
      "Epoch 304/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7281 - accuracy: 0.6924\n",
      "Epoch 305/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7145 - accuracy: 0.6981\n",
      "Epoch 306/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7094 - accuracy: 0.6919\n",
      "Epoch 307/500\n",
      "252/252 [==============================] - 0s 2ms/step - loss: 0.7184 - accuracy: 0.6912\n",
      "Epoch 308/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7113 - accuracy: 0.6876\n",
      "Epoch 309/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7234 - accuracy: 0.6872\n",
      "Epoch 310/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7295 - accuracy: 0.6976\n",
      "Epoch 311/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7127 - accuracy: 0.6850\n",
      "Epoch 312/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7070 - accuracy: 0.6913\n",
      "Epoch 313/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7194 - accuracy: 0.6922\n",
      "Epoch 314/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7095 - accuracy: 0.6912\n",
      "Epoch 315/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7106 - accuracy: 0.6930\n",
      "Epoch 316/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7050 - accuracy: 0.6982\n",
      "Epoch 317/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7186 - accuracy: 0.6958\n",
      "Epoch 318/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7363 - accuracy: 0.6889\n",
      "Epoch 319/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7236 - accuracy: 0.6897\n",
      "Epoch 320/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7048 - accuracy: 0.6923\n",
      "Epoch 321/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7035 - accuracy: 0.6922\n",
      "Epoch 322/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7336 - accuracy: 0.6840\n",
      "Epoch 323/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7253 - accuracy: 0.6913\n",
      "Epoch 324/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7148 - accuracy: 0.6856\n",
      "Epoch 325/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7210 - accuracy: 0.6850\n",
      "Epoch 326/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7119 - accuracy: 0.6822\n",
      "Epoch 327/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7287 - accuracy: 0.6851\n",
      "Epoch 328/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7205 - accuracy: 0.6868\n",
      "Epoch 329/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7280 - accuracy: 0.6838\n",
      "Epoch 330/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7284 - accuracy: 0.6763\n",
      "Epoch 331/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7408 - accuracy: 0.6712\n",
      "Epoch 332/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7179 - accuracy: 0.6931\n",
      "Epoch 333/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6957 - accuracy: 0.6934\n",
      "Epoch 334/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7086 - accuracy: 0.6985\n",
      "Epoch 335/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6969 - accuracy: 0.7018\n",
      "Epoch 336/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7357 - accuracy: 0.6727\n",
      "Epoch 337/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7167 - accuracy: 0.6925\n",
      "Epoch 338/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7038 - accuracy: 0.6956\n",
      "Epoch 339/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.6950\n",
      "Epoch 340/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7280 - accuracy: 0.6852\n",
      "Epoch 341/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7223 - accuracy: 0.6882\n",
      "Epoch 342/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7076 - accuracy: 0.6860\n",
      "Epoch 343/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7248 - accuracy: 0.6833\n",
      "Epoch 344/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7138 - accuracy: 0.6872\n",
      "Epoch 345/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7291 - accuracy: 0.6863\n",
      "Epoch 346/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7122 - accuracy: 0.6869\n",
      "Epoch 347/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7292 - accuracy: 0.6894\n",
      "Epoch 348/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7140 - accuracy: 0.6996\n",
      "Epoch 349/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7188 - accuracy: 0.6813\n",
      "Epoch 350/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7078 - accuracy: 0.6907\n",
      "Epoch 351/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7236 - accuracy: 0.6973\n",
      "Epoch 352/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7304 - accuracy: 0.6853\n",
      "Epoch 353/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7204 - accuracy: 0.6847\n",
      "Epoch 354/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7115 - accuracy: 0.6976\n",
      "Epoch 355/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7070 - accuracy: 0.6949\n",
      "Epoch 356/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7095 - accuracy: 0.6940\n",
      "Epoch 357/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7161 - accuracy: 0.6830\n",
      "Epoch 358/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7142 - accuracy: 0.6924\n",
      "Epoch 359/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7103 - accuracy: 0.6902\n",
      "Epoch 360/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7131 - accuracy: 0.6891\n",
      "Epoch 361/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7098 - accuracy: 0.6935\n",
      "Epoch 362/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7223 - accuracy: 0.6851\n",
      "Epoch 363/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7196 - accuracy: 0.6861\n",
      "Epoch 364/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7049 - accuracy: 0.7011\n",
      "Epoch 365/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7070 - accuracy: 0.6896\n",
      "Epoch 366/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7020 - accuracy: 0.6934\n",
      "Epoch 367/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7271 - accuracy: 0.6811\n",
      "Epoch 368/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7149 - accuracy: 0.6995\n",
      "Epoch 369/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7152 - accuracy: 0.6873\n",
      "Epoch 370/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7239 - accuracy: 0.6919\n",
      "Epoch 371/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7260 - accuracy: 0.6902\n",
      "Epoch 372/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7331 - accuracy: 0.6808\n",
      "Epoch 373/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7009 - accuracy: 0.6965\n",
      "Epoch 374/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7329 - accuracy: 0.6858\n",
      "Epoch 375/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7389 - accuracy: 0.6731\n",
      "Epoch 376/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7006 - accuracy: 0.6995\n",
      "Epoch 377/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7091 - accuracy: 0.6799\n",
      "Epoch 378/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7187 - accuracy: 0.6821\n",
      "Epoch 379/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7183 - accuracy: 0.6890\n",
      "Epoch 380/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7178 - accuracy: 0.6825\n",
      "Epoch 381/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7219 - accuracy: 0.6822\n",
      "Epoch 382/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6965 - accuracy: 0.7017\n",
      "Epoch 383/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7001 - accuracy: 0.6847\n",
      "Epoch 384/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7194 - accuracy: 0.6873\n",
      "Epoch 385/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7310 - accuracy: 0.6824\n",
      "Epoch 386/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7049 - accuracy: 0.6910\n",
      "Epoch 387/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7320 - accuracy: 0.6750\n",
      "Epoch 388/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7299 - accuracy: 0.6759\n",
      "Epoch 389/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7181 - accuracy: 0.6891\n",
      "Epoch 390/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7103 - accuracy: 0.6967\n",
      "Epoch 391/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7142 - accuracy: 0.6957\n",
      "Epoch 392/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7120 - accuracy: 0.6904\n",
      "Epoch 393/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7247 - accuracy: 0.6916\n",
      "Epoch 394/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7159 - accuracy: 0.6846\n",
      "Epoch 395/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7100 - accuracy: 0.6940\n",
      "Epoch 396/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7065 - accuracy: 0.6956\n",
      "Epoch 397/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7328 - accuracy: 0.6846\n",
      "Epoch 398/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7413 - accuracy: 0.6722\n",
      "Epoch 399/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7148 - accuracy: 0.6789\n",
      "Epoch 400/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7016 - accuracy: 0.6989\n",
      "Epoch 401/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7184 - accuracy: 0.6848\n",
      "Epoch 402/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.6917\n",
      "Epoch 403/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7058 - accuracy: 0.6959\n",
      "Epoch 404/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7219 - accuracy: 0.6846\n",
      "Epoch 405/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7158 - accuracy: 0.6853\n",
      "Epoch 406/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7198 - accuracy: 0.6882\n",
      "Epoch 407/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7171 - accuracy: 0.6916\n",
      "Epoch 408/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7225 - accuracy: 0.6871\n",
      "Epoch 409/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7203 - accuracy: 0.6886\n",
      "Epoch 410/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7292 - accuracy: 0.6821\n",
      "Epoch 411/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7087 - accuracy: 0.7001\n",
      "Epoch 412/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7339 - accuracy: 0.6909\n",
      "Epoch 413/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7307 - accuracy: 0.6795\n",
      "Epoch 414/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7017 - accuracy: 0.6961\n",
      "Epoch 415/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7071 - accuracy: 0.6962\n",
      "Epoch 416/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7237 - accuracy: 0.6879\n",
      "Epoch 417/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7188 - accuracy: 0.6844\n",
      "Epoch 418/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7351 - accuracy: 0.6813\n",
      "Epoch 419/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7108 - accuracy: 0.6814\n",
      "Epoch 420/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7228 - accuracy: 0.6901\n",
      "Epoch 421/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7183 - accuracy: 0.6835\n",
      "Epoch 422/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7305 - accuracy: 0.6867\n",
      "Epoch 423/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7142 - accuracy: 0.6912\n",
      "Epoch 424/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7227 - accuracy: 0.6825\n",
      "Epoch 425/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.6912\n",
      "Epoch 426/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7210 - accuracy: 0.6797\n",
      "Epoch 427/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7376 - accuracy: 0.6736\n",
      "Epoch 428/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7174 - accuracy: 0.6904\n",
      "Epoch 429/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7240 - accuracy: 0.6885\n",
      "Epoch 430/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7124 - accuracy: 0.6909\n",
      "Epoch 431/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7166 - accuracy: 0.6809\n",
      "Epoch 432/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7197 - accuracy: 0.6849\n",
      "Epoch 433/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7132 - accuracy: 0.6921\n",
      "Epoch 434/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7178 - accuracy: 0.6874\n",
      "Epoch 435/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7169 - accuracy: 0.6830\n",
      "Epoch 436/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7342 - accuracy: 0.6867\n",
      "Epoch 437/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.6823\n",
      "Epoch 438/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7149 - accuracy: 0.6888\n",
      "Epoch 439/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7353 - accuracy: 0.6775\n",
      "Epoch 440/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7147 - accuracy: 0.6907\n",
      "Epoch 441/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7062 - accuracy: 0.6869\n",
      "Epoch 442/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7449 - accuracy: 0.6771\n",
      "Epoch 443/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7143 - accuracy: 0.6900\n",
      "Epoch 444/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7154 - accuracy: 0.6960\n",
      "Epoch 445/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7196 - accuracy: 0.6789\n",
      "Epoch 446/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7309 - accuracy: 0.6883\n",
      "Epoch 447/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7137 - accuracy: 0.6947\n",
      "Epoch 448/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7374 - accuracy: 0.6820\n",
      "Epoch 449/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7152 - accuracy: 0.6852\n",
      "Epoch 450/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7214 - accuracy: 0.6867\n",
      "Epoch 451/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7328 - accuracy: 0.6791: 0s - loss: 0.7331 - accuracy: 0.67\n",
      "Epoch 452/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7051 - accuracy: 0.6888\n",
      "Epoch 453/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7343 - accuracy: 0.6815\n",
      "Epoch 454/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7262 - accuracy: 0.6779\n",
      "Epoch 455/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7050 - accuracy: 0.6946\n",
      "Epoch 456/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7207 - accuracy: 0.6881\n",
      "Epoch 457/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7295 - accuracy: 0.6805\n",
      "Epoch 458/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7350 - accuracy: 0.6859\n",
      "Epoch 459/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7251 - accuracy: 0.6806\n",
      "Epoch 460/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7098 - accuracy: 0.6817\n",
      "Epoch 461/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7185 - accuracy: 0.6758\n",
      "Epoch 462/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7368 - accuracy: 0.6808\n",
      "Epoch 463/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7183 - accuracy: 0.6814\n",
      "Epoch 464/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7280 - accuracy: 0.6861\n",
      "Epoch 465/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7145 - accuracy: 0.6889\n",
      "Epoch 466/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7158 - accuracy: 0.6798\n",
      "Epoch 467/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7330 - accuracy: 0.6813\n",
      "Epoch 468/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7271 - accuracy: 0.6788\n",
      "Epoch 469/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7104 - accuracy: 0.6808\n",
      "Epoch 470/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7202 - accuracy: 0.6816\n",
      "Epoch 471/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7188 - accuracy: 0.6848\n",
      "Epoch 472/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7217 - accuracy: 0.6803\n",
      "Epoch 473/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7283 - accuracy: 0.6774\n",
      "Epoch 474/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7366 - accuracy: 0.6868\n",
      "Epoch 475/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7281 - accuracy: 0.6741\n",
      "Epoch 476/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7350 - accuracy: 0.6691\n",
      "Epoch 477/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7268 - accuracy: 0.6787\n",
      "Epoch 478/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7420 - accuracy: 0.6816\n",
      "Epoch 479/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7282 - accuracy: 0.6845\n",
      "Epoch 480/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7268 - accuracy: 0.6775\n",
      "Epoch 481/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7158 - accuracy: 0.6794\n",
      "Epoch 482/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7117 - accuracy: 0.6896\n",
      "Epoch 483/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7199 - accuracy: 0.6835\n",
      "Epoch 484/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7256 - accuracy: 0.6805\n",
      "Epoch 485/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7267 - accuracy: 0.6778\n",
      "Epoch 486/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7106 - accuracy: 0.6944\n",
      "Epoch 487/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7326 - accuracy: 0.6776\n",
      "Epoch 488/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7192 - accuracy: 0.6859\n",
      "Epoch 489/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.6938\n",
      "Epoch 490/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7110 - accuracy: 0.6909\n",
      "Epoch 491/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7207 - accuracy: 0.6807\n",
      "Epoch 492/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7113 - accuracy: 0.6936\n",
      "Epoch 493/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7374 - accuracy: 0.6661\n",
      "Epoch 494/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7271 - accuracy: 0.6790\n",
      "Epoch 495/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7409 - accuracy: 0.6890\n",
      "Epoch 496/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7162 - accuracy: 0.6892\n",
      "Epoch 497/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7002 - accuracy: 0.6953\n",
      "Epoch 498/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7221 - accuracy: 0.6860\n",
      "Epoch 499/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7276 - accuracy: 0.6856\n",
      "Epoch 500/500\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7244 - accuracy: 0.6801\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=500, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 915us/step - loss: 0.7902 - accuracy: 0.6337\n",
      "Acc:\n",
      "0.6337249279022217\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Acc:')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_history(history, labels=['loss','accuracy']):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    metrics = [history[m] for m in labels]\n",
    "    epochs = len(metrics[0])\n",
    "    idx = range(0,epochs)\n",
    "    colors = ['r','g','b','orange','magenta']\n",
    "    \n",
    "    fig,ax=plt.subplots(len(metrics),1, figsize=(20,5), sharex=True)\n",
    "    for i in range(len(metrics)):\n",
    "        ax[i].plot(idx,metrics[i],label=labels[i],c=colors[i])\n",
    "        ax[i].grid(alpha=0.3)\n",
    "        ax[i].legend()\n",
    "    ax[i].set_xlabel('Epoch',fontsize=16)\n",
    "    ax[i].set_xlim(0,epochs)\n",
    "    ax[i].set_xticks(range(0,epochs+5,5))\n",
    " \n",
    "    plt.show()\n",
    "\n",
    "# view dictionary element\n",
    "hist = history.history\n",
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La gráfica anterior muestra el progreso del loss y del accuracy del modelo con los datos del entrenamiento a medida que se ejecutan más epochs. Basados en esa gráfica, se determinó que no es necesario ejecutar 500 epochs, así que se volvió a ejecutar el modelo, pero esta vez con un límite de 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_241\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_740 (Dense)            (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_741 (Dense)            (None, 14)                266       \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_742 (Dense)            (None, 10)                150       \n",
      "_________________________________________________________________\n",
      "dense_743 (Dense)            (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 791\n",
      "Trainable params: 791\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(18, kernel_initializer='normal', activation='relu', input_shape=(18,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(14, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "252/252 [==============================] - 1s 1ms/step - loss: 1.0294 - accuracy: 0.4680\n",
      "Epoch 2/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.8299 - accuracy: 0.6492\n",
      "Epoch 3/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7739 - accuracy: 0.6517\n",
      "Epoch 4/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7774 - accuracy: 0.6419\n",
      "Epoch 5/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7412 - accuracy: 0.6743\n",
      "Epoch 6/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7535 - accuracy: 0.6534\n",
      "Epoch 7/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7543 - accuracy: 0.6589\n",
      "Epoch 8/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7537 - accuracy: 0.6580\n",
      "Epoch 9/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7585 - accuracy: 0.6619\n",
      "Epoch 10/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7511 - accuracy: 0.6620\n",
      "Epoch 11/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7558 - accuracy: 0.6602\n",
      "Epoch 12/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7539 - accuracy: 0.6574\n",
      "Epoch 13/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7427 - accuracy: 0.6738\n",
      "Epoch 14/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7526 - accuracy: 0.6642\n",
      "Epoch 15/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7576 - accuracy: 0.6544\n",
      "Epoch 16/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7399 - accuracy: 0.6688\n",
      "Epoch 17/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7530 - accuracy: 0.6611\n",
      "Epoch 18/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7450 - accuracy: 0.6644\n",
      "Epoch 19/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7514 - accuracy: 0.6645\n",
      "Epoch 20/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7519 - accuracy: 0.6615\n",
      "Epoch 21/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7270 - accuracy: 0.6754\n",
      "Epoch 22/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7536 - accuracy: 0.6589\n",
      "Epoch 23/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7451 - accuracy: 0.6712\n",
      "Epoch 24/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7384 - accuracy: 0.6698\n",
      "Epoch 25/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7459 - accuracy: 0.6701\n",
      "Epoch 26/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7389 - accuracy: 0.6741\n",
      "Epoch 27/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7448 - accuracy: 0.6630\n",
      "Epoch 28/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7178 - accuracy: 0.6852\n",
      "Epoch 29/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7353 - accuracy: 0.6635\n",
      "Epoch 30/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7154 - accuracy: 0.6795\n",
      "Epoch 31/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7334 - accuracy: 0.6776\n",
      "Epoch 32/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7270 - accuracy: 0.6696\n",
      "Epoch 33/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7321 - accuracy: 0.6712\n",
      "Epoch 34/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7311 - accuracy: 0.6753\n",
      "Epoch 35/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7282 - accuracy: 0.6757\n",
      "Epoch 36/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7183 - accuracy: 0.6726\n",
      "Epoch 37/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7322 - accuracy: 0.6778\n",
      "Epoch 38/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7400 - accuracy: 0.6695\n",
      "Epoch 39/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7424 - accuracy: 0.6740\n",
      "Epoch 40/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7388 - accuracy: 0.6700\n",
      "Epoch 41/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7383 - accuracy: 0.6693\n",
      "Epoch 42/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7321 - accuracy: 0.6639\n",
      "Epoch 43/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7356 - accuracy: 0.6695\n",
      "Epoch 44/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7303 - accuracy: 0.6784\n",
      "Epoch 45/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7340 - accuracy: 0.6768\n",
      "Epoch 46/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7362 - accuracy: 0.6719\n",
      "Epoch 47/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7585 - accuracy: 0.6631\n",
      "Epoch 48/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7293 - accuracy: 0.6726\n",
      "Epoch 49/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7265 - accuracy: 0.6798\n",
      "Epoch 50/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7350 - accuracy: 0.6669\n",
      "Epoch 51/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7393 - accuracy: 0.6755\n",
      "Epoch 52/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7240 - accuracy: 0.6791\n",
      "Epoch 53/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7341 - accuracy: 0.6749\n",
      "Epoch 54/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7383 - accuracy: 0.6736\n",
      "Epoch 55/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7411 - accuracy: 0.6640\n",
      "Epoch 56/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7402 - accuracy: 0.6730\n",
      "Epoch 57/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7294 - accuracy: 0.6710\n",
      "Epoch 58/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7389 - accuracy: 0.6666\n",
      "Epoch 59/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7173 - accuracy: 0.6862\n",
      "Epoch 60/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7413 - accuracy: 0.6709\n",
      "Epoch 61/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7435 - accuracy: 0.6799\n",
      "Epoch 62/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7387 - accuracy: 0.6725\n",
      "Epoch 63/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7296 - accuracy: 0.6671\n",
      "Epoch 64/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7254 - accuracy: 0.6846\n",
      "Epoch 65/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7298 - accuracy: 0.6722\n",
      "Epoch 66/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7343 - accuracy: 0.6651\n",
      "Epoch 67/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7165 - accuracy: 0.6845\n",
      "Epoch 68/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7393 - accuracy: 0.6652\n",
      "Epoch 69/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7191 - accuracy: 0.6861\n",
      "Epoch 70/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7368 - accuracy: 0.6754\n",
      "Epoch 71/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7490 - accuracy: 0.6666\n",
      "Epoch 72/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7127 - accuracy: 0.6818\n",
      "Epoch 73/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7209 - accuracy: 0.6853\n",
      "Epoch 74/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7282 - accuracy: 0.6772\n",
      "Epoch 75/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7228 - accuracy: 0.6710\n",
      "Epoch 76/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7230 - accuracy: 0.6883\n",
      "Epoch 77/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7263 - accuracy: 0.6736\n",
      "Epoch 78/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7065 - accuracy: 0.6833\n",
      "Epoch 79/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7247 - accuracy: 0.6710\n",
      "Epoch 80/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7274 - accuracy: 0.6779\n",
      "Epoch 81/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7363 - accuracy: 0.6712\n",
      "Epoch 82/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7322 - accuracy: 0.6735\n",
      "Epoch 83/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7087 - accuracy: 0.6861\n",
      "Epoch 84/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7216 - accuracy: 0.6818\n",
      "Epoch 85/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7175 - accuracy: 0.6774\n",
      "Epoch 86/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7214 - accuracy: 0.6827\n",
      "Epoch 87/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7183 - accuracy: 0.6916\n",
      "Epoch 88/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7225 - accuracy: 0.6825\n",
      "Epoch 89/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7130 - accuracy: 0.6872\n",
      "Epoch 90/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7240 - accuracy: 0.6851\n",
      "Epoch 91/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7330 - accuracy: 0.6727\n",
      "Epoch 92/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7242 - accuracy: 0.6717\n",
      "Epoch 93/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7197 - accuracy: 0.6826\n",
      "Epoch 94/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7017 - accuracy: 0.6965\n",
      "Epoch 95/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7452 - accuracy: 0.6670\n",
      "Epoch 96/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7090 - accuracy: 0.6872\n",
      "Epoch 97/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.6908\n",
      "Epoch 98/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7198 - accuracy: 0.6942\n",
      "Epoch 99/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7310 - accuracy: 0.6718\n",
      "Epoch 100/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7205 - accuracy: 0.6826\n",
      "Epoch 101/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7375 - accuracy: 0.6669\n",
      "Epoch 102/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7150 - accuracy: 0.6876\n",
      "Epoch 103/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7187 - accuracy: 0.6815\n",
      "Epoch 104/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7216 - accuracy: 0.6775\n",
      "Epoch 105/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7143 - accuracy: 0.6883\n",
      "Epoch 106/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7266 - accuracy: 0.6719\n",
      "Epoch 107/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7249 - accuracy: 0.6835\n",
      "Epoch 108/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7181 - accuracy: 0.6756\n",
      "Epoch 109/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7216 - accuracy: 0.6833\n",
      "Epoch 110/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7210 - accuracy: 0.6886\n",
      "Epoch 111/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7302 - accuracy: 0.6794\n",
      "Epoch 112/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7029 - accuracy: 0.6965\n",
      "Epoch 113/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7183 - accuracy: 0.6901\n",
      "Epoch 114/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7255 - accuracy: 0.6792\n",
      "Epoch 115/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7001 - accuracy: 0.6831\n",
      "Epoch 116/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7278 - accuracy: 0.6720\n",
      "Epoch 117/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7256 - accuracy: 0.6810\n",
      "Epoch 118/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7335 - accuracy: 0.6804\n",
      "Epoch 119/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7435 - accuracy: 0.6678\n",
      "Epoch 120/120\n",
      "252/252 [==============================] - 0s 1ms/step - loss: 0.7239 - accuracy: 0.6814\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=120, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 819us/step - loss: 0.7765 - accuracy: 0.6344\n",
      "Acc:\n",
      "0.6344160437583923\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Acc:')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_history(history, labels=['loss','accuracy']):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    metrics = [history[m] for m in labels]\n",
    "    epochs = len(metrics[0])\n",
    "    idx = range(0,epochs)\n",
    "    colors = ['r','g','b','orange','magenta']\n",
    "    \n",
    "    fig,ax=plt.subplots(len(metrics),1, figsize=(20,5), sharex=True)\n",
    "    for i in range(len(metrics)):\n",
    "        ax[i].plot(idx,metrics[i],label=labels[i],c=colors[i])\n",
    "        ax[i].grid(alpha=0.3)\n",
    "        ax[i].legend()\n",
    "    ax[i].set_xlabel('Epoch',fontsize=16)\n",
    "    ax[i].set_xlim(0,epochs)\n",
    "    ax[i].set_xticks(range(0,epochs+5,5))\n",
    " \n",
    "    plt.show()\n",
    "\n",
    "# view dictionary element\n",
    "hist = history.history\n",
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 912us/step - loss: 0.7847 - accuracy: 0.6283\n",
      "Acc:\n",
      "0.6283310055732727\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_val, y_val)\n",
    "print('Acc:')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este gráfico muestra un mejor trabajo del modelo, ya que no recorrió más epochs de los necesarios para alcanzar su máxima presición. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ultimo paso, se realizó una predicción de los partidos disputados el 19 de Mayo de 2021. Hay que recordar que el objetivo del modelo es predecir resultados, situandonos en el medio tiempo. De esta forma conoceremos las estadísticas de juego al medio tiempo, lo cual otorga información vital para la predicción. A continuación se cargó el dataset llenado con la información de 5 partidos disputados el 19 de mayo. El resultado de la predicción será utilizado para apostar en la plataforma de BET365, y de esta forma pasar el modelo por la prueba de fuego. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTR</th>\n",
       "      <th>HS</th>\n",
       "      <th>AS</th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>6.00</td>\n",
       "      <td>19.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HTHG  HTAG  HTR  HS  AS  HST  AST   HF   AF  HC  AC  HY  AY  HR  AR  B365H  \\\n",
       "0     1     0    1   8   2    5    0  3.5  3.5   4   0   0   2   0   0   1.18   \n",
       "1     1     2   -1   1   8    1    4  7.0  6.5   0   1   1   0   0   0   1.55   \n",
       "2     0     1   -1   4   2    1    1  3.5  3.5   3   6   2   1   0   0  19.00   \n",
       "3     0     1   -1   4  12    1    1  5.0  3.5   2   2   0   0   0   0   9.00   \n",
       "4     1     1    0   7   9    3    3  4.0  5.5   4   5   2   1   0   0   5.25   \n",
       "\n",
       "   B365D  B365A  \n",
       "0   6.00  19.00  \n",
       "1   4.50   5.25  \n",
       "2   6.00   1.18  \n",
       "3   6.00   1.28  \n",
       "4   4.33   1.57  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predecir = pd.read_csv(\"partidos_19.csv\")\n",
    "predecir.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(predecir)\n",
    "\n",
    "predecir = scaler.transform(predecir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 1.  ],\n",
       "       [0.66, 0.27, 0.07],\n",
       "       [0.65, 0.27, 0.09],\n",
       "       [0.57, 0.31, 0.11],\n",
       "       [0.15, 0.34, 0.51]], dtype=float32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones = predecir\n",
    "\n",
    "pred = model.predict(predecir)\n",
    "pred = np.around(pred, 2)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al tener una variable objetivo con 3 categorías, el modelo predictivo retorna un array donde cada fila tiene 3 valores. El valor más alto será el que se tome como la predicción del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se generó la siguiente función para convertir el output de la predicción del modelo a una forma fácil de interpretar por el usuario, la cual es una lista que muestra el resultado de cada partido predecido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir(pred):\n",
    "    resultados=[]\n",
    "    for i in range(pred.shape[0]):\n",
    "            if ((pred[i,0] > pred[i,1]) & (pred[i,0] > pred[i,2])):\n",
    "               resultados.append('AWAY')\n",
    "            elif(pred[i,1] > pred[i,2]):\n",
    "               resulatos.append('DRAW')\n",
    "            else:\n",
    "               resultados.append('HOME')\n",
    "    return(resultados)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HOME', 'AWAY', 'AWAY', 'AWAY', 'HOME']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados = predecir(pred)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa en la lista, el modelo predijo los 5 resultados. Tras replicarlos en la plataforma de bet365, resulto ser que el modelo acerto 4 de las 5 predicciones. Esta cifra no esta mal, y de hecho esta por encima del valor esperado debido a su accuracy. El modelo fue capaz de obtener una ganancia neta de $0.10, con una apuesta de $1, es decir el 10% de ganacia. Esto me deja muy satisfecho, sin embargo soy conciente de que si se hubiese dado el valor esperado de aciertos, el resultado neto hubiera sido perdida. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSIONES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si consideramos las métricas obtenidas por el modelo (accuracy en train de 0.69, test de 0.64 y cross validation de 0.63) no suenan muy altas. Sin embargo, cabe mencionar que el dataset utilizado no era el más grande, y su informació era tambien dificil de aprovechar completamente. El dataset sufrío algunas transformacones para adptarse a las apuestas al medio tiempo (como tener que dividir las estadisticas del partido a la mitad), y aun así conservó la capacidad de predecir un 63% de las predicciones intentadas con el modelo de redes neurales. Adicionalmente tengo que decir que aunque me hubiera gustado obtener un accuracy más alto, si el fútbol fuera tan fácil de predecir, no sería fútbol. Probablemente estamos acostumbrados a fenomenos de la vida real que pueden ser muy estimables por modelos de machine learning, pero sin embargo queda claro que el fútbol, al menos con un set de datos como el que se utilizó para este proyecto, no puede ser predecido con la exactitud deseada. Sin embargo, un enfoque muy positivo es que el proyecto fue capaz de obtener ganancia neta despues de ser usado en 5 apuestas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias:                                                                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search Deep Learning Model Parameters: uso de un grid search, para probar multiples hiper parámetros, y definir cual era la mejor combinación sobre la cual seguir desarrollando el modelo. Fuente: https://machinelearningmastery.com/use-keras-deep-learning-models-scikit-learn-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criterio para generar la arquitectura más apropiada para la red neuronal que entrenaría el módelo final. Fuente: https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criterio para decidir si normalizar o estandarizar los datos, dependiendo de lo que se busca. Fuente: http://www.faqs.org/faqs/ai-faq/neural-nets/part2/section-16.html"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
